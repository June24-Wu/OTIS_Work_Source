{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from PIL import Image\n",
    "import os\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c9656def-8fa9-4254-ae11-5c925b7b14ab",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "BASE_PATH = ''\n",
    "DATA_PATH = ''\n",
    "\n",
    "batch_size = 128\n",
    "img_height = 240\n",
    "img_width = 320\n",
    "\n",
    "resized_height = 120\n",
    "resized_width = 160\n",
    "\n",
    "num_classes = 2\n",
    "NUM_EPOCHS = 120\n",
    "seed = 12\n",
    "log_dir = BASE_PATH + \"/logs\"\n",
    "\n",
    "STEPS_PER_EPOCH = 1508 //batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "99ce880e-5476-4f8e-b471-653a76a034d4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Found 16468 files belonging to 2 classes.\n",
       "Using 14822 files for training.\n",
       "Found 16468 files belonging to 2 classes.\n",
       "Using 1646 files for validation.\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Found 16468 files belonging to 2 classes.\nUsing 14822 files for training.\nFound 16468 files belonging to 2 classes.\nUsing 1646 files for validation.\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "  layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "  layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "  layers.experimental.preprocessing.RandomZoom(0.2),\n",
    "  layers.experimental.preprocessing.RandomContrast(0.2),\n",
    "])\n",
    "\n",
    "resize = tf.keras.layers.experimental.preprocessing.Resizing(resized_height, resized_width)\n",
    "\n",
    "def preprocess_input(image):\n",
    "    return (image/127.5) - 1\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  DATA_PATH,\n",
    "  seed=seed,\n",
    "  shuffle=True,\n",
    "  validation_split=0.1,\n",
    "  subset='training',\n",
    "  image_size=(img_height, img_width)\n",
    ")\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "train_ds = train_ds.map(\n",
    "  lambda x, y: (data_augmentation(x, training=True), y))\n",
    "\n",
    "train_ds = train_ds.map(\n",
    "  lambda x, y: (preprocess_input(x), y))\n",
    "\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  DATA_PATH,\n",
    "  seed=seed,\n",
    "  shuffle=True,\n",
    "  validation_split=0.1,\n",
    "  subset='validation',\n",
    "  image_size=(img_height, img_width)\n",
    ")\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.map(\n",
    "  lambda x, y: (preprocess_input(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "fdecf590-69e1-4548-be8e-746ec23f9612",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class CustomLearningRateScheduler(tf.keras.callbacks.Callback):\n",
    "    \"\"\"Learning rate scheduler which sets the learning rate according to schedule.\n",
    "\n",
    "  Arguments:\n",
    "      schedule: a function that takes an epoch index\n",
    "          (integer, indexed from 0) and current learning rate\n",
    "          as inputs and returns a new learning rate as output (float).\n",
    "  \"\"\"\n",
    "\n",
    "    def __init__(self, schedule):\n",
    "        super(CustomLearningRateScheduler, self).__init__()\n",
    "        self.schedule = schedule\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        if not hasattr(self.model.optimizer, \"lr\"):\n",
    "            raise ValueError('Optimizer must have a \"lr\" attribute.')\n",
    "        # Get the current learning rate from model's optimizer.\n",
    "        lr = float(tf.keras.backend.get_value(self.model.optimizer.learning_rate))\n",
    "        # Call schedule function to get the scheduled learning rate.\n",
    "        scheduled_lr = self.schedule(epoch, lr)\n",
    "        # Set the value back to the optimizer before this epoch starts\n",
    "        tf.keras.backend.set_value(self.model.optimizer.lr, scheduled_lr)\n",
    "        print(\"\\nEpoch %05d: Learning rate is %6.4f.\" % (epoch, scheduled_lr))\n",
    "\n",
    "\n",
    "LR_SCHEDULE = [\n",
    "    # (epoch to start, learning rate) tuples\n",
    "    (10, 0.005),\n",
    "    (30, 0.001),\n",
    "    (50, 0.0005)\n",
    "]\n",
    "\n",
    "\n",
    "def lr_schedule(epoch, lr):\n",
    "    \"\"\"Helper function to retrieve the scheduled learning rate based on epoch.\"\"\"\n",
    "    if epoch < LR_SCHEDULE[0][0] or epoch > LR_SCHEDULE[-1][0]:\n",
    "        return lr\n",
    "    for i in range(len(LR_SCHEDULE)):\n",
    "        if epoch == LR_SCHEDULE[i][0]:\n",
    "            return LR_SCHEDULE[i][1]\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "efb76772-5ba0-4868-9d28-45bd917b4836",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n",
       "<span class=\"ansi-red-fg\">TypeError</span>                                 Traceback (most recent call last)\n",
       "<span class=\"ansi-green-fg\">&lt;command-3534976955442343&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     28</span>                 metrics=[&#39;accuracy&#39;])\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     29</span>     <span class=\"ansi-green-fg\">return</span> model\n",
       "<span class=\"ansi-green-fg\">---&gt; 30</span><span class=\"ansi-red-fg\"> </span>model <span class=\"ansi-blue-fg\">=</span> get_model<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     31</span> model<span class=\"ansi-blue-fg\">.</span>summary<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n",
       "\n",
       "<span class=\"ansi-green-fg\">&lt;command-3534976955442343&gt;</span> in <span class=\"ansi-cyan-fg\">get_model</span><span class=\"ansi-blue-fg\">(lr, alpha)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      2</span>     base_model = tf.keras.applications.ResNet152V2(\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      3</span>         input_shape<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">(</span>img_height<span class=\"ansi-blue-fg\">,</span> img_width<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">3</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span>\n",
       "<span class=\"ansi-green-fg\">----&gt; 4</span><span class=\"ansi-red-fg\">         include_top=False, weights=&#39;imagenet&#39;, alpha=alpha)\n",
       "</span><span class=\"ansi-green-intense-fg ansi-bold\">      5</span> <span class=\"ansi-red-fg\">#     base_model.trainable = False</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      6</span>     base_model<span class=\"ansi-blue-fg\">.</span>trainable <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">True</span>\n",
       "\n",
       "<span class=\"ansi-red-fg\">TypeError</span>: ResNet152V2() got an unexpected keyword argument &#39;alpha&#39;</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">TypeError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-3534976955442343&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     28</span>                 metrics=[&#39;accuracy&#39;])\n<span class=\"ansi-green-intense-fg ansi-bold\">     29</span>     <span class=\"ansi-green-fg\">return</span> model\n<span class=\"ansi-green-fg\">---&gt; 30</span><span class=\"ansi-red-fg\"> </span>model <span class=\"ansi-blue-fg\">=</span> get_model<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     31</span> model<span class=\"ansi-blue-fg\">.</span>summary<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">&lt;command-3534976955442343&gt;</span> in <span class=\"ansi-cyan-fg\">get_model</span><span class=\"ansi-blue-fg\">(lr, alpha)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span>     base_model = tf.keras.applications.ResNet152V2(\n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span>         input_shape<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">(</span>img_height<span class=\"ansi-blue-fg\">,</span> img_width<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">3</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-fg\">----&gt; 4</span><span class=\"ansi-red-fg\">         include_top=False, weights=&#39;imagenet&#39;, alpha=alpha)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">      5</span> <span class=\"ansi-red-fg\">#     base_model.trainable = False</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      6</span>     base_model<span class=\"ansi-blue-fg\">.</span>trainable <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">True</span>\n\n<span class=\"ansi-red-fg\">TypeError</span>: ResNet152V2() got an unexpected keyword argument &#39;alpha&#39;</div>",
       "errorSummary": "<span class=\"ansi-red-fg\">TypeError</span>: ResNet152V2() got an unexpected keyword argument &#39;alpha&#39;",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_model(lr=0.001, alpha=0.35):\n",
    "    base_model = tf.keras.applications.ResNet152V2(\n",
    "        input_shape=(img_height, img_width, 3),\n",
    "        include_top=False, weights='imagenet', \n",
    "#       alpha=alpha\n",
    "    )\n",
    "#     base_model.trainable = False\n",
    "    base_model.trainable = True\n",
    "    # Add a new classifier layer for transfer learning\n",
    "    global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "    dropout = tf.keras.layers.Dropout(0.2)\n",
    "    prediction_layer = tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "#     prediction_layer = tf.keras.layers.Dense(1, activation='softmax')\n",
    "  \n",
    "    model = tf.keras.Sequential([\n",
    "      base_model,\n",
    "      global_average_layer,\n",
    "      dropout,\n",
    "      prediction_layer\n",
    "    ])\n",
    "    return model\n",
    "  \n",
    "def get_compiled_model(alpha=0.35, lr=0.001):\n",
    "    model = get_model(lr, alpha)\n",
    "#     lr = learning_rate = CustomSchedule(2)\n",
    "    model.compile(\n",
    "                optimizer=tf.keras.optimizers.SGD(learning_rate=lr, momentum=0.9),\n",
    "#                 optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "    return model\n",
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "36b6f893-7f0c-41ec-b049-985d42543ba7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train_and_evaluate(train_ds, val_ds=None, lr=0.001):\n",
    "    model = get_compiled_model()\n",
    "#     model = get_compiled_model_2()\n",
    "    checkpoint_path = BASE_PATH + \"/Model/Best_Model.ckpt\"\n",
    "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "    \n",
    "#     model.save_weights(checkpoint_path.format(epoch=0))\n",
    "\n",
    "    # 创建一个保存模型权重的回调\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                     save_weights_only= True,\n",
    "                                                     save_best_only = True,\n",
    "                                                     monitor='accuracy',\n",
    "                                                     mode='auto', \n",
    "                                                     save_freq='epoch',\n",
    "                                                     verbose=1)\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=10)\n",
    "    board_callback = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=log_dir,\n",
    "        histogram_freq=0,  # How often to log histogram visualizations\n",
    "        embeddings_freq=0,  # How often to log embedding visualizations\n",
    "        update_freq=\"epoch\",\n",
    "    )  # How often to write logs (default: once per epoch)\n",
    "    \n",
    "#     steps_per_epoch = len(train_ds) // batch_size\n",
    "    hist = model.fit(train_ds, \n",
    "#                      steps_per_epoch=steps_per_epoch,\n",
    "                     epochs=NUM_EPOCHS,\n",
    "                     validation_data=val_ds,\n",
    "#                      class_weight={0:0.3, 1:0.7},\n",
    "#                      validation_steps=validation_steps,\n",
    "                     verbose=2,\n",
    "                     callbacks=[\n",
    "                       cp_callback, \n",
    "#                        board_callback, \n",
    "                       early_stop,\n",
    "#                        CustomLearningRateScheduler(lr_schedule),\n",
    "                     ])\n",
    "#     model.save('saved_model/my_model')\n",
    "    return hist,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4e02e922-b7c8-4368-af37-78a199f4b31c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "  try:\n",
    "    for gpu in gpus:\n",
    "#       tf.config.experimental.set_memory_growth(gpu, True)\n",
    "      print('yes')\n",
    "#     tf.config.experimental.set_virtual_device_configuration(\n",
    "#         gpus[0],\n",
    "#         [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d82f6f97-cdd4-41dc-afec-12b0b69e0a34",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "with strategy.scope():\n",
    "  hist,model = train_and_evaluate(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2fc10fee-5b2a-4be1-a095-842b0547489a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = hist.history['accuracy']\n",
    "# val_acc = hist.history['val_accuracy']\n",
    "\n",
    "loss = hist.history['loss']\n",
    "# val_loss = hist.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "# plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "# plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "ResNet50_random_train_test",
   "notebookOrigID": 3534976955442338,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
