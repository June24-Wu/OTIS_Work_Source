{"cells":[{"cell_type":"code","source":["import tensorflow as tf\nfrom tensorflow.keras import layers\nfrom PIL import Image\nimport os\nimport pathlib\nimport numpy as np\nimport pathlib\nimport shutil"],"metadata":{"ExecuteTime":{"end_time":"2021-03-17T04:20:11.325951Z","start_time":"2021-03-17T04:19:34.532762Z"},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d2aca74f-2f2d-4475-aee5-19061ce67bc6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["BASE_PATH = '/dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331'\nDATA_PATH = '/dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/Pictures'\n\ncheckpoint_path = BASE_PATH + \"/Model/Best_Model_Small.h5py\"\ncheckpoint_dir = os.path.dirname(checkpoint_path)\n# train_dir = pathlib.Path(DATA_PATH+'/training')\n# val_dir = pathlib.Path(DATA_PATH+'/val')\n\n# train_dir = dbutils.fs.ls(DATA_PATH+\"/train/\")\n# val_dir = dbutils.fs.ls(DATA_PATH+\"/val/\")\nbatch_size = 128\nimg_height = 120\nimg_width = 160\n\nresized_height = 120\nresized_width = 160\n\n# IMG_SHAPE = (224, 224, 3)\n# CLASS_PEOPLE = \"/dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/training/people_class\"\nnum_classes = 2\nNUM_EPOCHS = 400\nseed = 12\nlog_dir = BASE_PATH + \"/logs\"\n\nSTEPS_PER_EPOCH = 1508 //batch_size"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c9656def-8fa9-4254-ae11-5c925b7b14ab"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["AUTOTUNE = tf.data.experimental.AUTOTUNE\ndata_augmentation = tf.keras.Sequential([\n#   layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n  layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n  layers.experimental.preprocessing.RandomRotation(0.2),\n  layers.experimental.preprocessing.RandomZoom(0.2),\n  layers.experimental.preprocessing.RandomContrast(0.2),\n#   layers.experimental.preprocessing.RandomContrast(0.2),\n])\n\nresize = tf.keras.layers.experimental.preprocessing.Resizing(resized_height, resized_width)\n\ndef preprocess_input(image):\n    return (image/127.5) - 1\n\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(\n  DATA_PATH,\n  seed=seed,\n  shuffle=True,\n  validation_split=0.2,\n  subset='training',\n  image_size=(img_height, img_width)\n)\ntrain_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n\ntrain_ds = train_ds.map(\n  lambda x, y: (data_augmentation(x, training=True), y))\n\ntrain_ds = train_ds.map(\n  lambda x, y: (preprocess_input(x), y))\n\n\nval_ds = tf.keras.preprocessing.image_dataset_from_directory(\n  DATA_PATH,\n  seed=seed,\n  shuffle=True,\n  validation_split=0.2,\n  subset='validation',\n  image_size=(img_height, img_width)\n)\nval_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\nval_ds = val_ds.map(\n  lambda x, y: (preprocess_input(x), y))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"99ce880e-5476-4f8e-b471-653a76a034d4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Found 11163 files belonging to 2 classes.\nUsing 8931 files for training.\nFound 11163 files belonging to 2 classes.\nUsing 2232 files for validation.\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Found 11163 files belonging to 2 classes.\nUsing 8931 files for training.\nFound 11163 files belonging to 2 classes.\nUsing 2232 files for validation.\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["class CustomLearningRateScheduler(tf.keras.callbacks.Callback):\n    \"\"\"Learning rate scheduler which sets the learning rate according to schedule.\n\n  Arguments:\n      schedule: a function that takes an epoch index\n          (integer, indexed from 0) and current learning rate\n          as inputs and returns a new learning rate as output (float).\n  \"\"\"\n\n    def __init__(self, schedule):\n        super(CustomLearningRateScheduler, self).__init__()\n        self.schedule = schedule\n\n    def on_epoch_begin(self, epoch, logs=None):\n        if not hasattr(self.model.optimizer, \"lr\"):\n            raise ValueError('Optimizer must have a \"lr\" attribute.')\n        # Get the current learning rate from model's optimizer.\n        lr = float(tf.keras.backend.get_value(self.model.optimizer.learning_rate))\n        # Call schedule function to get the scheduled learning rate.\n        scheduled_lr = self.schedule(epoch, lr)\n        # Set the value back to the optimizer before this epoch starts\n        tf.keras.backend.set_value(self.model.optimizer.lr, scheduled_lr)\n        print(\"\\nEpoch %05d: Learning rate is %6.4f.\" % (epoch, scheduled_lr))\n\n\nLR_SCHEDULE = [\n    # (epoch to start, learning rate) tuples\n    (10, 0.005),\n    (30, 0.001),\n    (50, 0.0005)\n]\n\n\ndef lr_schedule(epoch, lr):\n    \"\"\"Helper function to retrieve the scheduled learning rate based on epoch.\"\"\"\n    if epoch < LR_SCHEDULE[0][0] or epoch > LR_SCHEDULE[-1][0]:\n        return lr\n    for i in range(len(LR_SCHEDULE)):\n        if epoch == LR_SCHEDULE[i][0]:\n            return LR_SCHEDULE[i][1]\n    return lr"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fdecf590-69e1-4548-be8e-746ec23f9612"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["from tensorflow.keras.layers import Conv2D, DepthwiseConv2D, Dense, GlobalAveragePooling2D,Input\nfrom tensorflow.keras.layers import Activation, BatchNormalization, Add, Multiply, Reshape\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import backend as K\n\n# 定义relu6激活函数\ndef relu6(x):\n    return K.relu(x, max_value=6.0)\n# 定义h-swish激活函数\ndef hard_swish(x):\n    return x * K.relu(x + 3.0, max_value=6.0) / 6.0\n# 定义返回的激活函数是relu6还是h-swish\ndef return_activation(x, nl):\n    if nl == 'HS':\n        x = Activation(hard_swish)(x)\n    if nl == 'RE':\n        x = Activation(relu6)(x)\n    return x\n# 定义卷积块(卷积+标准化+激活函数)\ndef conv_block(inputs, filters, kernel, strides, nl):\n    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n    x = Conv2D(filters, kernel, padding='same', strides=strides)(inputs)\n    x = BatchNormalization(axis=channel_axis)(x)\n    return return_activation(x, nl)\n# 定义注意力机制模块\ndef SE(inputs):\n    input_channels = int(inputs.shape[-1])\n    x = GlobalAveragePooling2D()(inputs)\n    x = Dense(input_channels, activation='relu')(x)\n    x = Dense(input_channels, activation='hard_sigmoid')(x)\n    x = Reshape((1, 1, input_channels))(x)\n    x = Multiply()([inputs, x])\n    return x\n\ndef bottleneck(inputs, filters, kernel, e, s, squeeze, nl,alpha=1.0):\n    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n    input_shape = K.int_shape(inputs)\n    tchannel = int(e)\n    cchannel = int(alpha * filters)\n    r = s == 1 and input_shape[3] == filters\n    x = conv_block(inputs, tchannel, (1,1), (1,1), nl)\n    x = DepthwiseConv2D(kernel, strides=(s,s), depth_multiplier=1, padding='same')(x)\n    x = BatchNormalization(axis=channel_axis)(x)\n    x = return_activation(x,nl)\n    if squeeze:\n        x = SE(x)\n    x = Conv2D(cchannel, (1,1), strides=(1,1), padding='same')(x)\n    x = BatchNormalization(axis=channel_axis)(x)\n    if r:\n        x = Add()([x, inputs])\n    return x\n\n\ndef MobileNetv3_small(shape = (224,224,3),n_class = 1000,alpha=1.0):\n    inputs = Input(shape)\n    x = conv_block(inputs, 16, (3, 3), strides=(2, 2), nl='HS')\n    x = bottleneck(x, 16, (3, 3), e=16, s=2, squeeze=True, nl='RE', alpha=alpha)\n    x = bottleneck(x, 24, (3, 3), e=72, s=2, squeeze=False, nl='RE', alpha=alpha)\n    x = bottleneck(x, 24, (3, 3), e=88, s=1, squeeze=False, nl='RE', alpha=alpha)\n    x = bottleneck(x, 40, (5, 5), e=96, s=2, squeeze=True, nl='HS', alpha=alpha)\n    x = bottleneck(x, 40, (5, 5), e=240, s=1, squeeze=True, nl='HS', alpha=alpha)\n    x = bottleneck(x, 40, (5, 5), e=240, s=1, squeeze=True, nl='HS', alpha=alpha)\n    x = bottleneck(x, 48, (5, 5), e=120, s=1, squeeze=True, nl='HS', alpha=alpha)\n    x = bottleneck(x, 48, (5, 5), e=144, s=1, squeeze=True, nl='HS', alpha=alpha)\n    x = bottleneck(x, 96, (5, 5), e=288, s=2, squeeze=True, nl='HS', alpha=alpha)\n    x = bottleneck(x, 96, (5, 5), e=576, s=1, squeeze=True, nl='HS', alpha=alpha)\n    x = bottleneck(x, 96, (5, 5), e=576, s=1, squeeze=True, nl='HS', alpha=alpha)\n\n      \n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.Dropout(0.2)(x)\n    x = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n\n    model = Model(inputs, x)\n\n    return model\n\nmodel = MobileNetv3_small(shape = (img_height, img_width, 3))\nmodel.summary()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dcf06549-04fc-4f50-afe0-5fe4d1b476d7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Model: &#34;model&#34;\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            [(None, 120, 160, 3) 0                                            \n__________________________________________________________________________________________________\nconv2d (Conv2D)                 (None, 60, 80, 16)   448         input_1[0][0]                    \n__________________________________________________________________________________________________\nbatch_normalization (BatchNorma (None, 60, 80, 16)   64          conv2d[0][0]                     \n__________________________________________________________________________________________________\nactivation (Activation)         (None, 60, 80, 16)   0           batch_normalization[0][0]        \n__________________________________________________________________________________________________\nconv2d_1 (Conv2D)               (None, 60, 80, 16)   272         activation[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_1 (BatchNor (None, 60, 80, 16)   64          conv2d_1[0][0]                   \n__________________________________________________________________________________________________\nactivation_1 (Activation)       (None, 60, 80, 16)   0           batch_normalization_1[0][0]      \n__________________________________________________________________________________________________\ndepthwise_conv2d (DepthwiseConv (None, 30, 40, 16)   160         activation_1[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_2 (BatchNor (None, 30, 40, 16)   64          depthwise_conv2d[0][0]           \n__________________________________________________________________________________________________\nactivation_2 (Activation)       (None, 30, 40, 16)   0           batch_normalization_2[0][0]      \n__________________________________________________________________________________________________\nglobal_average_pooling2d (Globa (None, 16)           0           activation_2[0][0]               \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 16)           272         global_average_pooling2d[0][0]   \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 16)           272         dense[0][0]                      \n__________________________________________________________________________________________________\nreshape (Reshape)               (None, 1, 1, 16)     0           dense_1[0][0]                    \n__________________________________________________________________________________________________\nmultiply (Multiply)             (None, 30, 40, 16)   0           activation_2[0][0]               \n                                                                 reshape[0][0]                    \n__________________________________________________________________________________________________\nconv2d_2 (Conv2D)               (None, 30, 40, 16)   272         multiply[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_3 (BatchNor (None, 30, 40, 16)   64          conv2d_2[0][0]                   \n__________________________________________________________________________________________________\nconv2d_3 (Conv2D)               (None, 30, 40, 72)   1224        batch_normalization_3[0][0]      \n__________________________________________________________________________________________________\nbatch_normalization_4 (BatchNor (None, 30, 40, 72)   288         conv2d_3[0][0]                   \n__________________________________________________________________________________________________\nactivation_3 (Activation)       (None, 30, 40, 72)   0           batch_normalization_4[0][0]      \n__________________________________________________________________________________________________\ndepthwise_conv2d_1 (DepthwiseCo (None, 15, 20, 72)   720         activation_3[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_5 (BatchNor (None, 15, 20, 72)   288         depthwise_conv2d_1[0][0]         \n__________________________________________________________________________________________________\nactivation_4 (Activation)       (None, 15, 20, 72)   0           batch_normalization_5[0][0]      \n__________________________________________________________________________________________________\nconv2d_4 (Conv2D)               (None, 15, 20, 24)   1752        activation_4[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_6 (BatchNor (None, 15, 20, 24)   96          conv2d_4[0][0]                   \n__________________________________________________________________________________________________\nconv2d_5 (Conv2D)               (None, 15, 20, 88)   2200        batch_normalization_6[0][0]      \n__________________________________________________________________________________________________\nbatch_normalization_7 (BatchNor (None, 15, 20, 88)   352         conv2d_5[0][0]                   \n__________________________________________________________________________________________________\nactivation_5 (Activation)       (None, 15, 20, 88)   0           batch_normalization_7[0][0]      \n__________________________________________________________________________________________________\ndepthwise_conv2d_2 (DepthwiseCo (None, 15, 20, 88)   880         activation_5[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_8 (BatchNor (None, 15, 20, 88)   352         depthwise_conv2d_2[0][0]         \n__________________________________________________________________________________________________\nactivation_6 (Activation)       (None, 15, 20, 88)   0           batch_normalization_8[0][0]      \n__________________________________________________________________________________________________\nconv2d_6 (Conv2D)               (None, 15, 20, 24)   2136        activation_6[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_9 (BatchNor (None, 15, 20, 24)   96          conv2d_6[0][0]                   \n__________________________________________________________________________________________________\nadd (Add)                       (None, 15, 20, 24)   0           batch_normalization_9[0][0]      \n                                                                 batch_normalization_6[0][0]      \n__________________________________________________________________________________________________\nconv2d_7 (Conv2D)               (None, 15, 20, 96)   2400        add[0][0]                        \n__________________________________________________________________________________________________\nbatch_normalization_10 (BatchNo (None, 15, 20, 96)   384         conv2d_7[0][0]                   \n__________________________________________________________________________________________________\nactivation_7 (Activation)       (None, 15, 20, 96)   0           batch_normalization_10[0][0]     \n__________________________________________________________________________________________________\ndepthwise_conv2d_3 (DepthwiseCo (None, 8, 10, 96)    2496        activation_7[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_11 (BatchNo (None, 8, 10, 96)    384         depthwise_conv2d_3[0][0]         \n__________________________________________________________________________________________________\nactivation_8 (Activation)       (None, 8, 10, 96)    0           batch_normalization_11[0][0]     \n__________________________________________________________________________________________________\nglobal_average_pooling2d_1 (Glo (None, 96)           0           activation_8[0][0]               \n__________________________________________________________________________________________________\ndense_2 (Dense)                 (None, 96)           9312        global_average_pooling2d_1[0][0] \n__________________________________________________________________________________________________\ndense_3 (Dense)                 (None, 96)           9312        dense_2[0][0]                    \n__________________________________________________________________________________________________\nreshape_1 (Reshape)             (None, 1, 1, 96)     0           dense_3[0][0]                    \n__________________________________________________________________________________________________\nmultiply_1 (Multiply)           (None, 8, 10, 96)    0           activation_8[0][0]               \n                                                                 reshape_1[0][0]                  \n__________________________________________________________________________________________________\nconv2d_8 (Conv2D)               (None, 8, 10, 40)    3880        multiply_1[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_12 (BatchNo (None, 8, 10, 40)    160         conv2d_8[0][0]                   \n__________________________________________________________________________________________________\nconv2d_9 (Conv2D)               (None, 8, 10, 240)   9840        batch_normalization_12[0][0]     \n__________________________________________________________________________________________________\nbatch_normalization_13 (BatchNo (None, 8, 10, 240)   960         conv2d_9[0][0]                   \n__________________________________________________________________________________________________\nactivation_9 (Activation)       (None, 8, 10, 240)   0           batch_normalization_13[0][0]     \n__________________________________________________________________________________________________\ndepthwise_conv2d_4 (DepthwiseCo (None, 8, 10, 240)   6240        activation_9[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_14 (BatchNo (None, 8, 10, 240)   960         depthwise_conv2d_4[0][0]         \n__________________________________________________________________________________________________\nactivation_10 (Activation)      (None, 8, 10, 240)   0           batch_normalization_14[0][0]     \n__________________________________________________________________________________________________\nglobal_average_pooling2d_2 (Glo (None, 240)          0           activation_10[0][0]              \n__________________________________________________________________________________________________\ndense_4 (Dense)                 (None, 240)          57840       global_average_pooling2d_2[0][0] \n__________________________________________________________________________________________________\ndense_5 (Dense)                 (None, 240)          57840       dense_4[0][0]                    \n__________________________________________________________________________________________________\nreshape_2 (Reshape)             (None, 1, 1, 240)    0           dense_5[0][0]                    \n__________________________________________________________________________________________________\nmultiply_2 (Multiply)           (None, 8, 10, 240)   0           activation_10[0][0]              \n                                                                 reshape_2[0][0]                  \n__________________________________________________________________________________________________\nconv2d_10 (Conv2D)              (None, 8, 10, 40)    9640        multiply_2[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_15 (BatchNo (None, 8, 10, 40)    160         conv2d_10[0][0]                  \n__________________________________________________________________________________________________\nadd_1 (Add)                     (None, 8, 10, 40)    0           batch_normalization_15[0][0]     \n                                                                 batch_normalization_12[0][0]     \n__________________________________________________________________________________________________\nconv2d_11 (Conv2D)              (None, 8, 10, 240)   9840        add_1[0][0]                      \n__________________________________________________________________________________________________\nbatch_normalization_16 (BatchNo (None, 8, 10, 240)   960         conv2d_11[0][0]                  \n__________________________________________________________________________________________________\nactivation_11 (Activation)      (None, 8, 10, 240)   0           batch_normalization_16[0][0]     \n__________________________________________________________________________________________________\ndepthwise_conv2d_5 (DepthwiseCo (None, 8, 10, 240)   6240        activation_11[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_17 (BatchNo (None, 8, 10, 240)   960         depthwise_conv2d_5[0][0]         \n__________________________________________________________________________________________________\nactivation_12 (Activation)      (None, 8, 10, 240)   0           batch_normalization_17[0][0]     \n__________________________________________________________________________________________________\nglobal_average_pooling2d_3 (Glo (None, 240)          0           activation_12[0][0]              \n__________________________________________________________________________________________________\ndense_6 (Dense)                 (None, 240)          57840       global_average_pooling2d_3[0][0] \n__________________________________________________________________________________________________\ndense_7 (Dense)                 (None, 240)          57840       dense_6[0][0]                    \n__________________________________________________________________________________________________\nreshape_3 (Reshape)             (None, 1, 1, 240)    0           dense_7[0][0]                    \n__________________________________________________________________________________________________\nmultiply_3 (Multiply)           (None, 8, 10, 240)   0           activation_12[0][0]              \n                                                                 reshape_3[0][0]                  \n__________________________________________________________________________________________________\nconv2d_12 (Conv2D)              (None, 8, 10, 40)    9640        multiply_3[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_18 (BatchNo (None, 8, 10, 40)    160         conv2d_12[0][0]                  \n__________________________________________________________________________________________________\nadd_2 (Add)                     (None, 8, 10, 40)    0           batch_normalization_18[0][0]     \n                                                                 add_1[0][0]                      \n__________________________________________________________________________________________________\nconv2d_13 (Conv2D)              (None, 8, 10, 120)   4920        add_2[0][0]                      \n__________________________________________________________________________________________________\nbatch_normalization_19 (BatchNo (None, 8, 10, 120)   480         conv2d_13[0][0]                  \n__________________________________________________________________________________________________\nactivation_13 (Activation)      (None, 8, 10, 120)   0           batch_normalization_19[0][0]     \n__________________________________________________________________________________________________\ndepthwise_conv2d_6 (DepthwiseCo (None, 8, 10, 120)   3120        activation_13[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_20 (BatchNo (None, 8, 10, 120)   480         depthwise_conv2d_6[0][0]         \n__________________________________________________________________________________________________\nactivation_14 (Activation)      (None, 8, 10, 120)   0           batch_normalization_20[0][0]     \n__________________________________________________________________________________________________\nglobal_average_pooling2d_4 (Glo (None, 120)          0           activation_14[0][0]              \n__________________________________________________________________________________________________\ndense_8 (Dense)                 (None, 120)          14520       global_average_pooling2d_4[0][0] \n__________________________________________________________________________________________________\ndense_9 (Dense)                 (None, 120)          14520       dense_8[0][0]                    \n__________________________________________________________________________________________________\nreshape_4 (Reshape)             (None, 1, 1, 120)    0           dense_9[0][0]                    \n__________________________________________________________________________________________________\nmultiply_4 (Multiply)           (None, 8, 10, 120)   0           activation_14[0][0]              \n                                                                 reshape_4[0][0]                  \n__________________________________________________________________________________________________\nconv2d_14 (Conv2D)              (None, 8, 10, 48)    5808        multiply_4[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_21 (BatchNo (None, 8, 10, 48)    192         conv2d_14[0][0]                  \n__________________________________________________________________________________________________\nconv2d_15 (Conv2D)              (None, 8, 10, 144)   7056        batch_normalization_21[0][0]     \n__________________________________________________________________________________________________\nbatch_normalization_22 (BatchNo (None, 8, 10, 144)   576         conv2d_15[0][0]                  \n__________________________________________________________________________________________________\nactivation_15 (Activation)      (None, 8, 10, 144)   0           batch_normalization_22[0][0]     \n__________________________________________________________________________________________________\ndepthwise_conv2d_7 (DepthwiseCo (None, 8, 10, 144)   3744        activation_15[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_23 (BatchNo (None, 8, 10, 144)   576         depthwise_conv2d_7[0][0]         \n__________________________________________________________________________________________________\nactivation_16 (Activation)      (None, 8, 10, 144)   0           batch_normalization_23[0][0]     \n__________________________________________________________________________________________________\nglobal_average_pooling2d_5 (Glo (None, 144)          0           activation_16[0][0]              \n__________________________________________________________________________________________________\ndense_10 (Dense)                (None, 144)          20880       global_average_pooling2d_5[0][0] \n__________________________________________________________________________________________________\ndense_11 (Dense)                (None, 144)          20880       dense_10[0][0]                   \n__________________________________________________________________________________________________\nreshape_5 (Reshape)             (None, 1, 1, 144)    0           dense_11[0][0]                   \n__________________________________________________________________________________________________\nmultiply_5 (Multiply)           (None, 8, 10, 144)   0           activation_16[0][0]              \n                                                                 reshape_5[0][0]                  \n__________________________________________________________________________________________________\nconv2d_16 (Conv2D)              (None, 8, 10, 48)    6960        multiply_5[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_24 (BatchNo (None, 8, 10, 48)    192         conv2d_16[0][0]                  \n__________________________________________________________________________________________________\nadd_3 (Add)                     (None, 8, 10, 48)    0           batch_normalization_24[0][0]     \n                                                                 batch_normalization_21[0][0]     \n__________________________________________________________________________________________________\nconv2d_17 (Conv2D)              (None, 8, 10, 288)   14112       add_3[0][0]                      \n__________________________________________________________________________________________________\nbatch_normalization_25 (BatchNo (None, 8, 10, 288)   1152        conv2d_17[0][0]                  \n__________________________________________________________________________________________________\nactivation_17 (Activation)      (None, 8, 10, 288)   0           batch_normalization_25[0][0]     \n__________________________________________________________________________________________________\ndepthwise_conv2d_8 (DepthwiseCo (None, 4, 5, 288)    7488        activation_17[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_26 (BatchNo (None, 4, 5, 288)    1152        depthwise_conv2d_8[0][0]         \n__________________________________________________________________________________________________\nactivation_18 (Activation)      (None, 4, 5, 288)    0           batch_normalization_26[0][0]     \n__________________________________________________________________________________________________\nglobal_average_pooling2d_6 (Glo (None, 288)          0           activation_18[0][0]              \n__________________________________________________________________________________________________\ndense_12 (Dense)                (None, 288)          83232       global_average_pooling2d_6[0][0] \n__________________________________________________________________________________________________\ndense_13 (Dense)                (None, 288)          83232       dense_12[0][0]                   \n__________________________________________________________________________________________________\nreshape_6 (Reshape)             (None, 1, 1, 288)    0           dense_13[0][0]                   \n__________________________________________________________________________________________________\nmultiply_6 (Multiply)           (None, 4, 5, 288)    0           activation_18[0][0]              \n                                                                 reshape_6[0][0]                  \n__________________________________________________________________________________________________\nconv2d_18 (Conv2D)              (None, 4, 5, 96)     27744       multiply_6[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_27 (BatchNo (None, 4, 5, 96)     384         conv2d_18[0][0]                  \n__________________________________________________________________________________________________\nconv2d_19 (Conv2D)              (None, 4, 5, 576)    55872       batch_normalization_27[0][0]     \n__________________________________________________________________________________________________\nbatch_normalization_28 (BatchNo (None, 4, 5, 576)    2304        conv2d_19[0][0]                  \n__________________________________________________________________________________________________\nactivation_19 (Activation)      (None, 4, 5, 576)    0           batch_normalization_28[0][0]     \n__________________________________________________________________________________________________\ndepthwise_conv2d_9 (DepthwiseCo (None, 4, 5, 576)    14976       activation_19[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_29 (BatchNo (None, 4, 5, 576)    2304        depthwise_conv2d_9[0][0]         \n__________________________________________________________________________________________________\nactivation_20 (Activation)      (None, 4, 5, 576)    0           batch_normalization_29[0][0]     \n__________________________________________________________________________________________________\nglobal_average_pooling2d_7 (Glo (None, 576)          0           activation_20[0][0]              \n__________________________________________________________________________________________________\ndense_14 (Dense)                (None, 576)          332352      global_average_pooling2d_7[0][0] \n__________________________________________________________________________________________________\ndense_15 (Dense)                (None, 576)          332352      dense_14[0][0]                   \n__________________________________________________________________________________________________\nreshape_7 (Reshape)             (None, 1, 1, 576)    0           dense_15[0][0]                   \n__________________________________________________________________________________________________\nmultiply_7 (Multiply)           (None, 4, 5, 576)    0           activation_20[0][0]              \n                                                                 reshape_7[0][0]                  \n__________________________________________________________________________________________________\nconv2d_20 (Conv2D)              (None, 4, 5, 96)     55392       multiply_7[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_30 (BatchNo (None, 4, 5, 96)     384         conv2d_20[0][0]                  \n__________________________________________________________________________________________________\nadd_4 (Add)                     (None, 4, 5, 96)     0           batch_normalization_30[0][0]     \n                                                                 batch_normalization_27[0][0]     \n__________________________________________________________________________________________________\nconv2d_21 (Conv2D)              (None, 4, 5, 576)    55872       add_4[0][0]                      \n__________________________________________________________________________________________________\nbatch_normalization_31 (BatchNo (None, 4, 5, 576)    2304        conv2d_21[0][0]                  \n__________________________________________________________________________________________________\nactivation_21 (Activation)      (None, 4, 5, 576)    0           batch_normalization_31[0][0]     \n__________________________________________________________________________________________________\ndepthwise_conv2d_10 (DepthwiseC (None, 4, 5, 576)    14976       activation_21[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_32 (BatchNo (None, 4, 5, 576)    2304        depthwise_conv2d_10[0][0]        \n__________________________________________________________________________________________________\nactivation_22 (Activation)      (None, 4, 5, 576)    0           batch_normalization_32[0][0]     \n__________________________________________________________________________________________________\nglobal_average_pooling2d_8 (Glo (None, 576)          0           activation_22[0][0]              \n__________________________________________________________________________________________________\ndense_16 (Dense)                (None, 576)          332352      global_average_pooling2d_8[0][0] \n__________________________________________________________________________________________________\ndense_17 (Dense)                (None, 576)          332352      dense_16[0][0]                   \n__________________________________________________________________________________________________\nreshape_8 (Reshape)             (None, 1, 1, 576)    0           dense_17[0][0]                   \n__________________________________________________________________________________________________\nmultiply_8 (Multiply)           (None, 4, 5, 576)    0           activation_22[0][0]              \n                                                                 reshape_8[0][0]                  \n__________________________________________________________________________________________________\nconv2d_22 (Conv2D)              (None, 4, 5, 96)     55392       multiply_8[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_33 (BatchNo (None, 4, 5, 96)     384         conv2d_22[0][0]                  \n__________________________________________________________________________________________________\nadd_5 (Add)                     (None, 4, 5, 96)     0           batch_normalization_33[0][0]     \n                                                                 add_4[0][0]                      \n__________________________________________________________________________________________________\nglobal_average_pooling2d_9 (Glo (None, 96)           0           add_5[0][0]                      \n__________________________________________________________________________________________________\ndropout (Dropout)               (None, 96)           0           global_average_pooling2d_9[0][0] \n__________________________________________________________________________________________________\ndense_18 (Dense)                (None, 2)            194         dropout[0][0]                    \n==================================================================================================\nTotal params: 2,243,090\nTrainable params: 2,232,098\nNon-trainable params: 10,992\n__________________________________________________________________________________________________\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Model: &#34;model&#34;\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            [(None, 120, 160, 3) 0                                            \n__________________________________________________________________________________________________\nconv2d (Conv2D)                 (None, 60, 80, 16)   448         input_1[0][0]                    \n__________________________________________________________________________________________________\nbatch_normalization (BatchNorma (None, 60, 80, 16)   64          conv2d[0][0]                     \n__________________________________________________________________________________________________\nactivation (Activation)         (None, 60, 80, 16)   0           batch_normalization[0][0]        \n__________________________________________________________________________________________________\nconv2d_1 (Conv2D)               (None, 60, 80, 16)   272         activation[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_1 (BatchNor (None, 60, 80, 16)   64          conv2d_1[0][0]                   \n__________________________________________________________________________________________________\nactivation_1 (Activation)       (None, 60, 80, 16)   0           batch_normalization_1[0][0]      \n__________________________________________________________________________________________________\ndepthwise_conv2d (DepthwiseConv (None, 30, 40, 16)   160         activation_1[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_2 (BatchNor (None, 30, 40, 16)   64          depthwise_conv2d[0][0]           \n__________________________________________________________________________________________________\nactivation_2 (Activation)       (None, 30, 40, 16)   0           batch_normalization_2[0][0]      \n__________________________________________________________________________________________________\nglobal_average_pooling2d (Globa (None, 16)           0           activation_2[0][0]               \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 16)           272         global_average_pooling2d[0][0]   \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 16)           272         dense[0][0]                      \n__________________________________________________________________________________________________\nreshape (Reshape)               (None, 1, 1, 16)     0           dense_1[0][0]                    \n__________________________________________________________________________________________________\nmultiply (Multiply)             (None, 30, 40, 16)   0           activation_2[0][0]               \n                                                                 reshape[0][0]                    \n__________________________________________________________________________________________________\nconv2d_2 (Conv2D)               (None, 30, 40, 16)   272         multiply[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_3 (BatchNor (None, 30, 40, 16)   64          conv2d_2[0][0]                   \n__________________________________________________________________________________________________\nconv2d_3 (Conv2D)               (None, 30, 40, 72)   1224        batch_normalization_3[0][0]      \n__________________________________________________________________________________________________\nbatch_normalization_4 (BatchNor (None, 30, 40, 72)   288         conv2d_3[0][0]                   \n__________________________________________________________________________________________________\nactivation_3 (Activation)       (None, 30, 40, 72)   0           batch_normalization_4[0][0]      \n__________________________________________________________________________________________________\ndepthwise_conv2d_1 (DepthwiseCo (None, 15, 20, 72)   720         activation_3[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_5 (BatchNor (None, 15, 20, 72)   288         depthwise_conv2d_1[0][0]         \n__________________________________________________________________________________________________\nactivation_4 (Activation)       (None, 15, 20, 72)   0           batch_normalization_5[0][0]      \n__________________________________________________________________________________________________\nconv2d_4 (Conv2D)               (None, 15, 20, 24)   1752        activation_4[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_6 (BatchNor (None, 15, 20, 24)   96          conv2d_4[0][0]                   \n__________________________________________________________________________________________________\nconv2d_5 (Conv2D)               (None, 15, 20, 88)   2200        batch_normalization_6[0][0]      \n__________________________________________________________________________________________________\nbatch_normalization_7 (BatchNor (None, 15, 20, 88)   352         conv2d_5[0][0]                   \n__________________________________________________________________________________________________\nactivation_5 (Activation)       (None, 15, 20, 88)   0           batch_normalization_7[0][0]      \n__________________________________________________________________________________________________\ndepthwise_conv2d_2 (DepthwiseCo (None, 15, 20, 88)   880         activation_5[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_8 (BatchNor (None, 15, 20, 88)   352         depthwise_conv2d_2[0][0]         \n__________________________________________________________________________________________________\nactivation_6 (Activation)       (None, 15, 20, 88)   0           batch_normalization_8[0][0]      \n__________________________________________________________________________________________________\nconv2d_6 (Conv2D)               (None, 15, 20, 24)   2136        activation_6[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_9 (BatchNor (None, 15, 20, 24)   96          conv2d_6[0][0]                   \n__________________________________________________________________________________________________\nadd (Add)                       (None, 15, 20, 24)   0           batch_normalization_9[0][0]      \n                                                                 batch_normalization_6[0][0]      \n__________________________________________________________________________________________________\nconv2d_7 (Conv2D)               (None, 15, 20, 96)   2400        add[0][0]                        \n__________________________________________________________________________________________________\nbatch_normalization_10 (BatchNo (None, 15, 20, 96)   384         conv2d_7[0][0]                   \n__________________________________________________________________________________________________\nactivation_7 (Activation)       (None, 15, 20, 96)   0           batch_normalization_10[0][0]     \n__________________________________________________________________________________________________\ndepthwise_conv2d_3 (DepthwiseCo (None, 8, 10, 96)    2496        activation_7[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_11 (BatchNo (None, 8, 10, 96)    384         depthwise_conv2d_3[0][0]         \n__________________________________________________________________________________________________\nactivation_8 (Activation)       (None, 8, 10, 96)    0           batch_normalization_11[0][0]     \n__________________________________________________________________________________________________\nglobal_average_pooling2d_1 (Glo (None, 96)           0           activation_8[0][0]               \n__________________________________________________________________________________________________\ndense_2 (Dense)                 (None, 96)           9312        global_average_pooling2d_1[0][0] \n__________________________________________________________________________________________________\ndense_3 (Dense)                 (None, 96)           9312        dense_2[0][0]                    \n__________________________________________________________________________________________________\nreshape_1 (Reshape)             (None, 1, 1, 96)     0           dense_3[0][0]                    \n__________________________________________________________________________________________________\nmultiply_1 (Multiply)           (None, 8, 10, 96)    0           activation_8[0][0]               \n                                                                 reshape_1[0][0]                  \n__________________________________________________________________________________________________\nconv2d_8 (Conv2D)               (None, 8, 10, 40)    3880        multiply_1[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_12 (BatchNo (None, 8, 10, 40)    160         conv2d_8[0][0]                   \n__________________________________________________________________________________________________\nconv2d_9 (Conv2D)               (None, 8, 10, 240)   9840        batch_normalization_12[0][0]     \n__________________________________________________________________________________________________\nbatch_normalization_13 (BatchNo (None, 8, 10, 240)   960         conv2d_9[0][0]                   \n__________________________________________________________________________________________________\nactivation_9 (Activation)       (None, 8, 10, 240)   0           batch_normalization_13[0][0]     \n__________________________________________________________________________________________________\ndepthwise_conv2d_4 (DepthwiseCo (None, 8, 10, 240)   6240        activation_9[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_14 (BatchNo (None, 8, 10, 240)   960         depthwise_conv2d_4[0][0]         \n__________________________________________________________________________________________________\nactivation_10 (Activation)      (None, 8, 10, 240)   0           batch_normalization_14[0][0]     \n__________________________________________________________________________________________________\nglobal_average_pooling2d_2 (Glo (None, 240)          0           activation_10[0][0]              \n__________________________________________________________________________________________________\ndense_4 (Dense)                 (None, 240)          57840       global_average_pooling2d_2[0][0] \n__________________________________________________________________________________________________\ndense_5 (Dense)                 (None, 240)          57840       dense_4[0][0]                    \n__________________________________________________________________________________________________\nreshape_2 (Reshape)             (None, 1, 1, 240)    0           dense_5[0][0]                    \n__________________________________________________________________________________________________\nmultiply_2 (Multiply)           (None, 8, 10, 240)   0           activation_10[0][0]              \n                                                                 reshape_2[0][0]                  \n__________________________________________________________________________________________________\nconv2d_10 (Conv2D)              (None, 8, 10, 40)    9640        multiply_2[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_15 (BatchNo (None, 8, 10, 40)    160         conv2d_10[0][0]                  \n__________________________________________________________________________________________________\nadd_1 (Add)                     (None, 8, 10, 40)    0           batch_normalization_15[0][0]     \n                                                                 batch_normalization_12[0][0]     \n__________________________________________________________________________________________________\nconv2d_11 (Conv2D)              (None, 8, 10, 240)   9840        add_1[0][0]                      \n__________________________________________________________________________________________________\nbatch_normalization_16 (BatchNo (None, 8, 10, 240)   960         conv2d_11[0][0]                  \n__________________________________________________________________________________________________\nactivation_11 (Activation)      (None, 8, 10, 240)   0           batch_normalization_16[0][0]     \n__________________________________________________________________________________________________\ndepthwise_conv2d_5 (DepthwiseCo (None, 8, 10, 240)   6240        activation_11[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_17 (BatchNo (None, 8, 10, 240)   960         depthwise_conv2d_5[0][0]         \n__________________________________________________________________________________________________\nactivation_12 (Activation)      (None, 8, 10, 240)   0           batch_normalization_17[0][0]     \n__________________________________________________________________________________________________\nglobal_average_pooling2d_3 (Glo (None, 240)          0           activation_12[0][0]              \n__________________________________________________________________________________________________\ndense_6 (Dense)                 (None, 240)          57840       global_average_pooling2d_3[0][0] \n__________________________________________________________________________________________________\ndense_7 (Dense)                 (None, 240)          57840       dense_6[0][0]                    \n__________________________________________________________________________________________________\nreshape_3 (Reshape)             (None, 1, 1, 240)    0           dense_7[0][0]                    \n__________________________________________________________________________________________________\nmultiply_3 (Multiply)           (None, 8, 10, 240)   0           activation_12[0][0]              \n                                                                 reshape_3[0][0]                  \n__________________________________________________________________________________________________\nconv2d_12 (Conv2D)              (None, 8, 10, 40)    9640        multiply_3[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_18 (BatchNo (None, 8, 10, 40)    160         conv2d_12[0][0]                  \n__________________________________________________________________________________________________\nadd_2 (Add)                     (None, 8, 10, 40)    0           batch_normalization_18[0][0]     \n                                                                 add_1[0][0]                      \n__________________________________________________________________________________________________\nconv2d_13 (Conv2D)              (None, 8, 10, 120)   4920        add_2[0][0]                      \n__________________________________________________________________________________________________\nbatch_normalization_19 (BatchNo (None, 8, 10, 120)   480         conv2d_13[0][0]                  \n__________________________________________________________________________________________________\nactivation_13 (Activation)      (None, 8, 10, 120)   0           batch_normalization_19[0][0]     \n__________________________________________________________________________________________________\ndepthwise_conv2d_6 (DepthwiseCo (None, 8, 10, 120)   3120        activation_13[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_20 (BatchNo (None, 8, 10, 120)   480         depthwise_conv2d_6[0][0]         \n__________________________________________________________________________________________________\nactivation_14 (Activation)      (None, 8, 10, 120)   0           batch_normalization_20[0][0]     \n__________________________________________________________________________________________________\nglobal_average_pooling2d_4 (Glo (None, 120)          0           activation_14[0][0]              \n__________________________________________________________________________________________________\ndense_8 (Dense)                 (None, 120)          14520       global_average_pooling2d_4[0][0] \n__________________________________________________________________________________________________\ndense_9 (Dense)                 (None, 120)          14520       dense_8[0][0]                    \n__________________________________________________________________________________________________\nreshape_4 (Reshape)             (None, 1, 1, 120)    0           dense_9[0][0]                    \n__________________________________________________________________________________________________\nmultiply_4 (Multiply)           (None, 8, 10, 120)   0           activation_14[0][0]              \n                                                                 reshape_4[0][0]                  \n__________________________________________________________________________________________________\nconv2d_14 (Conv2D)              (None, 8, 10, 48)    5808        multiply_4[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_21 (BatchNo (None, 8, 10, 48)    192         conv2d_14[0][0]                  \n__________________________________________________________________________________________________\nconv2d_15 (Conv2D)              (None, 8, 10, 144)   7056        batch_normalization_21[0][0]     \n__________________________________________________________________________________________________\nbatch_normalization_22 (BatchNo (None, 8, 10, 144)   576         conv2d_15[0][0]                  \n__________________________________________________________________________________________________\nactivation_15 (Activation)      (None, 8, 10, 144)   0           batch_normalization_22[0][0]     \n__________________________________________________________________________________________________\ndepthwise_conv2d_7 (DepthwiseCo (None, 8, 10, 144)   3744        activation_15[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_23 (BatchNo (None, 8, 10, 144)   576         depthwise_conv2d_7[0][0]         \n__________________________________________________________________________________________________\nactivation_16 (Activation)      (None, 8, 10, 144)   0           batch_normalization_23[0][0]     \n__________________________________________________________________________________________________\nglobal_average_pooling2d_5 (Glo (None, 144)          0           activation_16[0][0]              \n__________________________________________________________________________________________________\ndense_10 (Dense)                (None, 144)          20880       global_average_pooling2d_5[0][0] \n__________________________________________________________________________________________________\ndense_11 (Dense)                (None, 144)          20880       dense_10[0][0]                   \n__________________________________________________________________________________________________\nreshape_5 (Reshape)             (None, 1, 1, 144)    0           dense_11[0][0]                   \n__________________________________________________________________________________________________\nmultiply_5 (Multiply)           (None, 8, 10, 144)   0           activation_16[0][0]              \n                                                                 reshape_5[0][0]                  \n__________________________________________________________________________________________________\nconv2d_16 (Conv2D)              (None, 8, 10, 48)    6960        multiply_5[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_24 (BatchNo (None, 8, 10, 48)    192         conv2d_16[0][0]                  \n__________________________________________________________________________________________________\nadd_3 (Add)                     (None, 8, 10, 48)    0           batch_normalization_24[0][0]     \n                                                                 batch_normalization_21[0][0]     \n__________________________________________________________________________________________________\nconv2d_17 (Conv2D)              (None, 8, 10, 288)   14112       add_3[0][0]                      \n__________________________________________________________________________________________________\nbatch_normalization_25 (BatchNo (None, 8, 10, 288)   1152        conv2d_17[0][0]                  \n__________________________________________________________________________________________________\nactivation_17 (Activation)      (None, 8, 10, 288)   0           batch_normalization_25[0][0]     \n__________________________________________________________________________________________________\ndepthwise_conv2d_8 (DepthwiseCo (None, 4, 5, 288)    7488        activation_17[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_26 (BatchNo (None, 4, 5, 288)    1152        depthwise_conv2d_8[0][0]         \n__________________________________________________________________________________________________\nactivation_18 (Activation)      (None, 4, 5, 288)    0           batch_normalization_26[0][0]     \n__________________________________________________________________________________________________\nglobal_average_pooling2d_6 (Glo (None, 288)          0           activation_18[0][0]              \n__________________________________________________________________________________________________\ndense_12 (Dense)                (None, 288)          83232       global_average_pooling2d_6[0][0] \n__________________________________________________________________________________________________\ndense_13 (Dense)                (None, 288)          83232       dense_12[0][0]                   \n__________________________________________________________________________________________________\nreshape_6 (Reshape)             (None, 1, 1, 288)    0           dense_13[0][0]                   \n__________________________________________________________________________________________________\nmultiply_6 (Multiply)           (None, 4, 5, 288)    0           activation_18[0][0]              \n                                                                 reshape_6[0][0]                  \n__________________________________________________________________________________________________\nconv2d_18 (Conv2D)              (None, 4, 5, 96)     27744       multiply_6[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_27 (BatchNo (None, 4, 5, 96)     384         conv2d_18[0][0]                  \n__________________________________________________________________________________________________\nconv2d_19 (Conv2D)              (None, 4, 5, 576)    55872       batch_normalization_27[0][0]     \n__________________________________________________________________________________________________\nbatch_normalization_28 (BatchNo (None, 4, 5, 576)    2304        conv2d_19[0][0]                  \n__________________________________________________________________________________________________\nactivation_19 (Activation)      (None, 4, 5, 576)    0           batch_normalization_28[0][0]     \n__________________________________________________________________________________________________\ndepthwise_conv2d_9 (DepthwiseCo (None, 4, 5, 576)    14976       activation_19[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_29 (BatchNo (None, 4, 5, 576)    2304        depthwise_conv2d_9[0][0]         \n__________________________________________________________________________________________________\nactivation_20 (Activation)      (None, 4, 5, 576)    0           batch_normalization_29[0][0]     \n__________________________________________________________________________________________________\nglobal_average_pooling2d_7 (Glo (None, 576)          0           activation_20[0][0]              \n__________________________________________________________________________________________________\ndense_14 (Dense)                (None, 576)          332352      global_average_pooling2d_7[0][0] \n__________________________________________________________________________________________________\ndense_15 (Dense)                (None, 576)          332352      dense_14[0][0]                   \n__________________________________________________________________________________________________\nreshape_7 (Reshape)             (None, 1, 1, 576)    0           dense_15[0][0]                   \n__________________________________________________________________________________________________\nmultiply_7 (Multiply)           (None, 4, 5, 576)    0           activation_20[0][0]              \n                                                                 reshape_7[0][0]                  \n__________________________________________________________________________________________________\nconv2d_20 (Conv2D)              (None, 4, 5, 96)     55392       multiply_7[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_30 (BatchNo (None, 4, 5, 96)     384         conv2d_20[0][0]                  \n__________________________________________________________________________________________________\nadd_4 (Add)                     (None, 4, 5, 96)     0           batch_normalization_30[0][0]     \n                                                                 batch_normalization_27[0][0]     \n__________________________________________________________________________________________________\nconv2d_21 (Conv2D)              (None, 4, 5, 576)    55872       add_4[0][0]                      \n__________________________________________________________________________________________________\nbatch_normalization_31 (BatchNo (None, 4, 5, 576)    2304        conv2d_21[0][0]                  \n__________________________________________________________________________________________________\nactivation_21 (Activation)      (None, 4, 5, 576)    0           batch_normalization_31[0][0]     \n__________________________________________________________________________________________________\ndepthwise_conv2d_10 (DepthwiseC (None, 4, 5, 576)    14976       activation_21[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_32 (BatchNo (None, 4, 5, 576)    2304        depthwise_conv2d_10[0][0]        \n__________________________________________________________________________________________________\nactivation_22 (Activation)      (None, 4, 5, 576)    0           batch_normalization_32[0][0]     \n__________________________________________________________________________________________________\nglobal_average_pooling2d_8 (Glo (None, 576)          0           activation_22[0][0]              \n__________________________________________________________________________________________________\ndense_16 (Dense)                (None, 576)          332352      global_average_pooling2d_8[0][0] \n__________________________________________________________________________________________________\ndense_17 (Dense)                (None, 576)          332352      dense_16[0][0]                   \n__________________________________________________________________________________________________\nreshape_8 (Reshape)             (None, 1, 1, 576)    0           dense_17[0][0]                   \n__________________________________________________________________________________________________\nmultiply_8 (Multiply)           (None, 4, 5, 576)    0           activation_22[0][0]              \n                                                                 reshape_8[0][0]                  \n__________________________________________________________________________________________________\nconv2d_22 (Conv2D)              (None, 4, 5, 96)     55392       multiply_8[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_33 (BatchNo (None, 4, 5, 96)     384         conv2d_22[0][0]                  \n__________________________________________________________________________________________________\nadd_5 (Add)                     (None, 4, 5, 96)     0           batch_normalization_33[0][0]     \n                                                                 add_4[0][0]                      \n__________________________________________________________________________________________________\nglobal_average_pooling2d_9 (Glo (None, 96)           0           add_5[0][0]                      \n__________________________________________________________________________________________________\ndropout (Dropout)               (None, 96)           0           global_average_pooling2d_9[0][0] \n__________________________________________________________________________________________________\ndense_18 (Dense)                (None, 2)            194         dropout[0][0]                    \n==================================================================================================\nTotal params: 2,243,090\nTrainable params: 2,232,098\nNon-trainable params: 10,992\n__________________________________________________________________________________________________\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["def get_compiled_model(alpha=1.0, lr=0.001):\n    model = MobileNetv3_small(shape = (img_height, img_width, 3))\n    \n    model.compile(\n                optimizer=tf.keras.optimizers.SGD(learning_rate=lr, momentum=0.9),\n                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n                metrics=['accuracy'])\n    return model"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"efb76772-5ba0-4868-9d28-45bd917b4836"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["def train_and_evaluate(train_ds, val_ds=None, lr=0.001):\n    model = get_compiled_model()\n#     model = get_compiled_model_2()\n\n    \n#     model.save_weights(checkpoint_path.format(epoch=0))\n\n    # 创建一个保存模型权重的回调\n    cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n                                                     save_weights_only= False,\n                                                     save_best_only = True,\n                                                     monitor='accuracy',\n                                                     mode='auto', \n                                                     save_freq='epoch',\n                                                     verbose=1)\n    early_stop = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=10)\n    board_callback = tf.keras.callbacks.TensorBoard(\n        log_dir=log_dir,\n        histogram_freq=0,  # How often to log histogram visualizations\n        embeddings_freq=0,  # How often to log embedding visualizations\n        update_freq=\"epoch\",\n    )  # How often to write logs (default: once per epoch)\n    \n#     steps_per_epoch = len(train_ds) // batch_size\n    hist = model.fit(train_ds, \n#                      steps_per_epoch=steps_per_epoch,\n                     epochs=NUM_EPOCHS,\n                     validation_data=val_ds,\n#                      class_weight={0:0.3, 1:0.7},\n#                      validation_steps=validation_steps,\n                     verbose=2,\n                     callbacks=[\n                       cp_callback, \n#                        board_callback, \n                       early_stop,\n#                        CustomLearningRateScheduler(lr_schedule),\n                     ])\n#     model.save('saved_model/my_model')\n    return hist,model"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"36b6f893-7f0c-41ec-b049-985d42543ba7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["gpus = tf.config.experimental.list_physical_devices('GPU')\nprint(gpus)\nif gpus:\n  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n  try:\n    for gpu in gpus:\n#       tf.config.experimental.set_memory_growth(gpu, True)\n      print('yes')\n#     tf.config.experimental.set_virtual_device_configuration(\n#         gpus[0],\n#         [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])\n    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n  except RuntimeError as e:\n    # Virtual devices must be set before GPUs have been initialized\n    print(e)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4e02e922-b7c8-4368-af37-78a199f4b31c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">[PhysicalDevice(name=&#39;/physical_device:GPU:0&#39;, device_type=&#39;GPU&#39;), PhysicalDevice(name=&#39;/physical_device:GPU:1&#39;, device_type=&#39;GPU&#39;)]\nyes\nyes\n2 Physical GPUs, 2 Logical GPUs\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[PhysicalDevice(name=&#39;/physical_device:GPU:0&#39;, device_type=&#39;GPU&#39;), PhysicalDevice(name=&#39;/physical_device:GPU:1&#39;, device_type=&#39;GPU&#39;)]\nyes\nyes\n2 Physical GPUs, 2 Logical GPUs\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["tf.debugging.set_log_device_placement(True)\nstrategy = tf.distribute.MirroredStrategy()\nwith strategy.scope():\n  hist,model = train_and_evaluate(train_ds,val_ds)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d82f6f97-cdd4-41dc-afec-12b0b69e0a34"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">INFO:tensorflow:Using MirroredStrategy with devices (&#39;/job:localhost/replica:0/task:0/device:GPU:0&#39;, &#39;/job:localhost/replica:0/task:0/device:GPU:1&#39;)\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to (&#39;/job:localhost/replica:0/task:0/device:CPU:0&#39;,).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to (&#39;/job:localhost/replica:0/task:0/device:CPU:0&#39;,).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to (&#39;/job:localhost/replica:0/task:0/device:CPU:0&#39;,).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to (&#39;/job:localhost/replica:0/task:0/device:CPU:0&#39;,).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to (&#39;/job:localhost/replica:0/task:0/device:CPU:0&#39;,).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to (&#39;/job:localhost/replica:0/task:0/device:CPU:0&#39;,).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to (&#39;/job:localhost/replica:0/task:0/device:CPU:0&#39;,).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to (&#39;/job:localhost/replica:0/task:0/device:CPU:0&#39;,).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to (&#39;/job:localhost/replica:0/task:0/device:CPU:0&#39;,).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to (&#39;/job:localhost/replica:0/task:0/device:CPU:0&#39;,).\nEpoch 1/400\nINFO:tensorflow:batch_all_reduce: 174 all-reduces with algorithm = nccl, num_packs = 1\nINFO:tensorflow:batch_all_reduce: 174 all-reduces with algorithm = nccl, num_packs = 1\n280/280 - 408s - loss: 0.7311 - accuracy: 0.5659 - val_loss: 0.7034 - val_accuracy: 0.4754\n\nEpoch 00001: accuracy improved from -inf to 0.56589, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 2/400\n280/280 - 41s - loss: 0.5971 - accuracy: 0.6792 - val_loss: 0.6396 - val_accuracy: 0.7065\n\nEpoch 00002: accuracy improved from 0.56589 to 0.67921, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 3/400\n280/280 - 41s - loss: 0.5227 - accuracy: 0.7440 - val_loss: 0.5002 - val_accuracy: 0.7558\n\nEpoch 00003: accuracy improved from 0.67921 to 0.74404, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 4/400\n280/280 - 41s - loss: 0.4674 - accuracy: 0.7766 - val_loss: 0.4035 - val_accuracy: 0.8203\n\nEpoch 00004: accuracy improved from 0.74404 to 0.77662, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 5/400\n280/280 - 41s - loss: 0.4140 - accuracy: 0.8133 - val_loss: 0.3962 - val_accuracy: 0.8244\n\nEpoch 00005: accuracy improved from 0.77662 to 0.81335, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 6/400\n280/280 - 41s - loss: 0.3862 - accuracy: 0.8322 - val_loss: 0.3240 - val_accuracy: 0.8634\n\nEpoch 00006: accuracy improved from 0.81335 to 0.83216, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 7/400\n280/280 - 42s - loss: 0.3575 - accuracy: 0.8420 - val_loss: 0.3453 - val_accuracy: 0.8481\n\nEpoch 00007: accuracy improved from 0.83216 to 0.84201, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 8/400\n280/280 - 43s - loss: 0.3268 - accuracy: 0.8609 - val_loss: 0.2997 - val_accuracy: 0.8710\n\nEpoch 00008: accuracy improved from 0.84201 to 0.86093, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 9/400\n280/280 - 43s - loss: 0.3181 - accuracy: 0.8625 - val_loss: 0.4008 - val_accuracy: 0.8329\n\nEpoch 00009: accuracy improved from 0.86093 to 0.86250, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 10/400\n280/280 - 43s - loss: 0.2939 - accuracy: 0.8775 - val_loss: 0.2474 - val_accuracy: 0.9005\n\nEpoch 00010: accuracy improved from 0.86250 to 0.87751, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 11/400\n280/280 - 42s - loss: 0.2848 - accuracy: 0.8827 - val_loss: 0.2787 - val_accuracy: 0.8875\n\nEpoch 00011: accuracy improved from 0.87751 to 0.88266, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 12/400\n280/280 - 43s - loss: 0.2652 - accuracy: 0.8897 - val_loss: 0.2968 - val_accuracy: 0.8674\n\nEpoch 00012: accuracy improved from 0.88266 to 0.88971, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 13/400\n280/280 - 43s - loss: 0.2627 - accuracy: 0.8939 - val_loss: 0.2284 - val_accuracy: 0.9095\n\nEpoch 00013: accuracy improved from 0.88971 to 0.89385, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 14/400\n280/280 - 43s - loss: 0.2495 - accuracy: 0.8993 - val_loss: 0.2256 - val_accuracy: 0.9082\n\nEpoch 00014: accuracy improved from 0.89385 to 0.89934, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 15/400\n280/280 - 43s - loss: 0.2426 - accuracy: 0.9034 - val_loss: 0.2428 - val_accuracy: 0.9055\n\nEpoch 00015: accuracy improved from 0.89934 to 0.90337, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 16/400\n280/280 - 43s - loss: 0.2339 - accuracy: 0.9113 - val_loss: 0.3205 - val_accuracy: 0.8584\n\nEpoch 00016: accuracy improved from 0.90337 to 0.91132, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 17/400\n280/280 - 43s - loss: 0.2204 - accuracy: 0.9137 - val_loss: 0.2283 - val_accuracy: 0.9144\n\nEpoch 00017: accuracy improved from 0.91132 to 0.91367, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 18/400\n280/280 - 42s - loss: 0.2141 - accuracy: 0.9156 - val_loss: 0.1982 - val_accuracy: 0.9283\n\nEpoch 00018: accuracy improved from 0.91367 to 0.91557, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 19/400\n280/280 - 43s - loss: 0.2065 - accuracy: 0.9159 - val_loss: 0.2016 - val_accuracy: 0.9247\n\nEpoch 00019: accuracy improved from 0.91557 to 0.91591, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 20/400\n280/280 - 42s - loss: 0.1942 - accuracy: 0.9209 - val_loss: 0.1974 - val_accuracy: 0.9247\n\nEpoch 00020: accuracy improved from 0.91591 to 0.92095, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 21/400\n280/280 - 41s - loss: 0.1968 - accuracy: 0.9231 - val_loss: 0.3122 - val_accuracy: 0.8392\n\nEpoch 00021: accuracy improved from 0.92095 to 0.92308, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 22/400\n280/280 - 41s - loss: 0.1913 - accuracy: 0.9274 - val_loss: 0.2017 - val_accuracy: 0.9144\n\nEpoch 00022: accuracy improved from 0.92308 to 0.92744, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 23/400\n280/280 - 41s - loss: 0.1858 - accuracy: 0.9271 - val_loss: 0.1894 - val_accuracy: 0.9319\n\nEpoch 00023: accuracy did not improve from 0.92744\nEpoch 24/400\n280/280 - 41s - loss: 0.1876 - accuracy: 0.9278 - val_loss: 0.1996 - val_accuracy: 0.9225\n\nEpoch 00024: accuracy improved from 0.92744 to 0.92778, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 25/400\n280/280 - 41s - loss: 0.1765 - accuracy: 0.9301 - val_loss: 0.1711 - val_accuracy: 0.9315\n\nEpoch 00025: accuracy improved from 0.92778 to 0.93013, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 26/400\n280/280 - 41s - loss: 0.1817 - accuracy: 0.9300 - val_loss: 0.1572 - val_accuracy: 0.9350\n\nEpoch 00026: accuracy did not improve from 0.93013\nEpoch 27/400\n280/280 - 41s - loss: 0.1703 - accuracy: 0.9357 - val_loss: 0.1591 - val_accuracy: 0.9449\n\nEpoch 00027: accuracy improved from 0.93013 to 0.93573, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 28/400\n280/280 - 41s - loss: 0.1661 - accuracy: 0.9355 - val_loss: 0.1616 - val_accuracy: 0.9377\n\nEpoch 00028: accuracy did not improve from 0.93573\nEpoch 29/400\n280/280 - 41s - loss: 0.1603 - accuracy: 0.9388 - val_loss: 0.1605 - val_accuracy: 0.9409\n\nEpoch 00029: accuracy improved from 0.93573 to 0.93875, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 30/400\n280/280 - 42s - loss: 0.1591 - accuracy: 0.9366 - val_loss: 0.1434 - val_accuracy: 0.9458\n\nEpoch 00030: accuracy did not improve from 0.93875\nEpoch 31/400\n280/280 - 41s - loss: 0.1587 - accuracy: 0.9367 - val_loss: 0.1224 - val_accuracy: 0.9561\n\nEpoch 00031: accuracy did not improve from 0.93875\nEpoch 32/400\n280/280 - 41s - loss: 0.1511 - accuracy: 0.9429 - val_loss: 0.1412 - val_accuracy: 0.9467\n\nEpoch 00032: accuracy improved from 0.93875 to 0.94290, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 33/400\n280/280 - 41s - loss: 0.1498 - accuracy: 0.9435 - val_loss: 0.1774 - val_accuracy: 0.9364\n\nEpoch 00033: accuracy improved from 0.94290 to 0.94346, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 34/400\n280/280 - 41s - loss: 0.1442 - accuracy: 0.9424 - val_loss: 0.1611 - val_accuracy: 0.9368\n\nEpoch 00034: accuracy did not improve from 0.94346\nEpoch 35/400\n280/280 - 41s - loss: 0.1467 - accuracy: 0.9446 - val_loss: 0.1534 - val_accuracy: 0.9418\n\nEpoch 00035: accuracy improved from 0.94346 to 0.94458, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 36/400\n280/280 - 41s - loss: 0.1391 - accuracy: 0.9470 - val_loss: 0.1294 - val_accuracy: 0.9530\n\nEpoch 00036: accuracy improved from 0.94458 to 0.94704, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 37/400\n280/280 - 41s - loss: 0.1310 - accuracy: 0.9514 - val_loss: 0.2039 - val_accuracy: 0.9270\n\nEpoch 00037: accuracy improved from 0.94704 to 0.95141, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 38/400\n280/280 - 41s - loss: 0.1336 - accuracy: 0.9493 - val_loss: 0.1272 - val_accuracy: 0.9503\n\nEpoch 00038: accuracy did not improve from 0.95141\nEpoch 39/400\n280/280 - 41s - loss: 0.1367 - accuracy: 0.9491 - val_loss: 0.1155 - val_accuracy: 0.9565\n\nEpoch 00039: accuracy did not improve from 0.95141\nEpoch 40/400\n280/280 - 41s - loss: 0.1249 - accuracy: 0.9545 - val_loss: 0.1409 - val_accuracy: 0.9467\n\nEpoch 00040: accuracy improved from 0.95141 to 0.95454, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 41/400\n280/280 - 41s - loss: 0.1326 - accuracy: 0.9488 - val_loss: 0.1428 - val_accuracy: 0.9427\n\nEpoch 00041: accuracy did not improve from 0.95454\nEpoch 42/400\n280/280 - 41s - loss: 0.1317 - accuracy: 0.9492 - val_loss: 0.1117 - val_accuracy: 0.9565\n\nEpoch 00042: accuracy did not improve from 0.95454\nEpoch 43/400\n280/280 - 41s - loss: 0.1249 - accuracy: 0.9536 - val_loss: 0.1166 - val_accuracy: 0.9592\n\nEpoch 00043: accuracy did not improve from 0.95454\nEpoch 44/400\n280/280 - 41s - loss: 0.1159 - accuracy: 0.9579 - val_loss: 0.1182 - val_accuracy: 0.9552\n\nEpoch 00044: accuracy improved from 0.95454 to 0.95790, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 45/400\n280/280 - 41s - loss: 0.1211 - accuracy: 0.9569 - val_loss: 0.1389 - val_accuracy: 0.9534\n\nEpoch 00045: accuracy did not improve from 0.95790\nEpoch 46/400\n280/280 - 42s - loss: 0.1123 - accuracy: 0.9579 - val_loss: 0.1104 - val_accuracy: 0.9579\n\nEpoch 00046: accuracy did not improve from 0.95790\nEpoch 47/400\n280/280 - 41s - loss: 0.1126 - accuracy: 0.9600 - val_loss: 0.1235 - val_accuracy: 0.9624\n\nEpoch 00047: accuracy improved from 0.95790 to 0.96003, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 48/400\n280/280 - 41s - loss: 0.1154 - accuracy: 0.9583 - val_loss: 0.1661 - val_accuracy: 0.9355\n\nEpoch 00048: accuracy did not improve from 0.96003\nEpoch 49/400\n280/280 - 41s - loss: 0.1130 - accuracy: 0.9589 - val_loss: 0.1141 - val_accuracy: 0.9583\n\nEpoch 00049: accuracy did not improve from 0.96003\nEpoch 50/400\n280/280 - 42s - loss: 0.1025 - accuracy: 0.9641 - val_loss: 0.1020 - val_accuracy: 0.9646\n\nEpoch 00050: accuracy improved from 0.96003 to 0.96406, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 51/400\n280/280 - 42s - loss: 0.1024 - accuracy: 0.9613 - val_loss: 0.1379 - val_accuracy: 0.9498\n\nEpoch 00051: accuracy did not improve from 0.96406\nEpoch 52/400\n280/280 - 42s - loss: 0.1001 - accuracy: 0.9646 - val_loss: 0.1290 - val_accuracy: 0.9565\n\nEpoch 00052: accuracy improved from 0.96406 to 0.96462, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 53/400\n280/280 - 42s - loss: 0.1092 - accuracy: 0.9578 - val_loss: 0.1384 - val_accuracy: 0.9512\n\nEpoch 00053: accuracy did not improve from 0.96462\nEpoch 54/400\n280/280 - 41s - loss: 0.1025 - accuracy: 0.9647 - val_loss: 0.1070 - val_accuracy: 0.9668\n\nEpoch 00054: accuracy improved from 0.96462 to 0.96473, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 55/400\n280/280 - 41s - loss: 0.0976 - accuracy: 0.9662 - val_loss: 0.1199 - val_accuracy: 0.9565\n\nEpoch 00055: accuracy improved from 0.96473 to 0.96619, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 56/400\n280/280 - 41s - loss: 0.0956 - accuracy: 0.9651 - val_loss: 0.1028 - val_accuracy: 0.9619\n\nEpoch 00056: accuracy did not improve from 0.96619\nEpoch 57/400\n280/280 - 41s - loss: 0.0919 - accuracy: 0.9678 - val_loss: 0.1089 - val_accuracy: 0.9655\n\nEpoch 00057: accuracy improved from 0.96619 to 0.96775, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 58/400\n280/280 - 41s - loss: 0.0915 - accuracy: 0.9662 - val_loss: 0.1094 - val_accuracy: 0.9588\n\nEpoch 00058: accuracy did not improve from 0.96775\nEpoch 59/400\n280/280 - 41s - loss: 0.0960 - accuracy: 0.9662 - val_loss: 0.1050 - val_accuracy: 0.9673\n\nEpoch 00059: accuracy did not improve from 0.96775\nEpoch 60/400\n280/280 - 41s - loss: 0.0931 - accuracy: 0.9662 - val_loss: 0.1087 - val_accuracy: 0.9597\n\nEpoch 00060: accuracy did not improve from 0.96775\nEpoch 61/400\n280/280 - 41s - loss: 0.0848 - accuracy: 0.9690 - val_loss: 0.0932 - val_accuracy: 0.9659\n\nEpoch 00061: accuracy improved from 0.96775 to 0.96898, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 62/400\n280/280 - 42s - loss: 0.0897 - accuracy: 0.9676 - val_loss: 0.2676 - val_accuracy: 0.9216\n\nEpoch 00062: accuracy did not improve from 0.96898\nEpoch 63/400\n280/280 - 41s - loss: 0.0870 - accuracy: 0.9695 - val_loss: 0.1057 - val_accuracy: 0.9637\n\nEpoch 00063: accuracy improved from 0.96898 to 0.96954, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 64/400\n280/280 - 41s - loss: 0.0857 - accuracy: 0.9684 - val_loss: 0.1065 - val_accuracy: 0.9673\n\nEpoch 00064: accuracy did not improve from 0.96954\nEpoch 65/400\n280/280 - 41s - loss: 0.0833 - accuracy: 0.9704 - val_loss: 0.1067 - val_accuracy: 0.9664\n\nEpoch 00065: accuracy improved from 0.96954 to 0.97044, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 66/400\n280/280 - 41s - loss: 0.0767 - accuracy: 0.9726 - val_loss: 0.0906 - val_accuracy: 0.9682\n\nEpoch 00066: accuracy improved from 0.97044 to 0.97257, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 67/400\n280/280 - 41s - loss: 0.0756 - accuracy: 0.9729 - val_loss: 0.1580 - val_accuracy: 0.9449\n\nEpoch 00067: accuracy improved from 0.97257 to 0.97290, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 68/400\n280/280 - 41s - loss: 0.0789 - accuracy: 0.9704 - val_loss: 0.1020 - val_accuracy: 0.9664\n\nEpoch 00068: accuracy did not improve from 0.97290\nEpoch 69/400\n280/280 - 41s - loss: 0.0851 - accuracy: 0.9694 - val_loss: 0.1063 - val_accuracy: 0.9668\n\nEpoch 00069: accuracy did not improve from 0.97290\nEpoch 70/400\n280/280 - 41s - loss: 0.0805 - accuracy: 0.9703 - val_loss: 0.1070 - val_accuracy: 0.9628\n\nEpoch 00070: accuracy did not improve from 0.97290\nEpoch 71/400\n280/280 - 41s - loss: 0.0781 - accuracy: 0.9713 - val_loss: 0.1111 - val_accuracy: 0.9646\n\nEpoch 00071: accuracy did not improve from 0.97290\nEpoch 72/400\n280/280 - 41s - loss: 0.0738 - accuracy: 0.9753 - val_loss: 0.1449 - val_accuracy: 0.9556\n\nEpoch 00072: accuracy improved from 0.97290 to 0.97525, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 73/400\n280/280 - 41s - loss: 0.0804 - accuracy: 0.9702 - val_loss: 0.0874 - val_accuracy: 0.9722\n\nEpoch 00073: accuracy did not improve from 0.97525\nEpoch 74/400\n280/280 - 41s - loss: 0.0754 - accuracy: 0.9728 - val_loss: 0.0845 - val_accuracy: 0.9718\n\nEpoch 00074: accuracy did not improve from 0.97525\nEpoch 75/400\n280/280 - 41s - loss: 0.0684 - accuracy: 0.9745 - val_loss: 0.1643 - val_accuracy: 0.9471\n\nEpoch 00075: accuracy did not improve from 0.97525\nEpoch 76/400\n280/280 - 41s - loss: 0.0675 - accuracy: 0.9753 - val_loss: 0.0850 - val_accuracy: 0.9740\n\nEpoch 00076: accuracy did not improve from 0.97525\nEpoch 77/400\n280/280 - 41s - loss: 0.0663 - accuracy: 0.9768 - val_loss: 0.1132 - val_accuracy: 0.9673\n\nEpoch 00077: accuracy improved from 0.97525 to 0.97682, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 78/400\n280/280 - 41s - loss: 0.0700 - accuracy: 0.9738 - val_loss: 0.1072 - val_accuracy: 0.9668\n\nEpoch 00078: accuracy did not improve from 0.97682\nEpoch 79/400\n280/280 - 41s - loss: 0.0786 - accuracy: 0.9691 - val_loss: 0.0998 - val_accuracy: 0.9722\n\nEpoch 00079: accuracy did not improve from 0.97682\nEpoch 80/400\n280/280 - 41s - loss: 0.0779 - accuracy: 0.9725 - val_loss: 0.1290 - val_accuracy: 0.9525\n\nEpoch 00080: accuracy did not improve from 0.97682\nEpoch 81/400\n280/280 - 41s - loss: 0.0809 - accuracy: 0.9708 - val_loss: 0.0942 - val_accuracy: 0.9722\n\nEpoch 00081: accuracy did not improve from 0.97682\nEpoch 82/400\n280/280 - 41s - loss: 0.0633 - accuracy: 0.9765 - val_loss: 0.0947 - val_accuracy: 0.9754\n\nEpoch 00082: accuracy did not improve from 0.97682\nEpoch 83/400\n280/280 - 41s - loss: 0.0642 - accuracy: 0.9764 - val_loss: 0.1124 - val_accuracy: 0.9637\n\nEpoch 00083: accuracy did not improve from 0.97682\nEpoch 84/400\n280/280 - 41s - loss: 0.0654 - accuracy: 0.9757 - val_loss: 0.1012 - val_accuracy: 0.9713\n\nEpoch 00084: accuracy did not improve from 0.97682\nEpoch 85/400\n280/280 - 41s - loss: 0.0742 - accuracy: 0.9755 - val_loss: 0.0871 - val_accuracy: 0.9709\n\nEpoch 00085: accuracy did not improve from 0.97682\nEpoch 86/400\n280/280 - 41s - loss: 0.0651 - accuracy: 0.9762 - val_loss: 0.1059 - val_accuracy: 0.9637\n\nEpoch 00086: accuracy did not improve from 0.97682\nEpoch 87/400\n280/280 - 41s - loss: 0.0638 - accuracy: 0.9775 - val_loss: 0.1246 - val_accuracy: 0.9659\n\nEpoch 00087: accuracy improved from 0.97682 to 0.97749, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 88/400\n280/280 - 41s - loss: 0.0653 - accuracy: 0.9753 - val_loss: 0.0843 - val_accuracy: 0.9740\n\nEpoch 00088: accuracy did not improve from 0.97749\nEpoch 89/400\n280/280 - 41s - loss: 0.0581 - accuracy: 0.9792 - val_loss: 0.0864 - val_accuracy: 0.9709\n\nEpoch 00089: accuracy improved from 0.97749 to 0.97917, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 90/400\n280/280 - 41s - loss: 0.0591 - accuracy: 0.9793 - val_loss: 0.0933 - val_accuracy: 0.9736\n\nEpoch 00090: accuracy improved from 0.97917 to 0.97929, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 91/400\n280/280 - 41s - loss: 0.0656 - accuracy: 0.9767 - val_loss: 0.0920 - val_accuracy: 0.9745\n\nEpoch 00091: accuracy did not improve from 0.97929\nEpoch 92/400\n280/280 - 41s - loss: 0.0616 - accuracy: 0.9768 - val_loss: 0.1044 - val_accuracy: 0.9695\n\nEpoch 00092: accuracy did not improve from 0.97929\nEpoch 93/400\n280/280 - 41s - loss: 0.0602 - accuracy: 0.9768 - val_loss: 0.0992 - val_accuracy: 0.9704\n\nEpoch 00093: accuracy did not improve from 0.97929\nEpoch 94/400\n280/280 - 41s - loss: 0.0572 - accuracy: 0.9792 - val_loss: 0.1088 - val_accuracy: 0.9691\n\nEpoch 00094: accuracy did not improve from 0.97929\nEpoch 95/400\n280/280 - 41s - loss: 0.0596 - accuracy: 0.9794 - val_loss: 0.1043 - val_accuracy: 0.9686\n\nEpoch 00095: accuracy improved from 0.97929 to 0.97940, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 96/400\n280/280 - 41s - loss: 0.0608 - accuracy: 0.9778 - val_loss: 0.1099 - val_accuracy: 0.9704\n\nEpoch 00096: accuracy did not improve from 0.97940\nEpoch 97/400\n280/280 - 41s - loss: 0.0586 - accuracy: 0.9772 - val_loss: 0.0986 - val_accuracy: 0.9700\n\nEpoch 00097: accuracy did not improve from 0.97940\nEpoch 98/400\n280/280 - 41s - loss: 0.0596 - accuracy: 0.9756 - val_loss: 0.1387 - val_accuracy: 0.9507\n\nEpoch 00098: accuracy did not improve from 0.97940\nEpoch 99/400\n280/280 - 41s - loss: 0.0592 - accuracy: 0.9775 - val_loss: 0.0976 - val_accuracy: 0.9704\n\nEpoch 00099: accuracy did not improve from 0.97940\nEpoch 100/400\n280/280 - 41s - loss: 0.0607 - accuracy: 0.9770 - val_loss: 0.1076 - val_accuracy: 0.9673\n\nEpoch 00100: accuracy did not improve from 0.97940\nEpoch 101/400\n280/280 - 41s - loss: 0.0527 - accuracy: 0.9806 - val_loss: 0.0855 - val_accuracy: 0.9731\n\nEpoch 00101: accuracy improved from 0.97940 to 0.98063, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 102/400\n280/280 - 41s - loss: 0.0501 - accuracy: 0.9819 - val_loss: 0.0909 - val_accuracy: 0.9718\n\nEpoch 00102: accuracy improved from 0.98063 to 0.98186, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 103/400\n280/280 - 41s - loss: 0.0546 - accuracy: 0.9810 - val_loss: 0.0968 - val_accuracy: 0.9745\n\nEpoch 00103: accuracy did not improve from 0.98186\nEpoch 104/400\n280/280 - 41s - loss: 0.0529 - accuracy: 0.9803 - val_loss: 0.0946 - val_accuracy: 0.9673\n\nEpoch 00104: accuracy did not improve from 0.98186\nEpoch 105/400\n280/280 - 41s - loss: 0.0576 - accuracy: 0.9776 - val_loss: 0.1095 - val_accuracy: 0.9691\n\nEpoch 00105: accuracy did not improve from 0.98186\nEpoch 106/400\n280/280 - 41s - loss: 0.0493 - accuracy: 0.9815 - val_loss: 0.1288 - val_accuracy: 0.9615\n\nEpoch 00106: accuracy did not improve from 0.98186\nEpoch 107/400\n280/280 - 41s - loss: 0.0504 - accuracy: 0.9825 - val_loss: 0.0939 - val_accuracy: 0.9785\n\nEpoch 00107: accuracy improved from 0.98186 to 0.98253, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 108/400\n280/280 - 42s - loss: 0.0579 - accuracy: 0.9796 - val_loss: 0.0940 - val_accuracy: 0.9754\n\nEpoch 00108: accuracy did not improve from 0.98253\nEpoch 109/400\n280/280 - 41s - loss: 0.0505 - accuracy: 0.9812 - val_loss: 0.0970 - val_accuracy: 0.9722\n\nEpoch 00109: accuracy did not improve from 0.98253\nEpoch 110/400\n280/280 - 41s - loss: 0.0484 - accuracy: 0.9831 - val_loss: 0.1069 - val_accuracy: 0.9736\n\nEpoch 00110: accuracy improved from 0.98253 to 0.98309, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 111/400\n280/280 - 41s - loss: 0.0547 - accuracy: 0.9793 - val_loss: 0.1023 - val_accuracy: 0.9709\n\nEpoch 00111: accuracy did not improve from 0.98309\nEpoch 112/400\n280/280 - 41s - loss: 0.0597 - accuracy: 0.9765 - val_loss: 0.0985 - val_accuracy: 0.9695\n\nEpoch 00112: accuracy did not improve from 0.98309\nEpoch 113/400\n280/280 - 41s - loss: 0.0509 - accuracy: 0.9821 - val_loss: 0.0955 - val_accuracy: 0.9713\n\nEpoch 00113: accuracy did not improve from 0.98309\nEpoch 114/400\n280/280 - 41s - loss: 0.0492 - accuracy: 0.9828 - val_loss: 0.1026 - val_accuracy: 0.9736\n\nEpoch 00114: accuracy did not improve from 0.98309\nEpoch 115/400\n280/280 - 41s - loss: 0.0495 - accuracy: 0.9817 - val_loss: 0.0857 - val_accuracy: 0.9763\n\nEpoch 00115: accuracy did not improve from 0.98309\nEpoch 116/400\n280/280 - 41s - loss: 0.0499 - accuracy: 0.9813 - val_loss: 0.0909 - val_accuracy: 0.9745\n\nEpoch 00116: accuracy did not improve from 0.98309\nEpoch 117/400\n280/280 - 41s - loss: 0.0547 - accuracy: 0.9800 - val_loss: 0.1221 - val_accuracy: 0.9713\n\nEpoch 00117: accuracy did not improve from 0.98309\nEpoch 118/400\n280/280 - 41s - loss: 0.0473 - accuracy: 0.9844 - val_loss: 0.0921 - val_accuracy: 0.9709\n\nEpoch 00118: accuracy improved from 0.98309 to 0.98444, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 119/400\n280/280 - 41s - loss: 0.0457 - accuracy: 0.9821 - val_loss: 0.1186 - val_accuracy: 0.9677\n\nEpoch 00119: accuracy did not improve from 0.98444\nEpoch 120/400\n280/280 - 41s - loss: 0.0577 - accuracy: 0.9786 - val_loss: 0.0977 - val_accuracy: 0.9740\n\nEpoch 00120: accuracy did not improve from 0.98444\nEpoch 121/400\n280/280 - 41s - loss: 0.0521 - accuracy: 0.9810 - val_loss: 0.1009 - val_accuracy: 0.9709\n\nEpoch 00121: accuracy did not improve from 0.98444\nEpoch 122/400\n280/280 - 41s - loss: 0.0515 - accuracy: 0.9820 - val_loss: 0.0896 - val_accuracy: 0.9691\n\nEpoch 00122: accuracy did not improve from 0.98444\nEpoch 123/400\n280/280 - 41s - loss: 0.0496 - accuracy: 0.9829 - val_loss: 0.0845 - val_accuracy: 0.9731\n\nEpoch 00123: accuracy did not improve from 0.98444\nEpoch 124/400\n280/280 - 41s - loss: 0.0472 - accuracy: 0.9816 - val_loss: 0.1194 - val_accuracy: 0.9597\n\nEpoch 00124: accuracy did not improve from 0.98444\nEpoch 125/400\n280/280 - 41s - loss: 0.0519 - accuracy: 0.9824 - val_loss: 0.1175 - val_accuracy: 0.9727\n\nEpoch 00125: accuracy did not improve from 0.98444\nEpoch 126/400\n280/280 - 41s - loss: 0.0412 - accuracy: 0.9859 - val_loss: 0.0961 - val_accuracy: 0.9749\n\nEpoch 00126: accuracy improved from 0.98444 to 0.98589, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 127/400\n280/280 - 41s - loss: 0.0482 - accuracy: 0.9832 - val_loss: 0.0785 - val_accuracy: 0.9772\n\nEpoch 00127: accuracy did not improve from 0.98589\nEpoch 128/400\n280/280 - 42s - loss: 0.0438 - accuracy: 0.9835 - val_loss: 0.1159 - val_accuracy: 0.9713\n\nEpoch 00128: accuracy did not improve from 0.98589\nEpoch 129/400\n280/280 - 41s - loss: 0.0436 - accuracy: 0.9842 - val_loss: 0.1282 - val_accuracy: 0.9659\n\nEpoch 00129: accuracy did not improve from 0.98589\nEpoch 130/400\n280/280 - 41s - loss: 0.0457 - accuracy: 0.9832 - val_loss: 0.0952 - val_accuracy: 0.9767\n\nEpoch 00130: accuracy did not improve from 0.98589\nEpoch 131/400\n280/280 - 41s - loss: 0.0464 - accuracy: 0.9850 - val_loss: 0.1081 - val_accuracy: 0.9722\n\nEpoch 00131: accuracy did not improve from 0.98589\nEpoch 132/400\n280/280 - 41s - loss: 0.0440 - accuracy: 0.9837 - val_loss: 0.0895 - val_accuracy: 0.9758\n\nEpoch 00132: accuracy did not improve from 0.98589\nEpoch 133/400\n280/280 - 41s - loss: 0.0434 - accuracy: 0.9841 - val_loss: 0.1158 - val_accuracy: 0.9677\n\nEpoch 00133: accuracy did not improve from 0.98589\nEpoch 134/400\n280/280 - 41s - loss: 0.0434 - accuracy: 0.9839 - val_loss: 0.1020 - val_accuracy: 0.9722\n\nEpoch 00134: accuracy did not improve from 0.98589\nEpoch 135/400\n280/280 - 41s - loss: 0.0403 - accuracy: 0.9854 - val_loss: 0.1214 - val_accuracy: 0.9727\n\nEpoch 00135: accuracy did not improve from 0.98589\nEpoch 136/400\n280/280 - 41s - loss: 0.0413 - accuracy: 0.9844 - val_loss: 0.1701 - val_accuracy: 0.9642\n\nEpoch 00136: accuracy did not improve from 0.98589\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">INFO:tensorflow:Using MirroredStrategy with devices (&#39;/job:localhost/replica:0/task:0/device:GPU:0&#39;, &#39;/job:localhost/replica:0/task:0/device:GPU:1&#39;)\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to (&#39;/job:localhost/replica:0/task:0/device:CPU:0&#39;,).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to (&#39;/job:localhost/replica:0/task:0/device:CPU:0&#39;,).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to (&#39;/job:localhost/replica:0/task:0/device:CPU:0&#39;,).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to (&#39;/job:localhost/replica:0/task:0/device:CPU:0&#39;,).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to (&#39;/job:localhost/replica:0/task:0/device:CPU:0&#39;,).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to (&#39;/job:localhost/replica:0/task:0/device:CPU:0&#39;,).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to (&#39;/job:localhost/replica:0/task:0/device:CPU:0&#39;,).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to (&#39;/job:localhost/replica:0/task:0/device:CPU:0&#39;,).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to (&#39;/job:localhost/replica:0/task:0/device:CPU:0&#39;,).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to (&#39;/job:localhost/replica:0/task:0/device:CPU:0&#39;,).\nEpoch 1/400\nINFO:tensorflow:batch_all_reduce: 174 all-reduces with algorithm = nccl, num_packs = 1\nINFO:tensorflow:batch_all_reduce: 174 all-reduces with algorithm = nccl, num_packs = 1\n280/280 - 408s - loss: 0.7311 - accuracy: 0.5659 - val_loss: 0.7034 - val_accuracy: 0.4754\n\nEpoch 00001: accuracy improved from -inf to 0.56589, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 2/400\n280/280 - 41s - loss: 0.5971 - accuracy: 0.6792 - val_loss: 0.6396 - val_accuracy: 0.7065\n\nEpoch 00002: accuracy improved from 0.56589 to 0.67921, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 3/400\n280/280 - 41s - loss: 0.5227 - accuracy: 0.7440 - val_loss: 0.5002 - val_accuracy: 0.7558\n\nEpoch 00003: accuracy improved from 0.67921 to 0.74404, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 4/400\n280/280 - 41s - loss: 0.4674 - accuracy: 0.7766 - val_loss: 0.4035 - val_accuracy: 0.8203\n\nEpoch 00004: accuracy improved from 0.74404 to 0.77662, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 5/400\n280/280 - 41s - loss: 0.4140 - accuracy: 0.8133 - val_loss: 0.3962 - val_accuracy: 0.8244\n\nEpoch 00005: accuracy improved from 0.77662 to 0.81335, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 6/400\n280/280 - 41s - loss: 0.3862 - accuracy: 0.8322 - val_loss: 0.3240 - val_accuracy: 0.8634\n\nEpoch 00006: accuracy improved from 0.81335 to 0.83216, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 7/400\n280/280 - 42s - loss: 0.3575 - accuracy: 0.8420 - val_loss: 0.3453 - val_accuracy: 0.8481\n\nEpoch 00007: accuracy improved from 0.83216 to 0.84201, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 8/400\n280/280 - 43s - loss: 0.3268 - accuracy: 0.8609 - val_loss: 0.2997 - val_accuracy: 0.8710\n\nEpoch 00008: accuracy improved from 0.84201 to 0.86093, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 9/400\n280/280 - 43s - loss: 0.3181 - accuracy: 0.8625 - val_loss: 0.4008 - val_accuracy: 0.8329\n\nEpoch 00009: accuracy improved from 0.86093 to 0.86250, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 10/400\n280/280 - 43s - loss: 0.2939 - accuracy: 0.8775 - val_loss: 0.2474 - val_accuracy: 0.9005\n\nEpoch 00010: accuracy improved from 0.86250 to 0.87751, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 11/400\n280/280 - 42s - loss: 0.2848 - accuracy: 0.8827 - val_loss: 0.2787 - val_accuracy: 0.8875\n\nEpoch 00011: accuracy improved from 0.87751 to 0.88266, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 12/400\n280/280 - 43s - loss: 0.2652 - accuracy: 0.8897 - val_loss: 0.2968 - val_accuracy: 0.8674\n\nEpoch 00012: accuracy improved from 0.88266 to 0.88971, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 13/400\n280/280 - 43s - loss: 0.2627 - accuracy: 0.8939 - val_loss: 0.2284 - val_accuracy: 0.9095\n\nEpoch 00013: accuracy improved from 0.88971 to 0.89385, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 14/400\n280/280 - 43s - loss: 0.2495 - accuracy: 0.8993 - val_loss: 0.2256 - val_accuracy: 0.9082\n\nEpoch 00014: accuracy improved from 0.89385 to 0.89934, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 15/400\n280/280 - 43s - loss: 0.2426 - accuracy: 0.9034 - val_loss: 0.2428 - val_accuracy: 0.9055\n\nEpoch 00015: accuracy improved from 0.89934 to 0.90337, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 16/400\n280/280 - 43s - loss: 0.2339 - accuracy: 0.9113 - val_loss: 0.3205 - val_accuracy: 0.8584\n\nEpoch 00016: accuracy improved from 0.90337 to 0.91132, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 17/400\n280/280 - 43s - loss: 0.2204 - accuracy: 0.9137 - val_loss: 0.2283 - val_accuracy: 0.9144\n\nEpoch 00017: accuracy improved from 0.91132 to 0.91367, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 18/400\n280/280 - 42s - loss: 0.2141 - accuracy: 0.9156 - val_loss: 0.1982 - val_accuracy: 0.9283\n\nEpoch 00018: accuracy improved from 0.91367 to 0.91557, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 19/400\n280/280 - 43s - loss: 0.2065 - accuracy: 0.9159 - val_loss: 0.2016 - val_accuracy: 0.9247\n\nEpoch 00019: accuracy improved from 0.91557 to 0.91591, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 20/400\n280/280 - 42s - loss: 0.1942 - accuracy: 0.9209 - val_loss: 0.1974 - val_accuracy: 0.9247\n\nEpoch 00020: accuracy improved from 0.91591 to 0.92095, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 21/400\n280/280 - 41s - loss: 0.1968 - accuracy: 0.9231 - val_loss: 0.3122 - val_accuracy: 0.8392\n\nEpoch 00021: accuracy improved from 0.92095 to 0.92308, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 22/400\n280/280 - 41s - loss: 0.1913 - accuracy: 0.9274 - val_loss: 0.2017 - val_accuracy: 0.9144\n\nEpoch 00022: accuracy improved from 0.92308 to 0.92744, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 23/400\n280/280 - 41s - loss: 0.1858 - accuracy: 0.9271 - val_loss: 0.1894 - val_accuracy: 0.9319\n\nEpoch 00023: accuracy did not improve from 0.92744\nEpoch 24/400\n280/280 - 41s - loss: 0.1876 - accuracy: 0.9278 - val_loss: 0.1996 - val_accuracy: 0.9225\n\nEpoch 00024: accuracy improved from 0.92744 to 0.92778, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 25/400\n280/280 - 41s - loss: 0.1765 - accuracy: 0.9301 - val_loss: 0.1711 - val_accuracy: 0.9315\n\nEpoch 00025: accuracy improved from 0.92778 to 0.93013, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 26/400\n280/280 - 41s - loss: 0.1817 - accuracy: 0.9300 - val_loss: 0.1572 - val_accuracy: 0.9350\n\nEpoch 00026: accuracy did not improve from 0.93013\nEpoch 27/400\n280/280 - 41s - loss: 0.1703 - accuracy: 0.9357 - val_loss: 0.1591 - val_accuracy: 0.9449\n\nEpoch 00027: accuracy improved from 0.93013 to 0.93573, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 28/400\n280/280 - 41s - loss: 0.1661 - accuracy: 0.9355 - val_loss: 0.1616 - val_accuracy: 0.9377\n\nEpoch 00028: accuracy did not improve from 0.93573\nEpoch 29/400\n280/280 - 41s - loss: 0.1603 - accuracy: 0.9388 - val_loss: 0.1605 - val_accuracy: 0.9409\n\nEpoch 00029: accuracy improved from 0.93573 to 0.93875, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 30/400\n280/280 - 42s - loss: 0.1591 - accuracy: 0.9366 - val_loss: 0.1434 - val_accuracy: 0.9458\n\nEpoch 00030: accuracy did not improve from 0.93875\nEpoch 31/400\n280/280 - 41s - loss: 0.1587 - accuracy: 0.9367 - val_loss: 0.1224 - val_accuracy: 0.9561\n\nEpoch 00031: accuracy did not improve from 0.93875\nEpoch 32/400\n280/280 - 41s - loss: 0.1511 - accuracy: 0.9429 - val_loss: 0.1412 - val_accuracy: 0.9467\n\nEpoch 00032: accuracy improved from 0.93875 to 0.94290, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 33/400\n280/280 - 41s - loss: 0.1498 - accuracy: 0.9435 - val_loss: 0.1774 - val_accuracy: 0.9364\n\nEpoch 00033: accuracy improved from 0.94290 to 0.94346, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 34/400\n280/280 - 41s - loss: 0.1442 - accuracy: 0.9424 - val_loss: 0.1611 - val_accuracy: 0.9368\n\nEpoch 00034: accuracy did not improve from 0.94346\nEpoch 35/400\n280/280 - 41s - loss: 0.1467 - accuracy: 0.9446 - val_loss: 0.1534 - val_accuracy: 0.9418\n\nEpoch 00035: accuracy improved from 0.94346 to 0.94458, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 36/400\n280/280 - 41s - loss: 0.1391 - accuracy: 0.9470 - val_loss: 0.1294 - val_accuracy: 0.9530\n\nEpoch 00036: accuracy improved from 0.94458 to 0.94704, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 37/400\n280/280 - 41s - loss: 0.1310 - accuracy: 0.9514 - val_loss: 0.2039 - val_accuracy: 0.9270\n\nEpoch 00037: accuracy improved from 0.94704 to 0.95141, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 38/400\n280/280 - 41s - loss: 0.1336 - accuracy: 0.9493 - val_loss: 0.1272 - val_accuracy: 0.9503\n\nEpoch 00038: accuracy did not improve from 0.95141\nEpoch 39/400\n280/280 - 41s - loss: 0.1367 - accuracy: 0.9491 - val_loss: 0.1155 - val_accuracy: 0.9565\n\nEpoch 00039: accuracy did not improve from 0.95141\nEpoch 40/400\n280/280 - 41s - loss: 0.1249 - accuracy: 0.9545 - val_loss: 0.1409 - val_accuracy: 0.9467\n\nEpoch 00040: accuracy improved from 0.95141 to 0.95454, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 41/400\n280/280 - 41s - loss: 0.1326 - accuracy: 0.9488 - val_loss: 0.1428 - val_accuracy: 0.9427\n\nEpoch 00041: accuracy did not improve from 0.95454\nEpoch 42/400\n280/280 - 41s - loss: 0.1317 - accuracy: 0.9492 - val_loss: 0.1117 - val_accuracy: 0.9565\n\nEpoch 00042: accuracy did not improve from 0.95454\nEpoch 43/400\n280/280 - 41s - loss: 0.1249 - accuracy: 0.9536 - val_loss: 0.1166 - val_accuracy: 0.9592\n\nEpoch 00043: accuracy did not improve from 0.95454\nEpoch 44/400\n280/280 - 41s - loss: 0.1159 - accuracy: 0.9579 - val_loss: 0.1182 - val_accuracy: 0.9552\n\nEpoch 00044: accuracy improved from 0.95454 to 0.95790, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 45/400\n280/280 - 41s - loss: 0.1211 - accuracy: 0.9569 - val_loss: 0.1389 - val_accuracy: 0.9534\n\nEpoch 00045: accuracy did not improve from 0.95790\nEpoch 46/400\n280/280 - 42s - loss: 0.1123 - accuracy: 0.9579 - val_loss: 0.1104 - val_accuracy: 0.9579\n\nEpoch 00046: accuracy did not improve from 0.95790\nEpoch 47/400\n280/280 - 41s - loss: 0.1126 - accuracy: 0.9600 - val_loss: 0.1235 - val_accuracy: 0.9624\n\nEpoch 00047: accuracy improved from 0.95790 to 0.96003, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 48/400\n280/280 - 41s - loss: 0.1154 - accuracy: 0.9583 - val_loss: 0.1661 - val_accuracy: 0.9355\n\nEpoch 00048: accuracy did not improve from 0.96003\nEpoch 49/400\n280/280 - 41s - loss: 0.1130 - accuracy: 0.9589 - val_loss: 0.1141 - val_accuracy: 0.9583\n\nEpoch 00049: accuracy did not improve from 0.96003\nEpoch 50/400\n280/280 - 42s - loss: 0.1025 - accuracy: 0.9641 - val_loss: 0.1020 - val_accuracy: 0.9646\n\nEpoch 00050: accuracy improved from 0.96003 to 0.96406, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 51/400\n280/280 - 42s - loss: 0.1024 - accuracy: 0.9613 - val_loss: 0.1379 - val_accuracy: 0.9498\n\nEpoch 00051: accuracy did not improve from 0.96406\nEpoch 52/400\n280/280 - 42s - loss: 0.1001 - accuracy: 0.9646 - val_loss: 0.1290 - val_accuracy: 0.9565\n\nEpoch 00052: accuracy improved from 0.96406 to 0.96462, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 53/400\n280/280 - 42s - loss: 0.1092 - accuracy: 0.9578 - val_loss: 0.1384 - val_accuracy: 0.9512\n\nEpoch 00053: accuracy did not improve from 0.96462\nEpoch 54/400\n280/280 - 41s - loss: 0.1025 - accuracy: 0.9647 - val_loss: 0.1070 - val_accuracy: 0.9668\n\nEpoch 00054: accuracy improved from 0.96462 to 0.96473, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 55/400\n280/280 - 41s - loss: 0.0976 - accuracy: 0.9662 - val_loss: 0.1199 - val_accuracy: 0.9565\n\nEpoch 00055: accuracy improved from 0.96473 to 0.96619, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 56/400\n280/280 - 41s - loss: 0.0956 - accuracy: 0.9651 - val_loss: 0.1028 - val_accuracy: 0.9619\n\nEpoch 00056: accuracy did not improve from 0.96619\nEpoch 57/400\n280/280 - 41s - loss: 0.0919 - accuracy: 0.9678 - val_loss: 0.1089 - val_accuracy: 0.9655\n\nEpoch 00057: accuracy improved from 0.96619 to 0.96775, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 58/400\n280/280 - 41s - loss: 0.0915 - accuracy: 0.9662 - val_loss: 0.1094 - val_accuracy: 0.9588\n\nEpoch 00058: accuracy did not improve from 0.96775\nEpoch 59/400\n280/280 - 41s - loss: 0.0960 - accuracy: 0.9662 - val_loss: 0.1050 - val_accuracy: 0.9673\n\nEpoch 00059: accuracy did not improve from 0.96775\nEpoch 60/400\n280/280 - 41s - loss: 0.0931 - accuracy: 0.9662 - val_loss: 0.1087 - val_accuracy: 0.9597\n\nEpoch 00060: accuracy did not improve from 0.96775\nEpoch 61/400\n280/280 - 41s - loss: 0.0848 - accuracy: 0.9690 - val_loss: 0.0932 - val_accuracy: 0.9659\n\nEpoch 00061: accuracy improved from 0.96775 to 0.96898, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 62/400\n280/280 - 42s - loss: 0.0897 - accuracy: 0.9676 - val_loss: 0.2676 - val_accuracy: 0.9216\n\nEpoch 00062: accuracy did not improve from 0.96898\nEpoch 63/400\n280/280 - 41s - loss: 0.0870 - accuracy: 0.9695 - val_loss: 0.1057 - val_accuracy: 0.9637\n\nEpoch 00063: accuracy improved from 0.96898 to 0.96954, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 64/400\n280/280 - 41s - loss: 0.0857 - accuracy: 0.9684 - val_loss: 0.1065 - val_accuracy: 0.9673\n\nEpoch 00064: accuracy did not improve from 0.96954\nEpoch 65/400\n280/280 - 41s - loss: 0.0833 - accuracy: 0.9704 - val_loss: 0.1067 - val_accuracy: 0.9664\n\nEpoch 00065: accuracy improved from 0.96954 to 0.97044, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 66/400\n280/280 - 41s - loss: 0.0767 - accuracy: 0.9726 - val_loss: 0.0906 - val_accuracy: 0.9682\n\nEpoch 00066: accuracy improved from 0.97044 to 0.97257, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 67/400\n280/280 - 41s - loss: 0.0756 - accuracy: 0.9729 - val_loss: 0.1580 - val_accuracy: 0.9449\n\nEpoch 00067: accuracy improved from 0.97257 to 0.97290, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 68/400\n280/280 - 41s - loss: 0.0789 - accuracy: 0.9704 - val_loss: 0.1020 - val_accuracy: 0.9664\n\nEpoch 00068: accuracy did not improve from 0.97290\nEpoch 69/400\n280/280 - 41s - loss: 0.0851 - accuracy: 0.9694 - val_loss: 0.1063 - val_accuracy: 0.9668\n\nEpoch 00069: accuracy did not improve from 0.97290\nEpoch 70/400\n280/280 - 41s - loss: 0.0805 - accuracy: 0.9703 - val_loss: 0.1070 - val_accuracy: 0.9628\n\nEpoch 00070: accuracy did not improve from 0.97290\nEpoch 71/400\n280/280 - 41s - loss: 0.0781 - accuracy: 0.9713 - val_loss: 0.1111 - val_accuracy: 0.9646\n\nEpoch 00071: accuracy did not improve from 0.97290\nEpoch 72/400\n280/280 - 41s - loss: 0.0738 - accuracy: 0.9753 - val_loss: 0.1449 - val_accuracy: 0.9556\n\nEpoch 00072: accuracy improved from 0.97290 to 0.97525, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 73/400\n280/280 - 41s - loss: 0.0804 - accuracy: 0.9702 - val_loss: 0.0874 - val_accuracy: 0.9722\n\nEpoch 00073: accuracy did not improve from 0.97525\nEpoch 74/400\n280/280 - 41s - loss: 0.0754 - accuracy: 0.9728 - val_loss: 0.0845 - val_accuracy: 0.9718\n\nEpoch 00074: accuracy did not improve from 0.97525\nEpoch 75/400\n280/280 - 41s - loss: 0.0684 - accuracy: 0.9745 - val_loss: 0.1643 - val_accuracy: 0.9471\n\nEpoch 00075: accuracy did not improve from 0.97525\nEpoch 76/400\n280/280 - 41s - loss: 0.0675 - accuracy: 0.9753 - val_loss: 0.0850 - val_accuracy: 0.9740\n\nEpoch 00076: accuracy did not improve from 0.97525\nEpoch 77/400\n280/280 - 41s - loss: 0.0663 - accuracy: 0.9768 - val_loss: 0.1132 - val_accuracy: 0.9673\n\nEpoch 00077: accuracy improved from 0.97525 to 0.97682, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 78/400\n280/280 - 41s - loss: 0.0700 - accuracy: 0.9738 - val_loss: 0.1072 - val_accuracy: 0.9668\n\nEpoch 00078: accuracy did not improve from 0.97682\nEpoch 79/400\n280/280 - 41s - loss: 0.0786 - accuracy: 0.9691 - val_loss: 0.0998 - val_accuracy: 0.9722\n\nEpoch 00079: accuracy did not improve from 0.97682\nEpoch 80/400\n280/280 - 41s - loss: 0.0779 - accuracy: 0.9725 - val_loss: 0.1290 - val_accuracy: 0.9525\n\nEpoch 00080: accuracy did not improve from 0.97682\nEpoch 81/400\n280/280 - 41s - loss: 0.0809 - accuracy: 0.9708 - val_loss: 0.0942 - val_accuracy: 0.9722\n\nEpoch 00081: accuracy did not improve from 0.97682\nEpoch 82/400\n280/280 - 41s - loss: 0.0633 - accuracy: 0.9765 - val_loss: 0.0947 - val_accuracy: 0.9754\n\nEpoch 00082: accuracy did not improve from 0.97682\nEpoch 83/400\n280/280 - 41s - loss: 0.0642 - accuracy: 0.9764 - val_loss: 0.1124 - val_accuracy: 0.9637\n\nEpoch 00083: accuracy did not improve from 0.97682\nEpoch 84/400\n280/280 - 41s - loss: 0.0654 - accuracy: 0.9757 - val_loss: 0.1012 - val_accuracy: 0.9713\n\nEpoch 00084: accuracy did not improve from 0.97682\nEpoch 85/400\n280/280 - 41s - loss: 0.0742 - accuracy: 0.9755 - val_loss: 0.0871 - val_accuracy: 0.9709\n\nEpoch 00085: accuracy did not improve from 0.97682\nEpoch 86/400\n280/280 - 41s - loss: 0.0651 - accuracy: 0.9762 - val_loss: 0.1059 - val_accuracy: 0.9637\n\nEpoch 00086: accuracy did not improve from 0.97682\nEpoch 87/400\n280/280 - 41s - loss: 0.0638 - accuracy: 0.9775 - val_loss: 0.1246 - val_accuracy: 0.9659\n\nEpoch 00087: accuracy improved from 0.97682 to 0.97749, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 88/400\n280/280 - 41s - loss: 0.0653 - accuracy: 0.9753 - val_loss: 0.0843 - val_accuracy: 0.9740\n\nEpoch 00088: accuracy did not improve from 0.97749\nEpoch 89/400\n280/280 - 41s - loss: 0.0581 - accuracy: 0.9792 - val_loss: 0.0864 - val_accuracy: 0.9709\n\nEpoch 00089: accuracy improved from 0.97749 to 0.97917, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 90/400\n280/280 - 41s - loss: 0.0591 - accuracy: 0.9793 - val_loss: 0.0933 - val_accuracy: 0.9736\n\nEpoch 00090: accuracy improved from 0.97917 to 0.97929, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 91/400\n280/280 - 41s - loss: 0.0656 - accuracy: 0.9767 - val_loss: 0.0920 - val_accuracy: 0.9745\n\nEpoch 00091: accuracy did not improve from 0.97929\nEpoch 92/400\n280/280 - 41s - loss: 0.0616 - accuracy: 0.9768 - val_loss: 0.1044 - val_accuracy: 0.9695\n\nEpoch 00092: accuracy did not improve from 0.97929\nEpoch 93/400\n280/280 - 41s - loss: 0.0602 - accuracy: 0.9768 - val_loss: 0.0992 - val_accuracy: 0.9704\n\nEpoch 00093: accuracy did not improve from 0.97929\nEpoch 94/400\n280/280 - 41s - loss: 0.0572 - accuracy: 0.9792 - val_loss: 0.1088 - val_accuracy: 0.9691\n\nEpoch 00094: accuracy did not improve from 0.97929\nEpoch 95/400\n280/280 - 41s - loss: 0.0596 - accuracy: 0.9794 - val_loss: 0.1043 - val_accuracy: 0.9686\n\nEpoch 00095: accuracy improved from 0.97929 to 0.97940, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 96/400\n280/280 - 41s - loss: 0.0608 - accuracy: 0.9778 - val_loss: 0.1099 - val_accuracy: 0.9704\n\nEpoch 00096: accuracy did not improve from 0.97940\nEpoch 97/400\n280/280 - 41s - loss: 0.0586 - accuracy: 0.9772 - val_loss: 0.0986 - val_accuracy: 0.9700\n\nEpoch 00097: accuracy did not improve from 0.97940\nEpoch 98/400\n280/280 - 41s - loss: 0.0596 - accuracy: 0.9756 - val_loss: 0.1387 - val_accuracy: 0.9507\n\nEpoch 00098: accuracy did not improve from 0.97940\nEpoch 99/400\n280/280 - 41s - loss: 0.0592 - accuracy: 0.9775 - val_loss: 0.0976 - val_accuracy: 0.9704\n\nEpoch 00099: accuracy did not improve from 0.97940\nEpoch 100/400\n280/280 - 41s - loss: 0.0607 - accuracy: 0.9770 - val_loss: 0.1076 - val_accuracy: 0.9673\n\nEpoch 00100: accuracy did not improve from 0.97940\nEpoch 101/400\n280/280 - 41s - loss: 0.0527 - accuracy: 0.9806 - val_loss: 0.0855 - val_accuracy: 0.9731\n\nEpoch 00101: accuracy improved from 0.97940 to 0.98063, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 102/400\n280/280 - 41s - loss: 0.0501 - accuracy: 0.9819 - val_loss: 0.0909 - val_accuracy: 0.9718\n\nEpoch 00102: accuracy improved from 0.98063 to 0.98186, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 103/400\n280/280 - 41s - loss: 0.0546 - accuracy: 0.9810 - val_loss: 0.0968 - val_accuracy: 0.9745\n\nEpoch 00103: accuracy did not improve from 0.98186\nEpoch 104/400\n280/280 - 41s - loss: 0.0529 - accuracy: 0.9803 - val_loss: 0.0946 - val_accuracy: 0.9673\n\nEpoch 00104: accuracy did not improve from 0.98186\nEpoch 105/400\n280/280 - 41s - loss: 0.0576 - accuracy: 0.9776 - val_loss: 0.1095 - val_accuracy: 0.9691\n\nEpoch 00105: accuracy did not improve from 0.98186\nEpoch 106/400\n280/280 - 41s - loss: 0.0493 - accuracy: 0.9815 - val_loss: 0.1288 - val_accuracy: 0.9615\n\nEpoch 00106: accuracy did not improve from 0.98186\nEpoch 107/400\n280/280 - 41s - loss: 0.0504 - accuracy: 0.9825 - val_loss: 0.0939 - val_accuracy: 0.9785\n\nEpoch 00107: accuracy improved from 0.98186 to 0.98253, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 108/400\n280/280 - 42s - loss: 0.0579 - accuracy: 0.9796 - val_loss: 0.0940 - val_accuracy: 0.9754\n\nEpoch 00108: accuracy did not improve from 0.98253\nEpoch 109/400\n280/280 - 41s - loss: 0.0505 - accuracy: 0.9812 - val_loss: 0.0970 - val_accuracy: 0.9722\n\nEpoch 00109: accuracy did not improve from 0.98253\nEpoch 110/400\n280/280 - 41s - loss: 0.0484 - accuracy: 0.9831 - val_loss: 0.1069 - val_accuracy: 0.9736\n\nEpoch 00110: accuracy improved from 0.98253 to 0.98309, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 111/400\n280/280 - 41s - loss: 0.0547 - accuracy: 0.9793 - val_loss: 0.1023 - val_accuracy: 0.9709\n\nEpoch 00111: accuracy did not improve from 0.98309\nEpoch 112/400\n280/280 - 41s - loss: 0.0597 - accuracy: 0.9765 - val_loss: 0.0985 - val_accuracy: 0.9695\n\nEpoch 00112: accuracy did not improve from 0.98309\nEpoch 113/400\n280/280 - 41s - loss: 0.0509 - accuracy: 0.9821 - val_loss: 0.0955 - val_accuracy: 0.9713\n\nEpoch 00113: accuracy did not improve from 0.98309\nEpoch 114/400\n280/280 - 41s - loss: 0.0492 - accuracy: 0.9828 - val_loss: 0.1026 - val_accuracy: 0.9736\n\nEpoch 00114: accuracy did not improve from 0.98309\nEpoch 115/400\n280/280 - 41s - loss: 0.0495 - accuracy: 0.9817 - val_loss: 0.0857 - val_accuracy: 0.9763\n\nEpoch 00115: accuracy did not improve from 0.98309\nEpoch 116/400\n280/280 - 41s - loss: 0.0499 - accuracy: 0.9813 - val_loss: 0.0909 - val_accuracy: 0.9745\n\nEpoch 00116: accuracy did not improve from 0.98309\nEpoch 117/400\n280/280 - 41s - loss: 0.0547 - accuracy: 0.9800 - val_loss: 0.1221 - val_accuracy: 0.9713\n\nEpoch 00117: accuracy did not improve from 0.98309\nEpoch 118/400\n280/280 - 41s - loss: 0.0473 - accuracy: 0.9844 - val_loss: 0.0921 - val_accuracy: 0.9709\n\nEpoch 00118: accuracy improved from 0.98309 to 0.98444, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 119/400\n280/280 - 41s - loss: 0.0457 - accuracy: 0.9821 - val_loss: 0.1186 - val_accuracy: 0.9677\n\nEpoch 00119: accuracy did not improve from 0.98444\nEpoch 120/400\n280/280 - 41s - loss: 0.0577 - accuracy: 0.9786 - val_loss: 0.0977 - val_accuracy: 0.9740\n\nEpoch 00120: accuracy did not improve from 0.98444\nEpoch 121/400\n280/280 - 41s - loss: 0.0521 - accuracy: 0.9810 - val_loss: 0.1009 - val_accuracy: 0.9709\n\nEpoch 00121: accuracy did not improve from 0.98444\nEpoch 122/400\n280/280 - 41s - loss: 0.0515 - accuracy: 0.9820 - val_loss: 0.0896 - val_accuracy: 0.9691\n\nEpoch 00122: accuracy did not improve from 0.98444\nEpoch 123/400\n280/280 - 41s - loss: 0.0496 - accuracy: 0.9829 - val_loss: 0.0845 - val_accuracy: 0.9731\n\nEpoch 00123: accuracy did not improve from 0.98444\nEpoch 124/400\n280/280 - 41s - loss: 0.0472 - accuracy: 0.9816 - val_loss: 0.1194 - val_accuracy: 0.9597\n\nEpoch 00124: accuracy did not improve from 0.98444\nEpoch 125/400\n280/280 - 41s - loss: 0.0519 - accuracy: 0.9824 - val_loss: 0.1175 - val_accuracy: 0.9727\n\nEpoch 00125: accuracy did not improve from 0.98444\nEpoch 126/400\n280/280 - 41s - loss: 0.0412 - accuracy: 0.9859 - val_loss: 0.0961 - val_accuracy: 0.9749\n\nEpoch 00126: accuracy improved from 0.98444 to 0.98589, saving model to /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py\nINFO:tensorflow:Assets written to: /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0331/Model/Best_Model_Small.h5py/assets\nEpoch 127/400\n280/280 - 41s - loss: 0.0482 - accuracy: 0.9832 - val_loss: 0.0785 - val_accuracy: 0.9772\n\nEpoch 00127: accuracy did not improve from 0.98589\nEpoch 128/400\n280/280 - 42s - loss: 0.0438 - accuracy: 0.9835 - val_loss: 0.1159 - val_accuracy: 0.9713\n\nEpoch 00128: accuracy did not improve from 0.98589\nEpoch 129/400\n280/280 - 41s - loss: 0.0436 - accuracy: 0.9842 - val_loss: 0.1282 - val_accuracy: 0.9659\n\nEpoch 00129: accuracy did not improve from 0.98589\nEpoch 130/400\n280/280 - 41s - loss: 0.0457 - accuracy: 0.9832 - val_loss: 0.0952 - val_accuracy: 0.9767\n\nEpoch 00130: accuracy did not improve from 0.98589\nEpoch 131/400\n280/280 - 41s - loss: 0.0464 - accuracy: 0.9850 - val_loss: 0.1081 - val_accuracy: 0.9722\n\nEpoch 00131: accuracy did not improve from 0.98589\nEpoch 132/400\n280/280 - 41s - loss: 0.0440 - accuracy: 0.9837 - val_loss: 0.0895 - val_accuracy: 0.9758\n\nEpoch 00132: accuracy did not improve from 0.98589\nEpoch 133/400\n280/280 - 41s - loss: 0.0434 - accuracy: 0.9841 - val_loss: 0.1158 - val_accuracy: 0.9677\n\nEpoch 00133: accuracy did not improve from 0.98589\nEpoch 134/400\n280/280 - 41s - loss: 0.0434 - accuracy: 0.9839 - val_loss: 0.1020 - val_accuracy: 0.9722\n\nEpoch 00134: accuracy did not improve from 0.98589\nEpoch 135/400\n280/280 - 41s - loss: 0.0403 - accuracy: 0.9854 - val_loss: 0.1214 - val_accuracy: 0.9727\n\nEpoch 00135: accuracy did not improve from 0.98589\nEpoch 136/400\n280/280 - 41s - loss: 0.0413 - accuracy: 0.9844 - val_loss: 0.1701 - val_accuracy: 0.9642\n\nEpoch 00136: accuracy did not improve from 0.98589\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["import matplotlib.pyplot as plt\nacc = hist.history['accuracy']\nval_acc = hist.history['val_accuracy']\n\nloss = hist.history['loss']\nval_loss = hist.history['val_loss']\n\nplt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.ylabel('Accuracy')\nplt.ylim([min(plt.ylim()),1])\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.ylabel('Cross Entropy')\nplt.ylim([0,1.0])\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2fc10fee-5b2a-4be1-a095-842b0547489a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"/plots/dcf93b5a-68f2-4a63-a241-e01fc0868770.png","removedWidgets":[],"addedWidgets":{},"type":"image","arguments":{}}},"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAfYAAAHwCAYAAABUsk2hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3hUVfrA8e87M+mFVAKk0HsJQqi6gmJH7AXsWHbV3bX9XNuuq25zV7fpNldd6yJ21oaoWEDBQhdCkQ4hAdJ7MpmZ8/vjTEIICUwwQ0h4P8+TZ+bO3PLOHZj3nnLPEWMMSimllOocHO0dgFJKKaXajiZ2pZRSqhPRxK6UUkp1IprYlVJKqU5EE7tSSinViWhiV0oppToRTezqmCIi74vI1W29bnsSkW0ickoQ9vuZiFzvf365iHwYyLqHcZwMEakQEefhxqqU2kcTuzrq+X/06/98IlLdaPny1uzLGHOmMeb5tl73aCQi94rIwmZeTxIRt4gMC3RfxphZxpjT2iiu/S5EjDE7jDHRxhhvW+y/meOJiGwRkbXB2L9SRxtN7Oqo5//RjzbGRAM7gGmNXptVv56IuNovyqPSi8BEEend5PXpwGpjzJp2iKk9nAh0BfqIyJgjeWD9N6nagyZ21WGJyGQRyRGRu0VkN/CsiMSLyLsiki8ixf7naY22aVy9fI2IfCEif/Svu1VEzjzMdXuLyEIRKReR+SLyDxH5bwtxBxLjr0VkkX9/H4pIUqP3rxSR7SJSKCI/b+n8GGNygE+AK5u8dRXw/KHiaBLzNSLyRaPlU0VkvYiUisjfAWn0Xl8R+cQfX4GIzBKROP97LwIZwDv+Gpe7RKSXiJj6JCgiPUTkbREpEpFNInJDo30/KCKvisgL/nOTLSJZLZ0Dv6uBt4C5/ueNP9dQEfnIf6w9InKf/3WniNwnIpv9x1kmIulNY/Wv2/TfySIR+YuIFAEPHux8+LdJF5E3/d9DoYj8XUTC/DENb7ReV7G1VcmH+LzqGKeJXXV03YAEoCfwQ+y/6Wf9yxlANfD3g2w/DtgAJAGPAP8RETmMdV8CvgESgQc5MJk2FkiMlwEzsSXNUOBOABEZAvzLv/8e/uM1m4z9nm8ci4gMBEYCswOM4wD+i4w3gF9gz8Vm4PjGqwAP++MbDKRjzwnGmCvZv9blkWYOMRvI8W9/EfA7EZnS6P1zgJeBOODtg8UsIpH+fczy/00XkVD/ezHAfGCe/1j9gI/9m94BzADOAmKBa4Gqg56YfcYBW7Df3W8Pdj7E9it4F9gO9AJSgZeNMbX+z3hFo/3OAOYbY/IDjEMdq4wx+qd/HeYP2Aac4n8+GXAD4QdZfyRQ3Gj5M+B6//NrgE2N3osEDNCtNetik6IHiGz0/n+B/wb4mZqL8ReNlm8G5vmf/xL7w1//XpT/HJzSwr4jgTJgon/5t8Bbh3muvvA/vwr4qtF6gk3E17ew3/OAFc19h/7lXv5z6cImPS8Q0+j9h4Hn/M8fxCa3+veGANUHObdXAPn+fYcBJcD5/vdmNI6ryXYbgHObeb0h1oOcpx2H+L4bzgcwoT6+ZtYbB+wEHP7lpcAl7fn/T/86xp+W2FVHl2+MqalfEJFIEfm3v6q6DFgIxEnLPa531z8xxtSXyKJbuW4PoKjRa2B/kJsVYIy7Gz2vahRTj8b7NsZUAoUtHcsf02vAVf7ahcuxpfjDOVf1msZgGi/7q4xfFpFd/v3+F1uyD0T9uSxv9Np2bEm2XtNzEy4tt2VfDbxqjPEYWwp+k33V8enY2obmHOy9Q9nvuz/E+UgHthtjPE13Yoz5GqgEJonIIGyNwtuHGZM6hmhiVx1d0+kJ/w8YCIwzxsRiO05BozbgIMgDEvzVvvXSD7L+94kxr/G+/cdMPMQ2zwOXAKcCMdiq3+8TR9MYhP0/78PY72WEf79XNNnnwaaUzMWey5hGr2UAuw4R0wH8/QVOBq4Qkd1i+2FcBJzlb07YCfRtYfOW3qv0Pzb+rrs1Wafp5zvY+dgJZBzkwuR5//pXAq83vohVqiWa2FVnE4NtKy4RkQTggWAf0BizHVtN+qCIhIrIBGBakGJ8HThbRE7wtxX/ikP/P/4cWwX9JLYa3/0943gPGCoiF/gT0i3sn9xigAr/flOBnzXZfg/Qp7kdG2N2AouBh0UkXERGANdh28db60rgO+zFy0j/3wBss8EM7AVONxG5zd9ZLUZExvm3fRr4tYj0F2uEiCQa2769C3ux4BSRa2n54qDewc7HN9gLpd+LSJT/Mzfur/AicD42ub9wGOdAHYM0savO5q9ABFAAfIXtGHUkXI5tLy0EfgO8AtS2sO5hx2iMyQZ+jO2slwcUYxPVwbYx2KTQk/2Tw2HFYYwpAC4Gfo/9vP2BRY1WeQgYBZRiLwLebLKLh4FfiEiJiNzZzCFmYNuyc4E5wAPGmI8Cia2Jq4F/GmN2N/4DngCu9lf3n4q9CNsNbARO8m/7Z+BV4ENsH4X/YM8VwA3Y5FwIDMVeiBxMi+fD2Hv3p2Gr2Xdgv8tLG72fAyzHlvg/b/0pUMcisf/nlVJtSUReAdYbY4JeY6A6NxF5Bsg1xvyivWNRHYMmdqXagNiBT4qArcBpwP+ACcaYFe0amOrQRKQXsBI4zhiztX2jUR1F0KriReQZEdkrIs2ObuVvt3pc7AAU34rIqGDFotQR0A1721MF8DhwkyZ19X2IyK+BNcCjmtRVawStxC4iJ2J/5F4wxhwwJrWInAX8FDsAxDjgMWPMuKbrKaWUUipwQSuxG2MWYqsmW3IuNukbY8xX2PtnuwcrHqWUUupY0J694lPZfyCHHPYfhEIppZRSrdSeMw81NwhGs+0CIvJD7DjgREVFjR40aFAw41JKKaWOKsuWLSswxgQ0AVB7JvYc9h+tKg173+oBjDFPYgfXICsryyxdujT40SmllFJHCRHZHui67VkV/zb+8atFZDxQaozJa8d4lFJKqQ4vaCV2EZmNnX0rSURysMNVhgAYY57Azo18FrAJO5HDzGDFopRSSh0rgpbYjTEzDvG+wQ6NqZRS6hhTWethd1kNfZKisPMItZ1dJdXM/noHG/eWM2lAV04dkkJyTNh+67g9Poqr3Lg9PrrGhhHmspMaFlbUsiqnhN2ltfRKjKRf12iSY8Jwe31U1nqpqfMS4nQQ6nJQW+dl3e5y1uaWsaeshpTYcFLjI0iNC2d4ahyhrvapFG/PNnallFKtZIyhoMLNtsJKKms9JMeEkRwTRmJUGE5HywmystbD6l2l7CquJrekmrAQB2cO6056wr6J6rw+w6a9FSzdXsSy7cUYA1dO6MmojPhm97mjsIpPN+ylsNJNUWUtXh/06GKTW0psODHhLqLCXCRGhRIXGQpArcfLrK928PdPN1FU6SY5JoxJA5I5ZXBXpgxOIcS5fzKsqfOSV1pDXkk1uaU15JZUk1daTbXbS8/EKPokR5EQFUphhZv88lq+2VbEx+v2YICUmHA+yN7Dz/+3mn7J0Xh9huo6LxU1Hspr982UKwLJ0WGEuhzkFFcf8DmdDsHrO/iYL1GhTird3oblVb88rd0Se4cbUlY7zymljpT1u8tYn1eOx2fw+QzduoQzrk9CQ+muJV6fYeXOErYXVuL2+Kjz+ogOdzGkexf6JEcdkLwOxRjDl1sKeX7xNhZvKtwvKdVzCCRE2STfJzmK04akcPKgrrg9Pp5bvI3nF2+jrMZu58CHCy9uQjguI45B3WJYv7uc9XnlVNfZ5JQUHYrb46OsxsOYXvHMPL43Jw/qSniIE5/P8NzibTzywXpq6nyIQFxECA4RCivdB8QGkBgVSt+u0ewqrmZXSTUT+yZy5vDufL2lkM83FlBaXUdyTBgzxmYwKiOOLzcXsuC7fNbvLm92X+EhTnJLq2mawhKjQrlkTDqXjc0gLT6C9bvLmbdmN2vzyggPcRIR4iAy1F5sxEeFEuIU8kpr2FVcTXWdl+GpXchMjyM1LoLthVVs3FvO3vJaosNcRIU6CQ9xUuf1UevxEeJ0MCAlhiHdY+kSGUJFrafhwmnywOQ2rYkQkWXGmKyA1tXErpRqb6XVdazLK2NdXhkJUaGcOiSFyNDWVShm55aSnVuGyyE4HUJkqIuEqFASokKJDnMR6nIQ5nJQW+ejqMqWMHcWVbNpbwWb8ysID3EysW8iJ/RPYnthFf/6bDMLvss/4DjRYS4mDUhmaGosxtikawz4DPiMYVN+BV/4E1VzQl0OMhIibWyRofSIi2BIj1iGdI/F4YCl24pZvr2Y/AqbTKLDXHybU8qGPeXER4Zw5vDu9O8aTe+kKKLDXBRU1JJfXku+v8SaX17DqpxS8strCXU6EAG318dpQ1KYPiaDnomRZCy6F8fqV9mUeBLPVU3k/Yr+DOgex5AesQzr0YWsXvFkJERS5fbyypKd/OeLrewqqSYq1MmUwSnsLq3hm21FnDQwmQfPGUpafGRDbUFNnZc9OzZSvncb+ZEDKDNh7C2rZdPeCjblV+B0CD89uR8n9EtqSHxen2Hhd/m8+NV2Pt2wF2MgxCmM6ZXAuN6JpMVH0D0unB5dIujWJZzwEGfDsXYWVVFU6SbJX3MRE+bal1CNgT3ZsOUzcFfChJshLKb5f0Dlu2HLAhh6HrgaVdv7vOCugPAurfr32NY0sSulDovPZ6jxeKl2e+kSEYKrFSVLj9fHu9/m8dzibSRFh/HzqYPpnRTV8H6d18d3e8pZs6uU1btK2VlUTX55Ld3KVlFSVcdyM6Bh3ahQJ6cP68YV41uuBq5XW7idr+b8ix473maDSecndT+l+WEymud0CD0TIimrqaOgws14x1pSKGJZxERmnDCY04emEOpwEFawiqLNy9i1Ywvle3ew0Z3IM94zqGH/ttuU2DBO7J/MpIHJDO3RhTCXbY8tqnSzLq+M7NyyhmRUVOlmZ3EVNXW+/faRFB1KanwkVbUeKmo9dI0J4/LxPTlnaCLh7mKI7WHrj42BvWth3bsQFg3jbgSHE6/PsGJHMfPW7Mbt9XHVhF706xptd164Gf4+BroNg+JtUFMKsamQOR0yL4OkflBZAPkbAAPp4/Hg4Msthcxdnce8NbvxeA2/nDaEi0an2SRan0C/mwfr3oG8lfZY4oDkwdBzot1/6mgb90HkbVxB2aavSBt3HlEJLQxG6q2D2nKITDjwvdJdsOVTm8y3fAaVjS7O4nrC+f+GnhP236auGv5zKuxeDV3S4aT7YMAZsGo2fPOkTfqX/hf6n9py4MYc8rN9H5rYlVKHZIxhc34FX24p4usthXyztYi95fumkI8NdzFpYFdOHpTMyPR4ujcqKVW7veSWVpNXUkNuaTU5RVW8uWIXOcXV9E2OYm9ZLbUeH6+mvUaf6tUUuEPJrXEx230i7/nGExPmoldSFCnRLv6yawZRnhK2jryT6JPuYFthFXNW7OK91XmU13i4fLCL+0Jm4+oxnNcjLuLVJTspr/UwPLUL11Q9S+aOF3Bg2B3Wm261Wyk68dcUD7+WqlovhZW1hGz9mOj8FdRIJNWOSAoSRuFMGUS8v7TcMzGSMJetXs5dNIsen9yCw3gxodHIkPMgPNYmq9J9A2WayCSkqgATm4b31N8gQ87F4alEyvLA4bQJxNlCjUNZHlQVQGg0hMXiDevC1qIa1uaV4fX5GJURT0a0QeqqILrrvu22L4Y5P4KSHRASBUn9obYMirZgL2QMDDwLLnjKJvmWvPVjWP063PqtLYV+9z6sfAk2zQfjs6/VlO5bPyIeBk6F/qdA8mA8cb0wCCGF6yFnKez4cv8EmjYGBk+DpAGQuxJ2LYVti8BTbV8beCZEJNgYu2RA35PAGWIT47Jn4f17wFsLDhf0Pw2GXQgZ4+3Fh6cGlr8Aix63n/2mxRDXaDiUL/4K8/0zJUclQ5/J0Ock6DMJSnPs+SveDsffCpPvhZBwe9z/3QyrXoIpD8Dat/wXJv5zmjEBaisgfz1c/Kz9bNXFsOgxu25NqX0/MgEuewW6Zx78P95h0sSuVCdgE28loU4H6QkR+7fXeT02gfhfq/P6WLy5kA+ydwPQNzmavslRFFS4Wba9mBU7inGIkJEQSc84F3mlNSzeVkZBhRswHBdTzrTkPfi6H4cnNo0wl4O1uWV8umGvfx0rOSYMj9dHcdWB1cyje8Zz46S+TBnUlYKKWl5643Vu2/5jVvj64XZEMMS1C0doBHtnfkPPxCgcDoEdX8Mzp0HyIPvDOexCOOuPEB5HVZ2HL195lHGb/0a0VFNtQhlf+3e6d+tOWnwke3M286b7RhY4xhE59TdMGD0aXrrUJpkbPrEl0i//CR/cu3+grnBbaht63v6vr3zJJr308TDpLljzBmTPsaXDvifbH/Rex0NMD3CF2mT1/l2wZ41NtHWV+/blDIXEfrb0FxZj/6oKIGcZlDcZhytjAsx8f//S3kvTbem3z2QYeTnszbZJK74njPUn94INIE4YNNX+Zf8P5t0NKcPgzD/YEveuZfbiYPK9NnkWb4O/jYYx19t1GivfDd++AkVb7UVD0kCoq4L178KGeVDrT/bitPvy1NjlqK7+BDrZnqfYZkrZNWWw9n+wYhbkfGMvIOpFJsGIS6Bijz3nfafApLvtcb99xb4OEN0NfB57HtPH2dJ1n5Ngxkv2/b3r4IkfQL9T4ORfQMrQA0vQteUw715Y8SIk9odzHrf/7t693R7zpPvA57Ox5i6HYRdBj5FQXQKzLoJdy2H01bDmTagpgf6nQ5c0e5Gy+g37b+Dqd6Db8APPwfekiV2p9uCptT/oTX5M6ry+AztLeT24Z01nR+woPoq7lI17ywlzOchIiCI1PoLs3FI+Wb2TjJKv+M6kURKayuDuscRHhdDVvZPbc39Gbmgvnuz2AFWEs3R7MeVVNVwTtoA1jgF8XZ3WcKiYcBfHZcTTw5vLmPw3OK32I2KkmnJnPJ6oFGLrCnBWF9iV+0yGq95q2NbnM+S//QtCtn4K7gpcdRXkRfQnu+/1kDGB7l0i6BEXTrdIH2Hh0ft/9hfPx7NrFasvWsCIPmk4v50N/7sJrv8Y0vy/Tx/eD1/9C+7aDEufgfkP0TCytCsCPNXUZpzI686zuHzrPewacy89zrrbXuTMfwiz6K/U/ngF4Um97DaVBfCvibaU2f80WPy4TcgXPGWTQsVeG8POr+GUB2HCTyF3Bax/x5bA+kyG6S9BqL8Joa7GJqHQfT3Hm36PrHjRJpXY7rZU6XXbpFrwHZTl2vbZ2nJbQk/LgtQsW5XurrBxLHsOZs7bVz1csAn+Php6/QBKttskDjDqajj9dwcvjX/3Abx+rd03QHicTUD9ToFLXoAP7rMXMLeusjEEyuO2Fxf539kLiroaSB1lq9bje7WuCtoYe8FQW2HP/aqXYP1cMF6bkI+/HRyOfec3b5Ut9ecstRcT4260F1j1pfPpL9lq8/+cZmsvfrIEopIOHsOmj+Hd2+y5dbig9yS4/DV7sdyS2nJ74bh9kT2fUx6A7iP2vV+0BZ6damsbrn4XUoYEfk4CoIldqba2ezXE927xR3XD/OdIX3QPn0ZPpeLEBzh1SDfW55Xx0jc7+CB7N1k9E/jH5aNIiLK3/Kx953GGLLsfgJvct7IiehJ1Xh+FlW6SKeaqkI+5KuQTuvhKqHNG8lr6/bxZPZKYqh08WnEvYbiJNFVscvbll1EPMDA5jNtL/0B8wVLMoKkUnv0sm/dWEBcZSv+u0Tg+uBe+fgIcTsyQ85CkAbbkWJZnqxBTR9uS57Ln4Y51+0pdJTvhr8NtKTCpP4RE2ORRVQA9j7fnZNdSm8gyJsAVr9ukuOMreOZ0OPXXcPwtdl/VJfDH/jDmBjjjd/YH/m+jbSn0yjl2nR1f22RXnwx7jILhF9nE8exUKN0Bt6y0pei/DLHHnD5r/y9j08fw3wvs89EzYeqf9v/BrquBt262pcOQSJtkEBhyri3Jh4S3xb+YwLir4M+DofeJcOmL9rX374ElT8Pt2bY6ecdicIRARoCzWhdutlXJ3UdCQh9bdf3ubdBthG0HH321PSdHk6oi287dpRXzgHnr4N+T7IVL1kz45Df2Am7EJYFt766ET39nazWmv9R8e31Tnlpbo9G1hflKCjfDs2fZi5TrP7b/ttuIJnalDqV8N0Qm2irFgzC7llM1936idn3Blr5X4Tjz9/RMjEREMMawp6iUzS/+lONL3qaCSMKp4fTaP7DZ2B+oLhEhTBnclXe/zaNrTBhPXZXF52u3c87CaZSEpJAaF0F06Qbkuo+g62BqvvgHoQt/h3hqkAGnw8jLbMkkdzlM+Imtbq2rgmvetaWN166xJa+aUpuwuqTaH5/bvt33Iepq4OFUW6qZ+ieI6db8hy3cDH8bBaf9Bib+1L722e/t362r9v1Iuatg+fOw+G/2xzgtyyb4JU/ZEu+Ml2HWxbZT162r9pV+wVYx562ySatwI/xjrI1pzPWH/s7WvgWvXgXTZ9sf8//dZGsX+kw+cN0lT9sf/nE3Nl+a9Png639BwUabVHtPgqjEQ8cQDB/90p7LW1fZtuc/D4YBp8OFT7fdMda9a0vyxge3rNi/Xboj2/mNLaljoN+pttQdxA5sASnYaDvcnf5wy/0sDoMmdnX08fn2Va8FQ+kum7AOVpVWsAlWv2Y7Qu3Nhtg08jNv5LGi8VSbUFLjI+jRJZyKWg81uzcyfts/yKpcQJGJptjEEC5ujq99nJjwEEKcDsqra3nZ9SCjHRtZ0uNKhl90D2H/nkB51yye6fkHMhIiOWt4d8Kr9/BtoYMbZq+hoMLNDfIW94S8TO2V7xHWtR88OdleYEQm2QTe/3Q442FI7GvjrquB9+6AlbNsFXPjNrztX8LsSyE2DS5+zrZLfvwQ3L0dIuLsOruWwVMn26rYIece/Dw+NcVWJd74hb3N57FM21Z81f8OXLf+t6P+h3T5i/D2T2znqZwlcNpvYeJP9t/m21fhzRts1fOOxfDxr/w1BAFUC3s98NgIW3NQXWIvKn78dfv/kH9fJTvteZ7wY4jLgLl3wnUfQfrYtj1O7grbVHGwnt0d0dy7bFv8jV90nguWZrQmsevIcyr4dq+GF861padJd7Xtvn1eWPhHWPB7GDwN9/nP8OaKXLJ6Jey7vQdsafSJ421pNmMCJRPuoXjle/T+/BfcZrqwwDmOr2p7scCXxsXOBVzj/JQ6CeXDpKuoGH0zJ3oWk/TxHTwxJYQvKntgDAytW8PotRspOPG3jDnZn8BOvJPYj37JbZNzbEei5S/Ae//HiJjuzJv2KA8sieC23PcwvU8jrO8JdptLZ8GzZ9qS8IX/sR3IGierkHA49x+2N3HSQEjed1sYPSfAbWtsFbkzBEr8bX571kAv//5z/bcedR956PM54lJ4/2ewZy2U59me4Kf+qvl1mybUUVfansof3Gc7VGVde+A2A8+0ndey37QXHD1GBd7W63TZfX7ya7t81h87flIHm4wGn21rQaKS7feUNqbtj9PjuLbf59HgzD/AlF8evO/BMUYTuwquykKYfZktYX36W/vDldWK+X7K98BLl8Cku/EOOJNFmwpIiAplcPdYnFX58Mb1sHWBTRBr3+LNzTdyT+n5hLoc3HX6QK49vjcOwZaCnKHkX72Qx5fV8fLCHTgkk/uHFXNJ3VtcmPMlF/o+BMA4XDD6OlyT7uK0+tuNKpPhkzs5w7WMM8473b721r8hNJqkExp9nnE3wpL/wAc/t/fuLnnadoIqzyP+jUt4PLE/eCpsx5t6aaPh5i9t00B9KbspEdsJrDnhsfue15fkd6/el9jzVtqSflzGoc/3sAtg3j2w+lXblhiRYHtcB2rCj+3niE1tvsNZWIwtMX77qq1OP/n+wPcNMPoaWPAHe3GQedDpKDqW8Tfvu3XqvH91jguWI0VEk3oTmthV8Hjr4LWr7e0q186zP8jv3QEx3WHgGYfe3ue11bZ5K9n72RNc8X4U3+2xvX27hnt53/l/xPpKmNvzPr6IOp3jdj7EZbWvMWDCSP5ZMp7fvLeOD7P3MDNhNWdu/oS3ut/KXf/egtdnmD42nZ+e3J+U2HDgcttUULgRdq9GUkfZTkeNRSXZjlrr37O3xNRV2x/iwefs34bsCrMl3Neutm3ME2+xSdzngYWPwqK/2oE6ug3bf//11e7fV0wKRKdAXqM29lx/R6pAkkVUEvSbYntOVxXB2Bv2H4UrEJnTD/7+0AtscwjAoLNbt++oJNsHICSyc/2Yp4+zJeqSHfb8KPU9aGJXh+dQoyz5fLbkt+1z29M4fSxc/Dw8N9V2+Jr5nu2J3eLuDflzf0vXrQvY7sige94XhMX8iMem2+rkimWvkrhzL7c47uPTbSPxmt24RtxPXYWXUase5KmzHuWNwZN4ZO5qRuT9nnUmgwfyxjN1RHdumzKAjMQmpUmHA5IH2r+WDDwLPvy5vRd41zJb7dxcEhtyLpz4M9uTvP5eaacLptxvE2VEAL1vv49uw22JHWzTw951tiQdqBGXwkZbe8FxV7Z9fANOt4k5pvvBz3dLxv2o7WNqbyK2D0RtxZHtla86JU3sqvVyV9rBGjJnwCkPHdgpLmeZbafdtcz25K5PfmHRcPlr1D5xEr4XpvPmmP+STzxxESGkxkfSNSaM9bvL+HJzITWbFvKPuj/zpu8Evu5yLn8o/Rn/O6UC50j/7TBrv4LYVB6/7Wf7H7/6BXjpEuTd27goNo0L+g7EsbmQHtfOYmXTYSRba5A/sa+fa4esjE2z1exNidj7cZvTUo/0ttRtuB3z2uO2tQa+OjvIRqAGnmXvuU4e1Ob34gK2huOsR+0FjlY57xNIU4lSAdDErlqndBfMnm47ei1+HIq3wvlP2s5beSvh6yftgBNRXeG8J/Yr0VbWerj/vVzWFv6EN0MfYPDCm3nIfT9uGt9yZrg4cgW/kv9QGd2LH1z7AhfEx8Of/4Rzw7sw8lLbs3fTfFsKbXpREREH135g72X+/I84Nn8MIy9Hvm9SB1s933WIHZAkf4O9PzuYPf0PV7cRNpnnr2tdx7l6oZF2aMyo5ODEB3DcFcHbt1LHOE3sKnC1FfbWqtoKuP4jWyr84D4oOg2v11XfRb4AACAASURBVIOzYB1uQliUcCnFWbczOj2D2Ko6PD7DjqIq7nxtFdsLK/nJyVOojE1k1Ps3sH78hxRO/gO78wsoz9vEyA1/JXLXF9B1qB2XOdF/b/Hgs227r7vKDvPp89gq4+aI2HGt+59ie3e3Vfs12I5kCx+1z0ccoi25vXTz94zfvdpebIXH2dHBWqO+451SqsPRxK4CU74H3v4p7Mkmb+rz/GZ+LeW1WYzp+iuuzv8Tmz3JvOa9jg2Jp7C9LISCt7cAW/bbRUpsGLOuH8+EvonAAKjciGPhIySvnEVD2TA8zt7GNHrm/oM7DD7H9jDf/LG9ZzVlmB0L+lDauiq5PrH3OK7l0afaW0IfO3b57tX+jnOZWuWt1DFEE7uydi6xPbVDIvZ/fddyO5Z39hzw1bF44L3M/F8IYa58eidHM9dzHO/EvMDEvklcOSadwd1jMcawcW8FS7cVU+vx4nIIoS4Hpw7p1jCkKmAnpojpZntfh8XY27b6n978CGA9j7e3bC3+mx38pKV7q4Ot+0gYer691/xo5XDY7zJnqW1jH3dje0eklDqCNLF3Jl7P4Q1huOUzO4BMv1NhxmyMw8Xm/Ap2LniBSdk/p1Yi+CJ6Gq86TuejVTGcPCiJ318wnK6xzffeFREGpMQwICXm4Md1OGDMdYHF6HTZqSNX/hcQO+tSexCxI7wd7boNtzUc0LqOc0qpDk8Te2eR960dMzl1lL0daODUFpO8MYaFGwt4fvE23B4fvyh4gN4STtimj/jwkRn83PsjRlR9yb9D/sIq11AeiXuQCiJwCPzhwgwuyUrffwrRI2XIOTax9zqhdZNFHIsaTxvZmo5zSqkOTxN7Z+Dz2YFfQiLsEKCvXmXvEa4fqtMZBtMew5fYn6+3FvGX+d/xzdYiuncJZ1LkVgbVrOSfodeS4KxmevVsEmMNI30L8SYN57jr3mN22CFK3kdKn8mQMXHfBCWqZfUd6MK6HDjYjlKqU9PE3hmsnGXbnc97wk5Z+N0H8O3L4K7E66nDuW0Bs175L48UnkBpdR3JMWH86tyhXDomnbBXn4SaBG6+3T+a19tORq/4LyQPwnn1HNv2fbRwhcG177d3FB1D18EgTjtftHacU+qYoom9o6sqgvkP2OFOM6fbH/FBZ8Ggs/h0/V4eeutbPjYLcZfkcvrQFCb0TeSMod2JCHXaXtPfzYOTfrFvWNSzH4PULDtZR3tNY6m+v5AIO8pdj1HtHYlS6gjTxN7RffJrTHUJy4f9nK8+20xZTR3Vbi9bCyr5fGMBfZKj8EYkMXNIBJyTuf+2n/8ZQmNsAqjndLVukhZ19DrzD+0dgVKqHWhi74BqPV6WbStmxerV3LTqWZ73nMZDb5YBZYS5HESEOokOc3H3GYO47oTehD7d3d6H3ljFXnsL2/G3tjyjmFJKqQ5HE/vRZvuX9n7uxH7Nzqq1aFMBN89aTml1Hae5VuBwGSJHXcKLw8cyMj2OmPCQA/cZ0w0qdu//WuFmwEDvZsY6V0op1WEFNbGLyBnAY4ATeNoY8/sm78cDzwB9gRrgWmPMmmDGdFTLXQHP+qczFYftzdx3ip2HO2MC8zcUcvNLy+mdGMWfLs7kB4Wb4WO49IyTIfIgM4Y1ncYToGyXfYzV28aUUqozCVpiFxEn8A/gVCAHWCIibxtj1jZa7T5gpTHmfBEZ5F9/SrBiOurlLLWPZ/3RVpXv/haWPw/f/JvasET+VHE3g7oP5fmZY4mPCoV3ttgZsg6W1MGW2Cv32vnNHU77miZ2pZTqlIJZYh8LbDLGbAEQkZeBc4HGiX0I8DCAMWa9iPQSkRRjzJ4D9tYZeNzgCm35/byVNlGPub7hFqU1W/P46v0XuX7vb5mesJELrr92X3V74SZbZX8o0SlgfFCZv2/a0LJc23EuPPZ7fiillFJHk2DOOZkK7Gy0nON/rbFVwAUAIjIW6AmkBTGm9lO0BR5Og7VvtbxO7io7/KcIW/IruObZbzj738t5fG8mFSFJXN67Yv829EATe30yL2/Uzl6ao6O3KaVUJxTMxN7cqBimyfLvgXgRWQn8FFgBeA7YkcgPRWSpiCzNz89v+0iPhD3Z4K2F9/7P3nveVF0N5K/D1y2Tfy/YzJmPfc7y7cXcdcZAFt1zMtEZI3DlN6rsqK2A8jxICqTE7k/sFY0qQspy941Mp5RSqtMIZmLPAdIbLacBuY1XMMaUGWNmGmNGAlcBycDWpjsyxjxpjMkyxmQlJyc3fbtjKNlhH6sK4YOfH/C22bMGfB4e+TaCh99fz4kDkpl/xyRuntzPltJThkL+BjvRC9jSOgRYYk+xj41L7GW52r6ulFKdUDAT+xKgv4j0FpFQYDrwduMVRCTO/x7A9cBCY0xZEGNqPyU7IDQajr8NVr0Emz5ueGvRpgKefnUOAF9Wp/O3Gcfx5JWj9589retQ8NTYKn1oXWKP9if2+hK7x22fa2JXSqlOJ2iJ3RjjAX4CfACsA141xmSLyI0iUj9B9GAgW0TWA2cCtwYrnnZXshPiMmDS3TYZv3sb3poKfvveWi5/+mu6VqynJqQLr9x1CdMyexw4e1rKUPu4N9s+Fm4GJLAJPlxhdi7z+hJ7xW7AaFW8Ukp1QkG9j90YMxeY2+S1Jxo9/xLoH8wYjholO2xiDwmHaY/Bc1N57cnf8FTuD7hqQk+m5e3FETkKQlv4SpIH2kk99mTD0PNtib1Luh0TPBDR3faV2Ev9t7pp5zmllOp0glkVrxor2WETMbA+fATrnAMZVzCHh6YN5ldT++PYu872iG+JKwyS+sMefwe6wo2Q2Dfw48ek7Cux6z3sSinVaWliPxKqS6C2lNqYNH43dx1TH/+CWb5T6e3YzdXdtttSuK8Ouh8ksQN0HQJ71oAxtio+kPb1eo1L7JrYlVKq09LEfiSU2tv5f/V5BU8u3MLFo9P4v9vuhshEWPK0HZgGDl5iB9vOXrLddqCrLWtdYo9JsYndGB2cRimlOjGdBOZI8N/qtr46jld/NIGxvf1DwB53JSx+HDy1EB4HcT0Pvp/6DnTr3rGPgdzDXi+6G3jdUF1sS+zavq6UUp2Sltjbms8Lq162t5T55W77DoATx47el9TBzntuDGz6CLpnNgwj26L6xF4/el1rS+xg29lLd2mPeKWU6qQ0sbe17Dkw50ewzt6yb4xh+epVVBPKzFNH779ufC/of5p9fqhqeLCd78JiIXc5OEMbOuMFpGH0ud066pxSSnVimtjb2qrZ9jFnCQAfrd2DqyyH2qg0YiOamQBm7A/tY9qYQ+9bxHagA3v/ev1MbYGoHy++NMc/OE3nHJJfKaWOdZrYD1d1Mcy5cd894WCruTd/AoBnxzd8ubmQh99fT5+QImK7tzCQTP9T4IZPYODUwI6b4k/sramGh32JPXclOjiNUkp1XprYD9fG+bZ0Pv/Bfa+tfh2Mj0Wu8fhyV3HNUwvZWVRFb1chjriMlveVOhocAX4V9e3srU3soVG2J3zucrusneeUUqpT0sR+uHYttY+rX4XcFfb5qpfJiRzCi9UTCRUvL0+L5Os7xxHiLrGjzrWFlGH2sbWJHWwHut1r7HO9h10ppTolTeyHK2ep7ckemQgf3m8T5p7VPFcxnuTBxwNwnGwksc4/KExbJfa0sXDWH+2wsq0V3c0OhANaFa+UUp2UJvbD4amF3d9C70l2Updtn8M7t+AVF2+4x3LJ5DE2kecs2Tdda5c2SuwOB4y9AcKiW79t/S1voTEQ3qVt4lFKKXVU0cR+OHavsYO9pGXB6Jm2h/quZSySUfTv3YvhaV1sL/ecJQ2jzrVZif37qL/lTUvrSinVaWliPxz17eupo8EVCqf+CoAXan7AdSf0tu+ljbUjvO34ElzhEN21nYJtpL7Erh3nlFKq09IhZQ9HzlJb+q3vgDZ4Gj9OeIrvqpM4ZbA/edbfl75hHnRJO/SockeCltiVUqrT0xL74di11FbD+5P1vDV5vJcbxcwTeuN0+BN4t+HgDIO6yqOjGh72ldh1cBqllOq0NLG3VlWRnV0t1Q4Pu2ZXKbe/sorM9DhmjG2UwF2h+4aJbc3Qr8FUn9DjjpJ4lFJKtTlN7K21a5l9TMsir7Sa655fQkJUKE9dNZrwkCZDvNZXxx8tJfakfnDJCzDswvaORCmlVJBoG3tr5SwFhOqkEVz3zFIqa728ftNYusaEH7huWpZ9PNR0rEfSkHPbOwKllFJBpIm9tXYtha6DeXV1CWvzynj6qiwGdYttft1+p8Doa6DvyUc0RKWUUscurYpvDWNg1zJ8qaN5ZtFWRmXEccqQlJbXD4uBaY9BVOKRi1EppdQxTRN7oHw++PYVqC5mnWMA2wuruP4HLczYppRSSrUTrYoPxOrXYcEjULABEvvz1x39SI0L57SDldaVUkqpdqAl9kPJWQZvXAcOF1z4H1ad8wEf7TTMPL4XLqeePqWUUkcXLbEfyt619nHGSxDfi//MXkF0mItLx+i94EoppY4+WuQ8lJLtIE6ITWN3aQ3vrc5j+ph0YsJD2jsypZRS6gCa2A+leJudNMXp4vON+Xh9houztLSulFLq6BTUxC4iZ4jIBhHZJCL3NPN+FxF5R0RWiUi2iMwMZjyHpXh7wwAzy3cUExvuon/Xw5gLXSmllDoCgpbYRcQJ/AM4ExgCzBCRIU1W+zGw1hiTCUwG/iQiocGK6bCUbId4m9iXbS9mVM94HI6jYKY2pZRSqhnBLLGPBTYZY7YYY9zAy0DT8UwNECMiAkQDRYAniDG1Tl01VOyB+F6UVtfx3Z4KRmfEt3dUSimlVIuCmdhTgZ2NlnP8rzX2d2AwkAusBm41xviCGFPrlOywj3G9WL6jGIDRvTSxK6WUOnoFM7E3V19tmiyfDqwEegAjgb+LyAEDr4vID0VkqYgszc/Pb/tIW1K8zT7G92T59mKcDiEzLe7IHV8ppZRqpWAm9hygcffxNGzJvLGZwJvG2gRsBQY13ZEx5kljTJYxJis5OTloAR+geLt9jOvJsu3FDO4eQ1SY3vqvlFLq6BXMxL4E6C8ivf0d4qYDbzdZZwcwBUBEUoCBwJYgxtQ6JdvBFYEnIomVO0vI6pnQ3hEppZRSBxW04qcxxiMiPwE+AJzAM8aYbBG50f/+E8CvgedEZDW26v5uY0xBsGJqteJtEJfB+j0VVLm9jOqp7etKKaWObkGtVzbGzAXmNnntiUbPc4HTghnD91KyHeJ7sWy7v+OcJnallFJHOR15riXG2Db2+J4s3V5M9y7hpMZFtHdUSiml1EEdMrGLyNkicuxdAFQXQ20ZxNke8VoNr5RSqiMIJGFPBzaKyCMiMjjYAR01SmyP+KKw7uwqqdaBaZRSSnUIh0zsxpgrgOOAzcCzIvKl/77ymKBH1578t7qtKu8CwJhe2iNeKaXU0S+gKnZjTBnwBnZY2O7A+cByEflpEGNrX/4S+2d7I4kNdzGkxwHj5iillFJHnUDa2KeJyBzgEyAEGGuMORPIBO4Mcnztp3gbRMTz6bZaxvVJxKkTvyillOoAArnd7WLgL8aYhY1fNMZUici1wQnrKFC8HXdMOjt2VDHz+F7tHY1SSikVkECq4h8AvqlfEJEIEekFYIz5ODhhHQVKtrPH2Q2AiX2T2jkYpZRSKjCBJPbXgMYzrnn9r3VePh+U7GBjbQKJUaEMSIlu74iUUkqpgASS2F3++dQB8D8PDV5IR4GK3eB1s7Q0lvF9E7HTxSullFJHv0ASe76InFO/ICLnAkfPeO7BULQVgOzqeCb2TWznYJRSSqnABdJ57kZgloj8HTtRy07gqqBG1d7y1wOwydeDB7V9XSmlVAdyyMRujNkMjBeRaECMMeXBD6ud5a+nRiLwxqTRKzGyvaNRSimlAhbQ7G4iMhUYCoTXtzcbY34VxLjaldm7jo0mjYn9krR9XSmlVIcSyAA1TwCXAj/FVsVfDPQMclztyrt7LdmeVCZo+7pSSqkOJpDOcxONMVcBxcaYh4AJQHpww2pHFfm4agrZaNIYltqlvaNRSimlWiWQxF7jf6wSkR5AHdA7eCG1s/x1AGww6aQnaPu6UkqpjiWQNvZ3RCQOeBRYDhjgqaBG1Z722h7xe8N6ER0WUBcEpZRS6qhx0MwlIg7gY2NMCfCGiLwLhBtjSo9IdO1h71oqHDGEx6e2dyRKKaVUqx20Kt4Y4wP+1Gi5tlMndYD89WwhjfSEqPaORCmllGq1QNrYPxSRC+VYuO/LGMzetWTX9SAtIaK9o1FKKaVaLZBG5DuAKMAjIjXYW96MMSY2qJG1h/LdSE0p63xpDIjXjnNKKaU6nkBGnos5EoEcFfauBWCjSWOK9ohXSinVAR0ysYvIic29boxZ2PbhtDP/GPEbfOmkx2tVvFJKqY4nkKr4nzV6Hg6MBZYBJwclova0dx1VIfEU18aSqoldKaVUBxRIVfy0xssikg48ErSI2tPedewK6UVKTDhhLmd7R6OUUkq1WiC94pvKAYa1dSDtzhjIX88m0knXHvFKKaU6qEDa2P+GHW0O7IXASGBVIDsXkTOAxwAn8LQx5vdN3v8ZcHmjWAYDycaYooCib0ulO8Fdwbe+7qRrj3illFIdVCBt7EsbPfcAs40xiw61kYg4gX8Ap2JL+UtE5G1jzNr6dYwxj2KHqkVEpgG3t0tSByjaCsCqqiTGaI94pZRSHVQgif11oMYY4wWbsEUk0hhTdYjtxgKbjDFb/Nu9DJwLrG1h/RnA7MDCDoI6+3EqTLhO/qKUUqrDCqSN/WOgcaNzBDA/gO1SgZ2NlnP8rx1ARCKBM4A3AthvcNRVA1BDqN7qppRSqsMKJLGHG2Mq6hf8zwMp0jY3BK1p5jWAacCilqrhReSHIrJURJbm5+cHcOjD4LGz01YTqiV2pZRSHVYgib1SREbVL4jIaKA6gO1ygPRGy2lAbgvrTucg1fDGmCeNMVnGmKzk5OQADn0Y/CV2ryOMlNjw4BxDKaWUCrJA2thvA14Tkfqk3B24NIDtlgD9RaQ3sAubvC9rupKIdAEmAVcEFHGw+BN7QpdYnI7OP9+NUkqpzimQAWqWiMggYCC2en29MaYugO08IvIT4APs7W7PGGOyReRG//tP+Fc9H/jQGFN5uB+iTXhsYk9OiGvXMJRSSqnvI5D72H8MzDLGrPEvx4vIDGPMPw+1rTFmLjC3yWtPNFl+DniuFTEHR10NXhx0i+/S3pEopZRShy2QNvYbjDEl9QvGmGLghuCF1D7qaquoMSGkJ2rHOaWUUh1XIG3sDhERY4yBhoFnQoMb1pFXUVGGj1AddU4ppVSHFkhi/wB4VUSewN6udiPwflCjage11ZV4CaVHnPaIV0op1XEFktjvBn4I3ITtPLcC2zO+U/HUVlNrQomP7HSVEUoppY4hh2xjN8b4gK+ALUAWMAVYF+S4jjifu4oaQonTxK6UUqoDa7HELiIDsPeezwAKgVcAjDEnHZnQjixTV00NoXSJCGnvUJRSSqnDdrCq+PXA58A0Y8wmABG5/YhE1Q7EU4PHEaaD0yillOrQDlYVfyGwG/hURJ4SkSk0P/57pyCeGrxO7TinlFKqY2sxsRtj5hhjLgUGAZ8BtwMpIvIvETntCMV3xDi91RiXJnallFIdWyCd5yqNMbOMMWdjJ3JZCdwT9MiOMJevFlw6XatSSqmOLZCR5xoYY4qMMf82xpwcrIDaS4ivFgnRxK6UUqpja1Vi78xCjRtHqI46p5RSqmPTxA6467yEU4szTEvsSimlOjZN7EBJZSVOMYSER7V3KEoppdT3ookdKCsrByAkTBO7Ukqpjk0TO1BWbhN7WIQmdqWUUh2bJnag3J/YwyM1sSullOrYNLEDlZU2sUdqYldKKdXBaWIHqiorAYiKjmnnSJRSSqnvRxM7UF1dAUCo9opXSinVwWliB2qrbGLXkeeUUkp1dJrYgdoaWxWPTgKjlFKqg9PEDnhqquyTEB1SVimlVMemiR2oq61P7FpiV0op1bFpYgd8bn9i12lblVJKdXDHfGI3xuBzV9sFLbErpZTq4I75xF5R6yHUuO2CltiVUkp1cEFN7CJyhohsEJFNInJPC+tMFpGVIpItIguCGU9zSqrqCBc3XnGB03WkD6+UUkq1qaBlMhFxAv8ATgVygCUi8rYxZm2jdeKAfwJnGGN2iEjXYMXTkuIqNxHU4nOF4zzSB1dKKaXaWDBL7GOBTcaYLcYYN/AycG6TdS4D3jTG7AAwxuwNYjzNKq6qIww3RqvhlVJKdQLBTOypwM5Gyzn+1xobAMSLyGciskxErgpiPM0qqXITLnU66pxSSqlOIZiNytLMa6aZ448GpgARwJci8pUx5rv9diTyQ+CHABkZGW0aZHGlmxRqNbErpZTqFIJZYs8B0hstpwG5zawzzxhTaYwpABYCmU13ZIx50hiTZYzJSk5ObtMgS6rrCMeNM1QTu1JKqY4vmIl9CdBfRHqLSCgwHXi7yTpvAT8QEZeIRALjgHVBjOkAJVV1RDk9iA4nq5RSqhMIWlW8McYjIj8BPgCcwDPGmGwRudH//hPGmHUiMg/4FvABTxtj1gQrpuYUV7mJctTp4DRKKaU6haDeuG2MmQvMbfLaE02WHwUeDWYcB1NcVUeUuHVwGqWUUp3CMT/ynO0V79YSu1JKqU7hmE/sxVVuwnGD9opXSinVCRzzib2kss6OFa9V8UoppTqBYzqx13l9lNd6CDW1WhWvlFKqUzimE3tJVR1gcPlqtcSulFKqUzjGE7ubMOrsgraxK6WU6gSO7cTuH3UO0MSulFKqUzimE3tMuItzh8bZBZe2sSullOr4junEPqhbLL86q59d0BK7UkqpTuCYTuwA1FXbR03sSimlOgFN7J4a+6i94pVSSnUCQR0rvkOoq7KPeh+7UuoIqqurIycnh5qamvYORR1FwsPDSUtLIyQk5LD3oYm9zv+fSqdtVUodQTk5OcTExNCrVy9EpL3DUUcBYwyFhYXk5OTQu3fvw96PVsV7/G3s2iteKXUE1dTUkJiYqEldNRAREhMTv3ctjib2hhK7trErpY4sTeqqqbb4N6GJvb6NXUvsSqljSGFhISNHjmTkyJF069aN1NTUhmW3233QbZcuXcott9xyyGNMnDixrcIF4NZbbyU1NRWfz9em++1stI3doyV2pdSxJzExkZUrVwLw4IMPEh0dzZ133tnwvsfjweVqPkVkZWWRlZV1yGMsXry4bYIFfD4fc+bMIT09nYULFzJ58uQ223djXq8Xp9MZlH0fKVpi1/vYlVIKgGuuuYY77riDk046ibvvvptvvvmGiRMnctxxxzFx4kQ2bNgAwGeffcbZZ58N2IuCa6+9lsmTJ9OnTx8ef/zxhv1FR0c3rD958mQuuugiBg0axOWXX44xBoC5c+cyaNAgTjjhBG655ZaG/Tb16aefMmzYMG666SZmz57d8PqePXs4//zzyczMJDMzs+Fi4oUXXmDEiBFkZmZy5ZVXNny+119/vdn4TjrpJC677DKGDx8OwHnnncfo0aMZOnQoTz75ZMM28+bNY9SoUWRmZjJlyhR8Ph/9+/cnPz8fsBcg/fr1o6Cg4HC/hu9NS+wN97FrVbxSqn089E42a3PL2nSfQ3rE8sC0oa3e7rvvvmP+/Pk4nU7KyspYuHAhLpeL+fPnc9999/HGG28csM369ev59NNPKS8vZ+DAgdx0000H3K61YsUKsrOz6dGjB8cffzyLFi0iKyuLH/3oRyxcuJDevXszY8aMFuOaPXs2M2bM4Nxzz+W+++6jrq6OkJAQbrnlFiZNmsScOXPwer1UVFSQnZ3Nb3/7WxYtWkRSUhJFRUWH/NzffPMNa9asaeiN/swzz5CQkEB1dTVjxozhwgsvxOfzccMNNzTEW1RUhMPh4IorrmDWrFncdtttzJ8/n8zMTJKSklp55tuOltjrqmxS104sSinFxRdf3FAVXVpaysUXX8ywYcO4/fbbyc7ObnabqVOnEhYWRlJSEl27dmXPnj0HrDN27FjS0tJwOByMHDmSbdu2sX79evr06dOQTFtK7G63m7lz53LeeecRGxvLuHHj+PDDDwH45JNPuOmmmwBwOp106dKFTz75hIsuuqghuSYkJBzyc48dO3a/W8wef/xxMjMzGT9+PDt37mTjxo189dVXnHjiiQ3r1e/32muv5YUXXgDsBcHMmTMPebxg0hJ7XY1Wwyul2tXhlKyDJSoqquH5/fffz0knncScOXPYtm1bi+3aYWFhDc+dTicejyegdeqr4w9l3rx5lJaWNlSTV1VVERkZydSpU5td3xjTbO9yl8vV0PHOGLNfJ8HGn/uzzz5j/vz5fPnll0RGRjJ58mRqampa3G96ejopKSl88sknfP3118yaNSugzxUsWmL3VOtwskop1YzS0lJSU1MBeO6559p8/4MGDWLLli1s27YNgFdeeaXZ9WbPns3TTz/Ntm3b2LZtG1u3buXDDz+kqqqKKVOm8K9//QuwHd/KysqYMmUKr776KoWFhQANVfG9evVi2bJlALz11lvU1dU1e7zS0lLi4+OJjIxk/fr1fPXVVwBMmDCBBQsWsHXr1v32C3D99ddzxRVXcMkll7R75ztN7HXVOpysUko146677uLee+/l+OOPx+v1tvn+IyIi+Oc//8kZZ5zBCSecQEpKCl26dNlvnaqqKj744IP9SudRUVGccMIJvPPOOzz22GN8+umnDB8+nNGjR5Odnc3QoUP5+c9/zqRJk8jMzOSOO+4A4IYbbmDBggWMHTuWr7/+er9SemNnnHEGHo+HESNGcP/99zN+/HgAkpOTefLJJ7ngggvIzMzk0ksvbdjmnHPOoaKiot2r4QEk0KqQo0VWVpZZunRp2+1w9mVQvA1ubrvbMpRS6lDWrVvH4MGD/5+9+w6PqsweOP49aQSS0BJ6770HUEQIuCNP6gAAIABJREFUdlBBBRXWhlix6+rq7lrX9ae7YlnXtnYXCzZkAUEUFMFOD723EGqAkACBlPP7452ESUiZQCYTJufzPHlmbpl7z50kc+Z971sCHUbApaenEx0djapy++2306ZNG+69995Ah1Vq8+fP595772Xu3LknfazC/jZEZIGqltzHECuxu6p4u8dujDEB8eabb9K9e3c6depEamoqt9xyS6BDKrVnnnmG4cOH8/TTTwc6FMBK7PDOYAgJhdFTy+6YxhhTAiuxm6JYif1k5XZ3M8YYY4KAXxO7iFwgIqtFZJ2IPFTI9gQRSRWRxZ6fR/0ZT6GyMqzxnDHGmKDht37sIhIKvAKcCyQB80RksqquKLDrXFUtfAzB8pB52OZiN8YYEzT8WWLvA6xT1Q2qehSYAAzz4/lOTFaGVcUbY4wJGv5M7I2ArV7LSZ51BZ0uIktEZLqIlP/wS5nWKt4YU/kkJCQwY8aMfOtefPFFbrvttmJfk9t4eciQIezfv/+4fR5//HHGjRtX7LknTZrEihXHKm8fffRRZs6cWZrwi1XZp3f1Z2IvbPD1gk3wFwLNVLUb8G9gUqEHErlZROaLyPzcGXTKjCV2Y0wlNGrUKCZMmJBv3YQJE4qdiMXbtGnTqFmz5gmdu2Bi/9vf/sY555xzQscqqOD0rv7ijwF7yoo/E3sS0MRruTGQ7L2Dqh5Q1XTP82lAuIgcNyWOqr6hqvGqGl+nTp2yizAnG3IybUhZY0ylM2LECKZOncqRI0cA2LRpE8nJyfTv35+xY8cSHx9Pp06deOyxxwp9ffPmzfOmJn3qqado164d55xzTt7UruD6qPfu3Ztu3boxfPhwDh06xM8//8zkyZN54IEH6N69O+vXr883neqsWbPo0aMHXbp0YcyYMXnxNW/enMcee4yePXvSpUsXVq1aVWhcNr2rfyeBmQe0EZEWwDZgJPAH7x1EpD6wU1VVRPrgvmik+DGm/PLmYrd77MaYAJr+EOxYWrbHrN8FBj9T5ObY2Fj69OnD119/zbBhw5gwYQJXXnklIsJTTz1F7dq1yc7O5uyzzyYxMZGuXbsWepwFCxYwYcIEFi1aRFZWFj179qRXr14AXHbZZdx0000APPzww7z99tvceeedDB06lIsuuogRI0bkO1ZGRgajR49m1qxZtG3blmuvvZbXXnuNe+65B4C4uDgWLlzIq6++yrhx43jrrbeOi8emd/VjiV1Vs4A7gBnASuBTVV0uIreKyK2e3UYAy0RkCfASMFLLc8Sc3MRuJXZjTCXkXR3vXQ3/6aef0rNnT3r06MHy5cvzVZsXNHfuXC699FKqVatG9erVGTp0aN62ZcuWceaZZ9KlSxc+/PDDIqd9zbV69WpatGhB27ZtAbjuuuvyVadfdtllAPTq1Stv4hhvNr2r49dpWz3V69MKrHvd6/nLwMv+jKFYWbkldkvsxpgAKqZk7U+XXHIJ9913HwsXLuTw4cP07NmTjRs3Mm7cOObNm0etWrUYPXo0GRkZxR6nsKlMwVVpT5o0iW7duvHee+8xe/bsYo9TUrkud+rXoqaGteldnco98lym54/VErsxphKKjo4mISGBMWPG5JXWDxw4QFRUFDVq1GDnzp1Mnz692GMMGDCAL7/8ksOHD5OWlsaUKVPytqWlpdGgQQMyMzPzJbGYmBjS0tKOO1b79u3ZtGkT69atA2D8+PEMHDjQ5+ux6V2dyp3Yc0vs1o/dGFNJjRo1iiVLljBy5EgAunXrRo8ePejUqRNjxozhjDPOKPb1PXv25Morr6R79+4MHz6cM888M2/bk08+Sd++fTn33HNp37593vqRI0fy7LPP0qNHD9avX5+3PjIyknfffZfLL7+cLl26EBISwq233oovbHrXYyr3JDBbfoV3zoerv4DWZdPVwhhjfGGTwFROvkzverKTwPj1HnuFl9cq3oaUNcYY41/PPPMMr732mt/ureeq3FXxTfrA2F+gQbdAR2KMMSbIPfTQQ2zevJn+/fv79TyVu8QeEQX1OgY6CmOMMabMVO4SuzHGBNCp1sbJ+F9Z/E1YYjfGmACIjIwkJSXFkrvJo6qkpKQQGXlyPbUqd1W8McYESOPGjUlKSqLMJ7Yyp7TIyEgaN258UsewxG6MMQEQHh6eb2hSY8qKVcUbY4wxQcQSuzHGGBNELLEbY4wxQeSUG1JWRHYDm8vwkHFA2c90X7FVtmu26w1udr3Bza7XaaaqdXw5wCmX2MuaiMz3dfzdYFHZrtmuN7jZ9QY3u97Ss6p4Y4wxJohYYjfGGGOCiCV2eCPQAQRAZbtmu97gZtcb3Ox6S6nS32M3xhhjgomV2I0xxpggUqkTu4hcICKrRWSdiDwU6HjKmog0EZHvRWSliCwXkbs962uLyLcistbzWCvQsZYlEQkVkUUiMtWzHLTXKyI1ReRzEVnl+T2fHuTXe6/nb3mZiHwsIpHBdr0i8o6I7BKRZV7rirxGEfmz5zNstYicH5ioT1wR1/us5286UUS+FJGaXtuC7nq9tt0vIioicV7rSn29lTaxi0go8AowGOgIjBKRYJucPQv4o6p2AE4Dbvdc40PALFVtA8zyLAeTu4GVXsvBfL3/Ar5W1fZAN9x1B+X1ikgj4C4gXlU7A6HASILvet8DLiiwrtBr9Pw/jwQ6eV7zquez7VTyHsdf77dAZ1XtCqwB/gxBfb2ISBPgXGCL17oTut5Km9iBPsA6Vd2gqkeBCcCwAMdUplR1u6ou9DxPw33oN8Jd5/ue3d4HLglMhGVPRBoDFwJvea0OyusVkerAAOBtAFU9qqr7CdLr9QgDqopIGFANSCbIrldV5wB7C6wu6hqHARNU9YiqbgTW4T7bThmFXa+qfqOqWZ7FX4Hc6c6C8no9XgD+BHg3fDuh663Mib0RsNVrOcmzLiiJSHOgB/AbUE9Vt4NL/kDdwEVW5l7E/XPkeK0L1uttCewG3vXcenhLRKII0utV1W3AOFyJZjuQqqrfEKTXW0BR11gZPsfGANM9z4PyekVkKLBNVZcU2HRC11uZE7sUsi4ouwiISDTwBXCPqh4IdDz+IiIXAbtUdUGgYyknYUBP4DVV7QEc5NSvhi6S577yMKAF0BCIEpGrAxtVwAX155iI/BV3S/HD3FWF7HZKX6+IVAP+Cjxa2OZC1pV4vZU5sScBTbyWG+Oq9YKKiITjkvqHqjrRs3qniDTwbG8A7ApUfGXsDGCoiGzC3Vo5S0Q+IHivNwlIUtXfPMuf4xJ9sF7vOcBGVd2tqpnARKAfwXu93oq6xqD9HBOR64CLgKv0WL/sYLzeVrgvq0s8n12NgYUiUp8TvN7KnNjnAW1EpIWIROAaKEwOcExlSkQEd/91pao+77VpMnCd5/l1wP/KOzZ/UNU/q2pjVW2O+31+p6pXE7zXuwPYKiLtPKvOBlYQpNeLq4I/TUSqef62z8a1GwnW6/VW1DVOBkaKSBURaQG0AX4PQHxlSkQuAB4EhqrqIa9NQXe9qrpUVeuqanPPZ1cS0NPz/31i16uqlfYHGIJrcbke+Gug4/HD9fXHVdskAos9P0OAWFzL2rWex9qBjtUP154ATPU8D9rrBboD8z2/40lArSC/3ieAVcAyYDxQJdiuF/gY14Yg0/Mhf0Nx14irxl0PrAYGBzr+Mrredbh7y7mfW68H8/UW2L4JiDuZ67WR54wxxpggUpmr4o0xxpigY4ndGGOMCSKW2I0xxpggYondGGOMCSKW2I0xxpggYondGGOMCSKW2I0xxpggYondGB+IyHTPEJdlum8gicgmETnHD8edLSI3ep5fJSLf+LLvCZynqYikn4LTdhrjV5bYTdDyfOjn/uSIyGGv5atKcyxVHayq75e8Z+n2rYhE5M8iMqeQ9XEiclREOvt6LFX9UFXPK6O48n0RUdUtqhqtqtllcfwC51IRaV3WxzWmPFhiN0HL86EfrarRuHHGL/ZalztbFJ65vc0x44F+nrGpvY0ElqrqsgDEZIzxkSV2U+mISIKIJInIgyKyAzefeS0RmSoiu0Vkn+d5Y6/XeFcvjxaRH0VknGffjSIy+AT3bSEic0QkTURmisgrnhnpCovblxifFJGfPMf7RkTivLZfIyKbRSTFMx1moVQ1CfgOuKbApmuB90uKo0DMo0XkR6/lc0VklYikisjLeE1LKSKtROQ7T3x7RORDEanp2TYeaApM8dS4/ElEmntK1mGefRqKyGQR2Ssi60TkJq9jPy4in4rIfz3vzXIRiS/qPSiKiNTwHGO35718WERCPNtai8gPnmvbIyKfeNaLiLwgIrs82xJLU+thTGlZYjeVVX2gNtAMuBn3v/CuZ7kpcBh4uZjX98VNyhAH/BN4W0QKmzu5pH0/ws3WFAs8zvHJ1JsvMf4BuB6oC0QA9wOISEfgNc/xG3rOV2gy9njfOxZxM8h1x01gUdr3KvcYcbgphB/GvRfrcVPt5u0CPO2JrwNuusrHAVT1GvLXuvyzkFN8jJtUoyEwAvg/ETnba/tQ3HS+NXGzZpUYcyH+DdQAWgIDcV92rvdsexL4BjcRT2PPvgDnAQOAtp5zXwmknMC5jfGJJXZTWeUAj6nqEVU9rKopqvqFqh5S1TTgKdwHd1E2q+qbnvu77wMNgHql2VdEmgK9gUdV9aiq/kgxUwf7GOO7qrpGVQ8Dn+KSMbhEN1VV56jqEeARz3tQlC89MfbzLF8LTFc3F3pp36tcQ4AVqvq5uvnUXwR2eF3fOlX91vM72Q087+NxEZEmuNkMH1TVDFVdDLxF/i9KP6rqNM/vYTzQzZdje50jFJeU/6yqaaq6CXjO6xyZuC87DT0x/Oi1PgZoD4iqrlTV7aU5tzGlYYndVFa7VTUjd0HcHN//8VSvHgDmADWl6BbX3gkpd77o6FLu2xDYq/nnm95aVMA+xrjD6/khr5gaeh9bVQ9STKnRE9NnwLWe2oWrcF9KTuS9ylUwBvVeFpG6IjJBRLZ5jvsBrmTvi9z3Ms1r3WagkddywfcmUkrXviIOVwuyuYhz/AlX6/C7p6p/DICqfoerHXgF2Ckib4hI9VKc15hSscRuKquC8xX/EWgH9FXV6riqU/C6B+wH24HaIlLNa12TYvY/mRi3ex/bc87YEl7zPnAFcC6uxDn1JOMoGIOQ/3qfxv1eunqOe3WBYxY3x3Qy7r2M8VrXFNhWQkylsYdjpfLjzqGqO1T1JlVtCNwCvCqelvWq+pKq9gI64arkHyjDuIzJxxK7MU4M7l7xfhGpDTzm7xOq6mZgPvC4iESIyOnAxX6K8XPgIhHpLyIRwN8o+f9/LrAfeAOYoKpHTzKOr4BOInKZp6R8F66tQ64YIN1z3EYcn/x24u5tH0dVtwI/A0+LSKSIdAVuAD4sbH8fRXiOFSkikZ51nwJPiUiMiDQD7sPVLCAil3s1ItyH+yKSLSK9RaSviIQDB4EMoMy76BmTyxK7Mc6LQFVcqexX4OtyOu9VwOm4avG/A58AR4rY94RjVNXlwO24xnrbcYknqYTXKPBfXAn1vycbh6ruAS4HnsFdbxvgJ69dngB6Aqm4LwETCxziaeBhEdkvIvcXcopRQHNc6f1LXBuKb32JrQjLcV9gcn+uB+7EJecNwI+49/Mdz/69gd9EJB3XVuJuVd0IVAfexL3nm3HXPu4k4jKmWOL+d40xFYGni9QqVfV7jYExJjhZid2YAPJU07YSkRARuQAYBkwKdFzGmFOX3xK7iLzjGZCh0FGqPIM2vOQZSCJRRHr6KxZjKrD6wGzcveWXgLGquiigERljTml+q4oXkQG4D6v/qupxoyyJyBDc/aohuAE8/qWqff0SjDHGGFNJ+K3ErqpzgL3F7DIMl/RVVX/F9YNt4K94jDHGmMogkPfYG5F/MI4k8g8mYYwxxphSCuSsVoUNZlHofQERuRk3njdRUVG92rdv78+4jDHGmAplwYIFe1S1ji/7BjKxJ5F/1KnGuP6nx1HVN3CDZBAfH6/z58/3f3TGGGNMBSEim0veywlkVfxkPONQi8hpQKpNjGCMMcacHL+V2EXkYyABiBORJNywk+EAqvo6MA3XIn4dbkKG6ws/kjHGGGN85bfErqqjStiuuCEujTHGGFNGAnmP3RhjjJ9kZmaSlJRERkZGyTubCiMyMpLGjRsTHh5+wsewxG6MMUEoKSmJmJgYmjdvjpsh11R0qkpKSgpJSUm0aNHihI9jY8UbY0wQysjIIDY21pL6KUREiI2NPelaFkvsxhgTpCypn3rK4ndmid0YY0yZS0lJoXv37nTv3p369evTqFGjvOWjR48W+9r58+dz1113lXiOfv36lUmss2fP5qKLLiqTY1UEdo/dGGNMmYuNjWXx4sUAPP7440RHR3P//ffnbc/KyiIsrPAUFB8fT3x8fInn+Pnnn8sm2CBjJXZjjDHlYvTo0dx3330MGjSIBx98kN9//51+/frRo0cP+vXrx+rVq4H8JejHH3+cMWPGkJCQQMuWLXnppZfyjhcdHZ23f0JCAiNGjKB9+/ZcddVV5M5cOm3aNNq3b0///v256667SlUy//jjj+nSpQudO3fmwQcfBCA7O5vRo0fTuXNnunTpwgsvvADASy+9RMeOHenatSsjR448+TfrJFiJ3RhjTLlZs2YNM2fOJDQ0lAMHDjBnzhzCwsKYOXMmf/nLX/jiiy+Oe82qVav4/vvvSUtLo127dowdO/a47mCLFi1i+fLlNGzYkDPOOIOffvqJ+Ph4brnlFubMmUOLFi0YNarY4VXySU5O5sEHH2TBggXUqlWL8847j0mTJtGkSRO2bdvGsmXLANi/fz8AzzzzDBs3bqRKlSp56wLFErsxxgS5J6YsZ0XygTI9ZseG1Xns4k6lft3ll19OaGgoAKmpqVx33XWsXbsWESEzM7PQ11x44YVUqVKFKlWqULduXXbu3Enjxo3z7dOnT5+8dd27d2fTpk1ER0fTsmXLvK5jo0aN4o033vApznnz5pGQkECdOm7elauuuoo5c+bwyCOPsGHDBu68804uvPBCzjvvPAC6du3KVVddxSWXXMIll1xS6velLFlVvDHGmHITFRWV9/yRRx5h0KBBLFu2jClTphTZzatKlSp5z0NDQ8nKyvJpn9zq+BNR1Gtr1arFkiVLSEhI4JVXXuHGG28E4KuvvuL2229nwYIF9OrVq9AYy4uV2I0xJsidSMm6PKSmptKoUSMA3nvvvTI/fvv27dmwYQObNm2iefPmfPLJJz6/tm/fvtx9993s2bOHWrVq8fHHH3PnnXeyZ88eIiIiGD58OK1atWL06NHk5OSwdetWBg0aRP/+/fnoo49IT0+nZs2aZX5NvrDEbowxJiD+9Kc/cd111/H8889z1llnlfnxq1atyquvvsoFF1xAXFwcffr0KXLfWbNm5ave/+yzz3j66acZNGgQqsqQIUMYNmwYS5Ys4frrrycnJweAp59+muzsbK6++mpSU1NRVe69996AJXUAOZmqikCw+diNMaZkK1eupEOHDoEOI+DS09OJjo5GVbn99ttp06YN9957b6DDKlZhvzsRWaCqJfcBxO6xG2OMCWJvvvkm3bt3p1OnTqSmpnLLLbcEOiS/s6p4Y4wxQevee++t8CX0smYldmOMMSaIWGI3xhhjgogldmOMMSaIWGI3xhhjgogldmOMMWUuISGBGTNm5Fv34osvcttttxX7mtzuzEOGDCl0zPXHH3+ccePGFXvuSZMmsWLFirzlRx99lJkzZ5Ym/EKdKtO7WmI3xhhT5kaNGsWECRPyrZswYYLPE7FMmzbthAd5KZjY//a3v3HOOeec0LFORZbYjTHGlLkRI0YwdepUjhw5AsCmTZtITk6mf//+jB07lvj4eDp16sRjjz1W6OubN2/Onj17AHjqqado164d55xzTt7UruD6qPfu3Ztu3boxfPhwDh06xM8//8zkyZN54IEH6N69O+vXr2f06NF8/vnngBthrkePHnTp0oUxY8bkxde8eXMee+wxevbsSZcuXVi1apXP11rRpne1xG6MMabMxcbG0qdPH77++mvAldavvPJKRISnnnqK+fPnk5iYyA8//EBiYmKRx1mwYAETJkxg0aJFTJw4kXnz5uVtu+yyy5g3bx5LliyhQ4cOvP322/Tr14+hQ4fy7LPPsnjxYlq1apW3f0ZGBqNHj+aTTz5h6dKlZGVl8dprr+Vtj4uLY+HChYwdO7bE6v5cudO7fvfddyxevJh58+YxadIkFi9enDe969KlS7n++usBN73rokWLSExM5PXXXy/Ve+orG6DGGGOC3fSHYMfSsj1m/S4w+Jlid8mtjh82bBgTJkzgnXfeAeDTTz/ljTfeICsri+3bt7NixQq6du1a6DHmzp3LpZdeSrVq1QAYOnRo3rZly5bx8MMPs3//ftLT0zn//POLjWf16tW0aNGCtm3bAnDdddfxyiuvcM899wDuiwJAr169mDhxog9vQsWc3tVK7MYYY/zikksuYdasWSxcuJDDhw/Ts2dPNm7cyLhx45g1axaJiYlceOGFRU7XmktECl0/evRoXn75ZZYuXcpjjz1W4nFKmhsld+rXoqaGLc0xAzm9q5XYjTEm2JVQsvaX6OhoEhISGDNmTF6juQMHDhAVFUWNGjXYuXMn06dPJyEhochjDBgwgNGjR/PQQw+RlZXFlClT8sZ7T0tLo0GDBmRmZvLhhx/mTQEbExNDWlraccdq3749mzZtYt26dbRu3Zrx48czcODAk7rGiji9qyV2Y4wxfjNq1Cguu+yyvBby3bp1o0ePHnTq1ImWLVtyxhlnFPv6nj17cuWVV9K9e3eaNWvGmWeembftySefpG/fvjRr1owuXbrkJfORI0dy00038dJLL+U1mgOIjIzk3Xff5fLLLycrK4vevXtz6623lup6ToXpXW3aVmOMCUI2beupy6ZtNcYYY0weS+zGGGNMELHEbowxxgQRvyZ2EblARFaLyDoReaiQ7TVEZIqILBGR5SJyvT/jMcaYyuRUa0NlyuZ35rfELiKhwCvAYKAjMEpEOhbY7XZghap2AxKA50Qkwl8xGWNMZREZGUlKSool91OIqpKSkkJkZORJHcef3d36AOtUdQOAiEwAhgErvPZRIEbc6APRwF6g7HvrG2NMJdO4cWOSkpLYvXt3oEMxpRAZGZmvO92J8GdibwRs9VpOAvoW2OdlYDKQDMQAV6pqjh9jMsaYSiE8PJwWLVoEOgwTAP68x17YGIAF64TOBxYDDYHuwMsiUv24A4ncLCLzRWS+ffs0xhhjiubPxJ4ENPFabowrmXu7HpiozjpgI9C+4IFU9Q1VjVfV+NyB9o0xxhhzPH8m9nlAGxFp4WkQNxJX7e5tC3A2gIjUA9oBG/wYkzHGGBPU/HaPXVWzROQOYAYQCryjqstF5FbP9teBJ4H3RGQprur+QVXd46+YjDHGmGDn10lgVHUaMK3Aute9nicD5/kzBmOMMaYysZHnjDHGmCBiid0YY4wJIpbYjTHGmCBiid0YY4wJIpbYjTHGmCBiid0YY4wJIpbYjTHGmCBSqRP71r2HeOX7dew8kBHoUIwxxpgyUakTe/L+wzw7YzVrdqYFOhRjjDGmTFTqxN6wZlUAtu+3ErsxxpjgUKkTe73qkYhAcurhQIdijDHGlIlKndgjwkKIi65C8n5L7MYYY4JDpU7sAC2qw479BwMdhjHGGFMmKndiXzuTj1OuIGrv8kBHYowxxpSJyp3Y63YglGyapSeiqoGOxhhjjDlplTux12jEgchGdNeVHDicFehojDHGmJNWuRM7kFo3nviQ1STvPxToUIwxxpiTVukTe3aT04mTA6Qm2X12Y4wxp75Kn9irte7vnmz+JbCBGGOMMWWg0if22Kad2KPVidk5L9ChGGOMMSet0if20NAQloZ2pH7qokCHYowxxpy0EhO7iNwhIrXKI5hA2VitK7GZOyB1W6BDMcYYY06KLyX2+sA8EflURC4QEfF3UOVtd+2e7skWu89ujDHm1FZiYlfVh4E2wNvAaGCtiPyfiLTyc2zlJqdeZ9I1Et38c6BDMcYYY06KT/fY1Q3LtsPzkwXUAj4XkX/6MbZyU79mNAty2pK9yRK7McaYU5sv99jvEpEFwD+Bn4AuqjoW6AUM93N85aJBjar8ntOesD0r4dDeQIdjjDHGnDBfSuxxwGWqer6qfqaqmQCqmgNc5NfoyknDmpEs1DZuYfuSwAZjjDHGnISwknZQ1UdFpKeIDAMU+ElVF3q2rfR3gOWhQY2qJGmcWziQHNhgjDHGmJPgS1X8I8D7QCyu9P6uiDzs78DKU2xUBPtCY91CmiV2Y4wxp64SS+zAH4AeqpoBICLPAAuBv/szsPIUEiLE1qhOWkYNYqzEbowx5hTmyz32TUCk13IVYL0vB/f0e18tIutE5KEi9kkQkcUislxEfvDluP7QoEYkeyTWquKNMcac0nwpsR8BlovIt7h77OcCP4rISwCqeldhLxKRUOAVz/5JuEFuJqvqCq99agKvAheo6hYRqXtSV3MSGtaoyrYdtWlxwEafM8YYc+ryJbF/6fnJNdvHY/cB1qnqBgARmQAMA1Z47fMHYKKqbgFQ1V0+HrvMNagZyebMmpxxYBFBN7SeMcaYSsOXVvHvi0gE0NazanVul7cSNAK2ei0nAX0L7NMWCBeR2UAM8C9V/a8Pxy5zDWpUJTmnNnIoBTIzIDyy5BcZY4wxFUyJiV1EEnCt4jcBAjQRketUdU5JLy1knRZy/l7A2UBV4BcR+VVV1xSI4WbgZoCmTZuWFPIJaVgzkkVa2y2kJUPtln45jzHGGONPvjSeew44T1UHquoA4HzgBR9elwQ08VpuDBRsmZYEfK2qB1V1DzAH6FbwQKr6hqrGq2p8nTp1fDh16bWtF8N2PIndGtAZY4w5RfmS2MNVdXXugqf2AEz0AAAgAElEQVQ0He7D6+YBbUSkhacqfyQwucA+/wPOFJEwEamGq6oPyKA3jWpW5XBkPbdgid0YY8wpypfGcwtE5G1gvGf5KmBBSS9S1SwRuQOYAYQC76jqchG51bP9dVVdKSJfA4lADvCWqi47kQs5WSJCnYYtXB2CtYw3xhhzivIlsd8K3A7chbtvPgfXRa1EqjoNmFZg3esFlp8FnvXleP7Wvml9UrdWI2rfNp/eGGOMMaaiKTZ/iUgIsEBVOwPPl09IgdOlcU12aG3q7t5MrUAHY4wxxpyAYu+xe2ZwWyIi/mmKXsF0bVyDHVqbrP1JgQ7FGGOMOSG+1Dg3wI089ztwMHelqg71W1QBUq96JL+G16HKwUWBDsUYY4w5Ib4k9if8HkUFItUbEb3/O8jOhFBfGv8bY4wxFYcv3d2GqOoP3j/AEH8HFihRdZoSgpK+x6rjjTHGnHp8SeznFrJucFkHUlHUadgCgI0b1gY4EmOMMab0ikzsIjJWRJYC7UQk0etnI7C0/EIsX02btwZgR5JPM9MaY4wxFUpx99g/AqYDTwPec6mnqepev0YVQDXrNwfgwK7NgQ3EGGOMOQFFJnZVTQVSgVGeudXrefaPFpHo3KlWg05kDTIkkqx9NvqcMcaYU48vs7vdATwO7MQN+wpulrau/gsrgETIiKxHVPpO9h08Sq2oiEBHZIwxxvjMl+5u9wDtVDXF38FUGDUa0uDgHhZu2cfZHeoFOhpjjDHGZ760it+Kq5KvNGLqNKOB7GXu2j2BDsUYY4wpFV9K7BuA2SLyFXAkd6WqBu3Y8aE1G1FP9vHj6h1Ap0CHY4wxxvjMl8S+xfMT4fkJftUbEkoOB1K2s3XvIZrUrhboiIwxxhiflJjYVfW4IWVFJLhnNa3eCICGksIPa3Zz9WnNAhyQMcYY45viBqj50ev5+AKbf/dbRBVBreYAdI/exw9rdgc2FmOMMaYUims8F+X1vHOBbeKHWCqO2i1BQhhQex8/r9vD0ayckl9jjDHGVADFJXYt4nlhy8ElrArUak7H8B0cPJrNwi37Ah2RMcYY45Pi7pXXFJFLccm/pohc5lkvQA2/RxZoce2os28TYSHCD2t2c1rL2EBHZIwxxpSouBL7D8BQ4CLP84s9PxcBc/wfWoDFtSF073p6Na3OHLvPbowx5hRR3Fjx15dnIBVOXFvIPspFTTN5ZM4hdqVlUDcmMtBRGWOMMcXyZeS5yqlOOwDOrOXur89dY6PQGWOMqfgssRcl1s3L3jQ7ibjoCOastep4Y4wxFZ8l9qJUqw1RdQhJWcOZbeowd+0ecnKCuzOAMcaYU1+JiV1ELheRGM/zh0Vkooj09H9oFUBcW9izloFt67D34FGWJVequXCMMcacgnwpsT+iqmki0h84H3gfeM2/YVUQcW1hz2rObB2LCPyw2qrjjTHGVGy+JPZsz+OFwGuq+j8qy2QwcW3h8D5iQ9Lp3LCGDS9rjDGmwvMlsW8Tkf8AVwDTRKSKj6879cW1dY971jCwbR0Wbd1P6uHMwMZkjDHGFMOXBH0FMAO4QFX3A7WBB/waVUVRxyuxt6tDdo7y8zrr9maMMabi8iWxNwC+UtW1IpIAXE6wz+6Wq3pjCKsKu9fQvUlNYqqEWbc3Y4wxFZovif0LIFtEWgNvAy2Aj/waVUUREgJxrWHPGsJDQzijdRw/rN6NqnV7M8YYUzH5kthzVDULuAx4UVXvxZXiSyQiF4jIahFZJyIPFbNfbxHJFpERvoVdjuLawZ41AAxoW4fk1AxW7UgLcFDGGGNM4XxJ7JkiMgq4FpjqWRde0otEJBR4BRgMdARGiUjHIvb7B+4+fsUT1xb2b4HMw5zXqR5Vw0N5dfb6QEdljDHGFMqXxH49cDrwlKpuFJEWwAc+vK4PsE5VN6jqUWACMKyQ/e7EVffv8jHm8hXXBlBI/IS4auHceGYLpixJZmmSj4PVHNrr1/CMMcYYbyUmdlVdAdwPLBWRzkCSqj7jw7EbAVu9lpM86/KISCPgUuB1nyMuby0TXKl9yt3wal9ui11ArWrh/OPrVSW/dtcqeLYVbJ3n7yiNMcYYwLchZROAtbhq9VeBNSIywIdjSyHrCrY6exF4UFWzC9nXO4abRWS+iMzfvbucW6VXqw23/QrD34aQcKpOGctT3ffx47o9zC2phfz2xaA5sNuHLwHGGGNMGfClKv454DxVHaiqA3DDyr7gw+uSgCZey42B5AL7xAMTRGQTMAJ4VUQuKXggVX1DVeNVNb5OnTo+nLqMhYRClxFwwwxAOC96PY1qVuUfX68qfmKYlHXuMW1HuYRpjDHG+JLYw1V1de6Cqq7Bh8ZzwDygjYi0EJEIYCQw2XsHVW2hqs1VtTnwOXCbqk7yOfryViUG6rQnbPsi/nheW5ZtO8DUpduL3n/PWveYbondGGNM+fAlsS8QkbdFJMHz8yawoKQXebrI3YFr7b4S+FRVl4vIrSJy68mFHUCNesG2BQzr1pD29WMYN2M1R7NyCt83xdN63krsxhhjyokvif1WYDlwF3A3sMKzrkSqOk1V26pqK1V9yrPudVU9rrGcqo5W1c99Dz1AGvWEQymEHtjCg4Pbs2XvISbM23L8fjk5VhVvjDGm3IUVt1FEQoAFqtoZeL58QqrgGvVyj9sWktDpUvq2qM1Ls9ZyWc/GRFfxejvTkiHrMEgopO8MTKzGGGMqnWJL7KqaAywRkablFE/FV68ThFaBbQsQER4a3J496Ud5a+6G/PvlltYbdncldhuG1hhjTDnwdRKY5SIyS0Qm5/74O7AKKzQcGnSDbQsB6NG0FoM71+fNORvYk37k2H65Deea94ecTBuoxhhjTLkotire4wm/R3GqadQTFv4XsrMgNIz7z2/HjOU7eGPOBv4ypIPbJ2U9hEdBg+5uOX0HRMUGLmZjjDGVQpEldhFpLSJnqOoP3j+4QWaSyi/ECqhRL8g8lDfwTKs60VzTMZzxv2w+VmpPWQuxrSDGM19OWjHd4owxxpgyUlxV/ItAYdOYHfJsq7zyGtB5ev0lfsoT6y+nT/ZC3sy9156yzo0zH1PfLadZAzpjjDH+V1xib66qiQVXqup8oLnfIjoV1G4JkTUgeSHs3QhT7wPg9rhFjP9lM3tT09yMcLGtvRK7ldiNMcb4X3GJPbKYbVXLOpBTiogrtW/9HSbeDBICrc6mV8YvZGdmMHHWXDdGfGwbCK8KVWpYlzdjjDHlorjEPk9Ebiq4UkRuwIeR54Jeo16wawUk/Q4XPQ+njSX0aBr3tdxG4uL5bp/YVu4xpr4NUmOMMaZcFNcq/h7gSxG5imOJPB6IwE21Wrnl3mfvNspNEJN1FCJrMipqAW9JFQDGLczh5thMqsfUK9vEnrwY6neFEF96KxpjjKlMiswMqrpTVfvhurtt8vw8oaqnq6oVP1ufAxc+B0PGueWwCGh/EdU3f8ttHTI4EFabV37eyaBnZ5MaFld2E8HsXA5vDIRVU8rmeMYYY4JKiUU+Vf1eVf/t+fmuPII6JYSGQ+8boUr0sXWdLoEjB4hc+xXVG3Vkyh39EYFZSYKW1ehzSZ5q/u3HtWssWXYWzPqbtdA3xpggZnW5ZanFQIisCdlHILYVnRvV4JGLOrL8QFUk+ygc3nfy59i+xD16+tCXyo5EmPscrKi4M+MaY4w5OZbYy5KnOh5wfdiBod0aUqu+G2p/z45CZoErrbzEvrr0r923yT3u3XjycRhjjKmQLLGXtS7D3WPdjgCICCMGxgPw4czfjt//8H6Y+bhvY8lnZ8HOZRASBns3QNaRkl/jbf9m97jPErsxxgQrS+xlrdVZcNP37tGjfqPmAGzetIE/T1zKvoNH3YbsLPhsNPz4Aiz/suRj71kDWRmu4Z5mH5tBzld5JfYNxe5mjDHm1GWJ3R8a9XSD2OTyjD53YYsQPp2/lUHPzeaDXzej0x+EDd9DaAQkzSv5uLnV8F2vcI+lvc+em9j3bYacnNK91hhjzCnBEnt5iIiCiBjObpzDtLvOpH39GNZMeQ6Z/xb0uwvanOdGsSvJ9iUQXg3aDnaj3ZX2Pvu+Te512UcgLfmELsUYY0zFZom9vHhGn2tXP4aPL67G4+Hj+Ta7F983uQ0ax8Pe9XAwpfhjbF8M9btARDWo1aJ0JfbsLNi/FRr2dMvWgM4YY4KSJfby4jWsrMwZh1SJ4j+1H+CeT5eyq0ZXt09x1fE5Oa7veoNubrluB9hVisR+IMndl281yC1bAzpjjAlKltjLS0x9N/rcrpWwcjLS91bGXTOAHFXGfp9DjoRxeOMvRb9+73rIPHgssddp59ZlHfXt/Ln315udcaxVvQlu0x+CxM8CHYUxppxZYi8v0fXciG9zn4PwKOg7luZxUTx/RXcW78hkWXYTFv30DX3/bybTlxYyxWtuw7m8xN4ecrJ8T9C5iT22NdRsalXxlcGi8Tb0sDGVkCX28hJTH7IOw9LPofcYiIoF4NyO9fjxwUHUancGvSM20jAmnNs+Wshbczeg3kPQbl8MoVVcQgdXYgff77Pv2wQh4VC9oZtP3qrig9vRQ3A0HdJ3BToSY0w5s8ReXmIauMewKnD6nfk2NahRlSZdEgjPPsyES2owuHN9/v7VSh6fvJwjWdlup+1LoF4nN0Y9uLnekVIk9s1QswmEhLqGd3s3lc3Y9aZiOrTHPabbvADGVDaW2MtLdD332PM6iKl3/PYmvQGosmMBL4/qyc0DWvL+L5s58x/f8+r3a9HkJceq4cHTMr556UrstZq757VbwJFU30a7M6emg7vdo5XYjal0LLGXl8a9od+dMOCBwrfXbAZRdSBpHiEhwl+GdOCDG/rSrn4MM7+ZihxJZdb++hw+mn3sNXXa+96X3Tux12rhWWfV8UEr3ZPYj6bDkfTAxmKMKVeW2MtLeCSc93eIrlP4dhFo3CffQDX928Qx/tK6fFrzZVLC6nH/8mac/dxs/rd4m7v/Xqcd7Fnr+qgXJyMVDu/1KrG3dI/WgC545ZbYAQ5aqd2YysQSe0XSpHf+gWoOpsAHwwkjm9hbpvKfW86nVlQEd09YzJ8+TyQrth3kZJbcMn6fZ/KXvBJ7M896S+xByzuxW3W8MZVKWKADMF6anOYeX+rhGsod3gepSXDdZKjTlj51YPId/fnXrLW8NGst1VJyeAIg6Xeo07bo4+Z2dctN7OFVIaah9WUPZvkSuzWgM6YysRJ7RdL0NBj2KnQZ4UaJyzwII9526z1CQ4T7zm3LM5d14cMtNdkU2oyM2S9ATnbRxy2Y2MFVx1tVfPA6uBsiYtxzK7EbU6lYib0iEYEeV7mfEozs05S61avwr4+H80Lq8zz/wtM0TRjN0G4NiQgr8H1t3yaoWgsiaxxbV7s5rP22TMM3FcjB3a4WJ3mRldiNqWT8WmIXkQtEZLWIrBORhwrZfpWIJHp+fhaRboUdxxTurPb1eOKhh9gb3ZbL0z/kwc8WkvDs94z/dfOx/u+Qv0V8rlot3Af+0YPlGbIpL+m7Ibq+62lhid2YSsVviV1EQoFXgMFAR2CUiHQssNtGYKCqdgWeBN7wVzzBqnrVKtS+8FGaaDJTB+2gQc2qPDJpGQnPzmbOGs991v2bj0/stT1d3k616vh9m3wfH78yO7jb9cCIrmdV8cZUMv4ssfcB1qnqBlU9CkwAhnnvoKo/q+o+z+KvQGM/xhO82l8E9bvQYfVrfN5vKz93nc5/sh5h8/ixzPjiHXT/lkISu6fL28Y5+ddnZ8GaGZB5uFxCL5XD++CVvvC7ff8rVk6OG3kuKjexW4ndmMrEn/fYGwFbvZaTgL7F7H8DML2wDSJyM3AzQNOmTcsqvuAhAgl/hgl/QL68mYYR0dSr25Z2O+ZSZam7j/7t9qpM/GABW/YeolezWlzSrRE9mp6OzPiz6+Oe8BdIWQuTxsK2BdB3LAx+JsAXVkDyYsjKgK2/AXcEOpqK6/Be0JxjiX3XikBHZIwpR/5M7FLIukIHJxeRQbjE3r+w7ar6Bp5q+vj4eBvgvDDthsBVX7jhaut2JDQklJDMDL6cPJGVC+fwyYoW1I5No0GNSD6Zt5X//rKZNrXv44V6H9B5zrOwYbab7z2iGtr0dGT+23Da2GN93iuC5EXucfviwMZR0eV2dYuqA9F1XVV8Tg6EWCcYYyoDfyb2JKCJ13JjILngTiLSFXgLGKyqKX6MJ7iJQJtz8q8Kj+TS4X9gwPnDua9KGJHhoQAcyMjk62U7mLRoGxdvuIKrQ2rxWNJ45kf05rGjN3JwXQbfV1lAyHdPETq8AlV7Jy90j/u3uHHuq9UObDwVVb7EXs8NYpSx394vYyoJfyb2eUAbEWkBbANGAn/w3kFEmgITgWtUdY0fY6nUYqOr5FuuHhnOFfFNuCK+CdtTDzN5cQdGLx9GSGQ0PWtGciQrh7cTz+PmpZ+ypcMNpNfswNTEZH7ZkMJlPRpx9WnNECmsQuYEqLovJb5IXnzsnvH2xdDqrLKJIdgULLEDpO2wxG5MJeG3xK6qWSJyBzADCAXeUdXlInKrZ/vrwKNALPCqJ1FkqWq8v2Iyx2tQoyq3DGzFLQNb5Vs/t91jpH/5Pes+fpAxmQ8QGiI0q12NR/63nF837OXp4V2oHhl+cic/tBfeOhu6XwUD7i9+3/TdkLoVzvwjzH3OTWNrib1w6QVK7OC+DNUr2CnFGBOM/DpAjapOA6YVWPe61/MbgRv9GYM5MWd2a0v67ns468eneK/3brqcNYpa1SJ4c+4G/jljNcuSU7nxzJYMaBNHs9ioEzvJog/csLbfPQkR0XDarUXvm3tfvdVZsPRzV3o3hTu4GyTUDUqUl9ity5sx5WLzL7Dif24mz6jYgIRgrWlMkaIH3AH1u5Kw+H5iN04hJES4ZWArPrn5NEJFeGTSMgY+O5sB//yef369ik17SjHYTU42zHsLmp7uuut9/SAs/rjo/bctBATqd4WG3QPXgE4VptwD62YF5vy+OLgbouJcY7ncqviK1uVtx1JIWR/oKIwpe8s+h4XvQ0S1gIVgQ8qaokVUg9FT4eNR8MWNruq81SDij6xnVr91pCWv5mDyakIPbGH/zyHs+jmandXiWNT8Jo7EdaZWVDiRYaFEhIUQGR5Kv9axx6rv1810A+ec87hr0f/R5fC/292kN6fdClVi8seSvAji2kBkdWjQzX0jPrzPlUrL07YFsOBdd1ug9dnle25fHdztquHBvY9hVUuf2DMOQGiEm27YHz69Dmo2gWv/55/jGxMIOTmwapqrWQyvGrAwLLGb4kXWgKu/gM/HwPQH8lYLUD2yJtVjW0HDflTPOEK1PTuISU2k9aq7ueTI42zVevkOVT0yjBv6t+T6/s2p/vsbbsjTDhdDaDiM/Ai+vBW+/zv8+iqccbfrbhfmafiXvAhaJrjnDbq7x+2J0HKg39+CfBI/dY8b58LRQwH9Vl4k78QucqzLW2m8cwE06gnDXi77+DJS3fTEh1JK13jSmIpu+yJIS4b2jwY0DEvspmThVeGK8ZA4wd27jW0Fsa3ztbKOxDNs4J618Pa5zKn9MilXTuFweC0ys3PYnXaEt3/cyAsz1zDjx5+Zxky+qj2a36au5ozWcQxqV5eIkR9C0gKY/TTMfMzNF3/xv+DAdkjfAQ17uJPlPm5fXL6JPTsTln0B1RvDgSQ3al+7C8rv/L46uNvNBZCrtKPPpe2EXcvda/zR/33HMveYsd/VfNS0QadMkFj1lfuMbHt+QMOwxG58ExoGPa4ueb+4NvCHT5H3LyZu8jVw3RSIiKZlnWj6toxl2bZU9nzxR7L2hvLukYGsWriN//6ymVrVwhnSpQE5GsG69PsYFlKVqxe8x85mw6gXkeGOnZvQq9WGGk1dy/jiHD3ounnVbObiP1kbZruhWi9/DybdDmtnVMzEnu5VYgdXYi/N/eyk393joT2wc6m79VEayya6czYvdLwp2JF47Pn2REvsJnis+gqa9Qt411JrPGfKXpM+MOIdV33+Vf5ubJ1rHCXh0DeEdRrK5w9cxuJHz+Xd0b05o3Ucny1IYvqy7QAsaHkrSVqHtC9u54dZU1AJhfpdjh2oQdfCW8ZnHYFProFnW8P/NYR/94Tvn/I99s2/wOH9hW9L/AQia0K7C6HVIFjzjatKLszBPZCZcfz6Hcvc/Wt/OXoQMg+6CWBylbbEvvV3CPF8EVr/fenOn74LvrwFvi2mKnJ7omsbISH5k3xll5oEu1YFOgpzovasg92rXGPgALMSu/GP9he67h4//MM1Musyws3K9um17nGAu18fFhrCoPZ1GdS+LlnZOYSGSN7gN/sS/03jiSNpuusTVtOICV9v5LaEVlSvGs7+qPbU3zuV/5v4K4t25bBxz0Eu7taQv8Z8RdjKydB1JMS14ei6Hwj77XXSe9xKVK26hIYUcz939dfw8ZWuMd+oAi30j6S7b+Ndr4SwCGhzLqyaCrtWHt8/PCPVfaGoUh3O+zt0HOYS/Yy/wNJP3fIV/y3Ld/uYg3vco3eJPaa+Gz8+66iLvSRbf4dGveBIGqz/Dvrf4/v5f38Tso+6L3WH90PVmsfvsyPRHX//VpfkjfP5De72070ryqaGyZSv1V+5x/ZDAhsHVmI3/jTgT9DkNJh6r5tu9euHYMvPrkFWvU7H7R4WGpJvRLtaXQdDlyuIkGzSandh/K+b6f+P7+n02Awe/MUNj7tmyS+oQo+mtfjmp3lkzx7H4TYXseHM57gn+WwuXnchIZmHeO+FP9H6r9O45u3fmLNmN1qwpH0g2U2AE1YVVk+DLb/l377qK8g8BF2vcMttznOPa2ccf92LP3LJPTQCPrvONUR7OR6WfwmNe8OKyf4rmXmPOpcrt8tb7rbiZB1xSblJH9eyd8uvrpGgL44ecl0YazZ1k9Bs+rHw4+9e5botNuh6YiX2bQuO3acPFnvWwtZfXc3Kej91pUzdVvLtq8rm6MGy63a56iv3d10Bbi1ZYjf+ExoGw98EBN4ZDPPfhn53udK7ry54Gup2pPf5V/HdHwdyzenNuC2hFddeOhRFeLfNT3w+uiNvXhvPFy2nkq1w8dohnPP8D8xYvpOB/QeSVP8cbq0ykzv71WH1jjSufed3Bv9rLjOW73AJPicbvrjJJZ0bZriq65mP569mX/op1GjivqgAVG/obg2s+SZ/vDk5rtTauDfc/jsMGecSWb3OMPYnGPUJhFeDH58/2Xe3cHmJPe7YOu/R50qyPRGyj0DjPtBykHu+5Wffzr3kI1czMPTfEB7l2iQUtGsl5GS5965+VziwDQ6WYoqIjFT4YDh8cpX7vZWV9d+V/rZDWVr0gWt0FVkDlhQznsOJOpgC75zv/g8P7yt5f39RdVNDVwQp6+GNQfBKH1fwOBlpO11NVwWohgdL7MbfajaFi190XUBane36rZdGVBzc9gu0v5BmsVE8clFH/nheO87u3RkZ/A9kw/fwRgL8/DL1k7/l0On3UadhK64/owVz/jSIvwzpQONhjxKRnc591Wcz98FBPDuiK9nZ2fxl/Hc8+p+P2f+/B2Hzj0xv/gAXf57GlJrXuGS29huXqGf9zfW77/6H/C3E25zvppD1/qDc8J3rytXnZvfFps9N8MB6uP4rqNPOjUQVfz0s/cyNugeuinz2M4UnwtLKS+x1j63LG6TGhy5vWz01FU36uEZAoRG+JbycHPjlVWjYE1oMhOZnFH49uSX0Bt1ciR1gRylKkb+84t7vfZtgzde+v644m36CDy+HL25wv4vylp0FSya42ztdR7p+0GWZfLOz4PPrXUPSzIOwcHzZHbu0Zj0BL3V3JWVvh/bC1nkndszdq93/6Ly3YO23LsmWZO1MeHOQ5/9F3N/VyVj8IaDuFmQFYDdyjP91vgxqNHbV7yGhZXfcvre4BPHZ9fDNXyG2DXHn3MfHBe8jN+gGbS+AX16hSlwbLt8ynRFHpyORB2AHsAO+yD6T+5e1pWsjuH9DN7pG1Cdm8l8Jr/8BMesmk9J2JHOrj2L5VytYtSONmMgw+ke25w+azaHl06gWf5U7129vuKTa8ZJj5y94v7Tfna5U/+MLcM4TrrHf5h/dbYDrpkCT3if+npxsiT3pd9eLIKa+W256mm+Jfc1094VmxDuuX3rLBPfFKHUb1Gh0bL/tiRAR47rj5Q4utD3x2Lj/eze6e/R12hVybSnuA7j9Ra5K+dfXiv4gPXrIxVHSICH7t7p2HxFRrl/92m+gQzmXutZ/57pz9rja/Z/8/h932yZ+TNkc/7snYeMPMOwVN7rj72/CabeV/3389F3ud5aV4ZLwGXe79arud7DpR/f33+LM0h3364fce5grPApung112ha+/8op7nx1O8HID107oIXjYeBDJQ8Bu24W/PYfuOh597sCd7vq+6eg7eBCbzEGgpXYTflo0sd9eJa1pqfBrXMh/ga47D9FNw4b8CfXb/qz0bD2G6TDUBj8LKlD32F8p7c5cP6/+O3PZ/O/O/oz+a5B/K/W9dROX0vMusk8kzmSXokXc89nK3j/l83sPXiUldvTeHR+JJty6iFT72XVt++6Evjab6DX6ELjOJKVzYTftzArSdCe17oP2TfPcsl0yDio3gA+usK1rgXXen7B+/DdU66V+dd/dh+I+za77aqu5LrsCzeVLbiubhEx+RNa7v32giX2nBzIPHxsWdVVJzbpe2xdq7Ncn/a0Hflfd/SgO96ab1xcU+9zXRA7DHP7tPCML7Dxh/zn3JEI9Tu7mo9qtd3tjdxS/NGDrrr4lT7w1rmuetq7ZPfj866dw9mPuhqRTXMLb3x3aC/850x4qWfh9/lzHT0EE/7gvkiM8dyCWfxh0fuX1pbfIPGzYw0aAXavgVlPwtznj9UOLP4AqsW6GqAG3aFOh/zDKx9Jd9d0IpZNhJ9ehF7Xuy8Op42F1C3HGnqVpCyrzX952Qx14t4AABmwSURBVL3X9bvAT/9y1wWuEeqmue5vduLNpbvW3atdUk/4C9y30n0xCKsCE28suvZlzjiIbeNuu9Vq5r5oZx2GeW8e2+dImhv22NvRQzD5Lteu5q1z3W2ltJ1uFMUaTeDS1yvMYEtWYjenvqg49w26OI17uf7nkTVd/+pQN7RtDeCanvl3bVc/hrZ3PsC2z1PYHtOZ7k3O5+1QoUntarSMiyIs1H0fPpKVzYo1bUn7YjRdfrqH3fObEiehrGw0gpxtqdSJqULdmCqICN+v2sUTU5azKcU1ROtbuy8f67uQcYCQ66a4LyitzoK3z4MPLnMl3qWfu6pTgNAqrgta7nJcW5f0Dmxzy9XiYPRXrsTu3dUN3Add1Vruw3Tem64bXtZh9yELrgQ84l1Xakzb7r6E5Wo5CP6/vTMPj6s6Ev2vWi21NmuzFu9abGO8YGMMBmOWgGHA4JgkEwYCBAJMyIJJmMnLS8jO5M17eS8kk4QxMQQIZHDCTiBAGLMZh8U7xtjygiwvkmxrtXa1ejvvj2pZbVm2ZUdCuFW/7+uvu8+9ffvUvd236lTVqcNPdEW9kB/K3tDiPIccP1lr/l/w7e5RYP4UNSjKl2sIAzQmvn8TzLy++7MjpncndK28T70KcxapgfT87bDshzDndq1QuOZBdVXnTdLwwvKfwaol8Jn7uo8X9KuybqzQPIhHP61GXWzfQI2YFxbpzfu6JyB/ss54eG+xGizpMaGMY7H1ZfVWnLoAcopVMS37QYyRIHpOIyFN/BOPJhdufQmuvEc/P/vL3cbg6V9QQ65+B1Rv0imj4tGQ1PHMjy59Hp79suaFzP+/2jZpvnpkVi7R2RlHonozPL9In0su1M9NvOxQ70tPOlv0kTHq8G3tDbD6QZj6OTj7q/DQJbD6Ab22y36gxsxnFmui6fOLdCTdFyW5aon+N866Ve8DGaNg4W/giRt0FH3p3YfuX7VeC1tdcU/3QCN/snr0Vt2vOUCt1fDHa6Bum1bE7PIKvXuv/vavuEeNg4cvg+wizfu44ZneZ4AMEnJYdvAnnDPPPNOtXbt2sLthGAfx+zvY+NAiZtc+zV/C53BH8BsHt6X7vORn+CivbaMkL40fLZhCsz/EQ2/vRCrXUu8ZzoQJp3D5tBGcMS6bcR1b8C29ShXPaf8Is27R0q4i2lZfpnHEHW+ALx0K52olwOe+psoiJUuV+K09kvpWPQBVa1UJJ6Z0P3cc0Jvj1M+qK/G52+ArK7qL0kQi8ItT1GDwZajBkT9ZEwATUyF3gir13lzeT9+qI7FvbdP+15XBf86Chf8JZ3xR91n+M318cwP89jxVItcuVVl3v6vGSNfMA08i3LFWb6agCm/9o3DnJhhWoJ955p91EY7PP6wzF17+tiajlVwE1zym5wzg7V9pdcN5P9KlgEFHf4tnwz/8O5y76NgXPhzSY7wXU3Z31Ez1nvibVEmceqXmZ2x/Ra/Paf8Ep10Ne96DF+5QRYiDr76jngzQSov/MQUyRmtlvoJp2rdTr1TjtDeFFwlr8mdXieNNz2hC6Jiz4PqndI2FLt5brFMvb3tLF1SKJdih53zFPZrIN/nT+ltrjHqJckr0Nzdujsqae4omTK78Lax5CCJBHTWP6bH69hv/C1b8HL6+Un8/S6+GyjXqafvbPfDF59Swfe8++O+7NFQgnm5D6Mpf6OdiaW+AX07R/8lVPWLkL3wD1v/hcNf+84vUi/GtrYeek93vwu/nwxk3qsEVCauR0LgHbn1V9733TC1IdfUj6jV77HP6f/zcgzD96l5+IP2LiKzr67LmptgNo5/Y/f5r7E4YRzAxk3DEsb/ZT3ltG7vr2zinZDg3zy0myaujfeccGyoaeWnjPl7ZvJ/KA90u8WnprRSOzOe0CeOYXZzD6KwUkhI8JCQIGyuaeH1rNW9tryUpwcPUUZlMHZXB/BHNjHzuH1UBn7pAlWNfeefXOkJMzlRl9d09h45u922EzmZ10Uc9HX1i/R9UeX19FeSfqsrm6VsONRy2vgyPf0EVUNU6vfH3jK/v3aCjpZHTu+Oy0G0oFJ6nSZote9VDEKusu/rxlztVEV3/FFSu1ZDH1M925wR08bt56u7/2ruHK9DKtRpuSctVz88bP1WlN/s2dXFveRFK/6wjwct/dux4a8NOLeaTmHL4Yjh/vEZzGz71HTUQ3v2NJoj1VCLVpTobYeOTOtIcNlLzFypWqvK97sluY6YLf5MqxPwpmiDpIhou2L9RZ3BEQmqAXP4zjTk7p27n8jc1tLH7HT0GaF6Ii6j3Z8pC9b74m1UZ5k7QfToa4VenqdF2zWPaVrVek9dADcrrHtfXzum1+WiZGp8jZ+h56myBK36u4YSu69JlnMUaRV0E2uD+C9R9ftub0VoOjfDLyWpYLfzNofs7Bw9dqsZGznj9nSSmaGJuYop6FMrfhEVruqezdRzQ81809+jXuZ8wxW4YJxHOObbub2F7dQsVDe3sqm9nQ0UjZTWtve6f5PUwp0STfDbvbaautZPEBOFfZ0T4yq47cadfx9tFd/BaaTUicErBME4dMYwx2akMT08iMaGX1JquEVXxBTrK6Q8a9+gNfd6P4bx/0SmE7y2G7+3tdjs3VenoFHS0tPDe4/uOF+6AbX9VJeD16Qhz3o8PV8pbX9Iky+wizRfIHqdx9Z55H2segpf+VZOvRs3UkdvWl9Sw6Cq124UnUV3ps750fH3uSW8L4fibdfQ8LJr4GAnriLJ2K9z0oo74N/xR3coer3onRs1UJVhfprHjT//6yHktb/5vjfOLR787OUtj3yOnq1em+IIj9zcS1u/Yu0G/3zk4659Vkdfv0HBSYipc/6Qqyvcf09kWsQYd6KqRH70Kt69Sr1MXgXY1oPImqSHZUq0hhZ1v6fWddbMaJPeeqaGPL73Yez/3bVTXfu5EuPlleH+pLmR12/Lu8tSxVK3Tvl78w+6QR8UaeOQKNVwu/A5c9L0jn5cBxhS7YcQBda2drN3VQENbkEAoTDDsKM5NY+6EXFKSumcXVDS0s/jNMp5cW8HwpDCdkkizP0JqUgIeEVo7D02AykpNZGx2KuPz0hifl875p+Rx+phMWPeIjuLGnU1PIhHHuzvqeWpdBV6Ph0un5HP+xDzSfMdI07n3TKj/SN34iI52vhaT0OYc/Hy8jrC+8X7v8dn+YucKVSZen97ceysk0tEI95yi2xISVVGGOjQuPWeRKr32Oo3D50063D08kDSUa7iiK89ixHTNXzjt6kNnQQw2VevhkQXd/cwugrO/pssxxxJo0zK6vc2A6EkkrIbIO7+GQItmvgfb4No/Hb3S27ZX1CN0ynw9f4kpOoI/HjY9Ax88AVf/fmASgPuIKXbDGIJsr25h8ZtlJCZ4mD9tBHMn5OLzeqhq7GB7dQt7G/3UtXZS19rJnoYOdtS0UtWoIYCZ47K4eW4xF07MY1iyF49HaPYH+aCikbW7DvD8hip21beTlZqIc9DUEdRQwOgMSnLTKclL4/SxWZxZlI3Pm0Ak4li+vYZX/raaaZ3rmZu+l8LQLrzTP6+JYrG8d5+6i8+4sVe5nHMsK61mR20raUleUpISqG3pZPPeJkr3NjO7OIf/87npRy8X3EVXIZKuOH1vvHa3egFyijWmPPZsjW/351TNE2XbX3X0e9rVn5ipVb2y+10NU5x6pWb691e2eNCvlfk2/1kNrqsfPfZ1WfVA95LTsfkdJxmm2A3D6BPN/iDPrqvkkXd3HczYF4FhPi8tnaGDxffOKsrmhnMKuWzqCLweYe3uA7y+pZpNVc3sqG2lpqUTgNSkBOaUDGdHbSu76tspyPCRIMLeJj9JCR4unVrAbeeXMGNs3zKI1+85wE9fLOX9PYcvzDMuJ5WxOSm8U1bPl84t4icLj67oAqEIT6zZAyJce9bY3kMSRnzy2k90/vpXVgzqqPvvwRS7YRjHRSTi+FtZHWU1rTS1B2jsCJKb7mPmuCymj8kiM+XoSXPN/iCryxtYvr2Gtz+qY3i6j5vOLWL+tBEkiLChspEXP9jHU+sqaPGHOLs4h0unFJCdmkRWaiJZqYlkpujrygMdrCqv550d9azYXkveMB/fvmwSC6aPxB+M0NYZIiMl8WCf/u0vpTz8zk5+tGAKt5xX3Gv/3thazU9f3MLOOnUPT8xP5+6rpnLu+E+QC9sYWHrLZTiJMMVuGMYnktbOEI+v3sPDb+9kb1Mvy9rGMD4vjQXTR3HbBSVHjeWHI46vL13HstJqbppTRMQ5GtuDNHXoo6EtwJ6G9oPTDUNhx0/+spnKAx2cNjqTggwfw9N8RJyjuqWTmmY/o7JS+MoFJcwuzjlkYaJQOMKy0mr+673dNHYEOackh7njc5k+JpPh6b6+hQMM4wQwxW4YxieaSMTR4g/R2BGgsT1IY0eQxnZ9PTw9idnFOeQPS+7z8ToCYW55ZA0rd9aTGR3Nxz5mFWZz/dmFB6cb+oNhfreinNW7GqhrDVDX2okAIzKTyR/mY0NFI3WtAWYVZnPRpDzta3uQFR/Vsq/Jz5jsFAqHp7J21wE6QxEAPALD032MzU5h2uhMpo3OJDUpgbKaVspqWtnb2EFDW4D6tgBej1Ccm0ZxbjoZKV6aOoI0dwTpDEXweT0kJngIhCLUtHRS0+Inf1gy35w3kXmT8w8xNI5G12yLiHNMHZV5xP0+qm6hrjXAOSU5Rz12OOJYu6uBv27ajz8Y5uufmsC44al9vkZ9pb61k49qWplVmG3hkhhMsRuGMeRwzuEcePph1OwPhnlybQX3v1VOVWMHPq+HzJREJo0Yxo1zirj41HwSPII/GGb9ngPsqGmltqWTmpZOyuva2FzVRFtAV58TgdFZKYzLSSUnLYncdB+doQg761opr22jIxA+GFpI8noIhiMEQhESEzzkZ/jIS/exdvcBdta1cca4LL58fglTRmUwJjuVzlCYd8rqeWNrDdXNfkZmJjMqK4WGtgDLSvdT0aDJkZdMLuC78ycxIX/YQRk3723i3tfLeGWzlgueMjKDOy6ewGVTRxxyDnfWtbF05W6e/2AvtS2d+LweRLR20a3nF3P7RRNIP8bsiGA4wqryBpaV7qe5I8iX5hZzei95FqvK67n9j+9T19pJTloSC2eM4pLJBQxL1qTJzJRE8tJ9R7zGLf4gHcHwcRmFJwum2A3DMPqBSMQRCEdITjy+jPhIxLGzvg1/MExJbvoh0xNPhGA4wtPrKvnVa9upbtZERZ/Xg3MQCEdI93kZk51CdbOfA+06Y+G8ibn8w5QC6tsCLFm+g7ZAiDMLc2gPqveh8kAHw3xebp5bxJjsVJa8tYPyujbyh/koyUujMCeNfc1+VmyvxesRLplcwIIZI7loUj4t/hD/75WtPPt+FV6PUJCRzKisZLJSkwiFIwTCEYIhPXfBcIQ9De20+EMkJ3pISvDQ7A9x/sRcbpxTxLicVAoyfDy7vop/f3kLhTmpLLp4Aq9vqeHV0moC4cgh5yI50UNhThqFw1MpytXnSMTx6pYa3ttRR8TBoosmcMfFEw6Wf/6gopHSfc2cXZxDcW7aET0TzjnaA2HaAiFwkBctCf1JwBS7YRhGHOIPhind10xZdSvbq1vweIQLT8njrKKcg2GGjqinINaYaGgLsPjNMjZUNJKZkkhWSiITCtK5/uzCg0mI4YjjpQ/3sXxrDbsb2tld305SgnDNWeP4wuyx5GccPgreUNHIss372dfkZ29jh06D9KryTkzwkOj1kJQg5Kb7mDe5gPMm5BJ2jqUrd/O7v5VT13roQi2XTingF/80g4xk7VNTe5DN+5rwB8N0BCI0tAfYU9/Gzrp2dte3sbuhnUA0FFI0PJVLpxRQ1xrguferOH1sFjedW8ifVlewemf3wjLjclIPTstM8IA/qIZHRUM7+5v9xKrEdJ+XCfnpFA5PJTXJS2pSghpUaC5eSmICU0ZlMH1MJgUZyRpi6gzR4g8yOiulX40CU+yGYRjGJxp/MMyHVU1UN/upbu4kKyWRz84cfVyhlEjEsa/ZTzAUoXB46kFF+uLGvXzv2Q9p9ocYlZnMLecVc+Epeawsr2f5tlpK9zUTijgiEYc3QRiXk8q4nDRGZyWTnuwlNclLOOIor22lrLaVioYO2gNhOgIhOkMRREAQgpHIQUMgNSmBjmD44PtNd192zBDF8WCK3TAMwxjSVDf72V7dwjklwwcsCa8jEKZ0XxMbK5uoaOggPdlLRrKXjJREFs4YddwhnKNxPIrdlm01DMMw4o6CjGQKegkf9CcpSQnMKsxhVuFxLKf7MWBzCQzDMAwjjjDFbhiGYRhxxIAqdhG5XES2iUiZiHy3l+0iIr+Jbt8oImcMZH8MwzAMI94ZMMUuIgnAYmA+MAX4gohM6bHbfGBi9HEb8NuB6o9hGIZhDAUGcsQ+GyhzzpU75wLA48BVPfa5CviDU1YCWSIycgD7ZBiGYRhxzUAq9tFARcz7ymjb8e5jGIZhGEYfGcjpbr1VGeg5ab4v+yAit6GueoBWEdn2d/Ytllygrh+PdzIw1GQ2eeMbkze+MXmVwr4eYCAVeyUwNub9GGDvCeyDc+4B4IH+7iCAiKzt66T/eGGoyWzyxjcmb3xj8h4/A+mKXwNMFJFiEUkCrgVe6LHPC8CN0ez4c4Am59y+AeyTYRiGYcQ1AzZid86FRGQR8N9AAvCwc26ziHw1un0J8DJwBVAGtAM3D1R/DMMwDGMoMKAlZZ1zL6PKO7ZtScxrB9w+kH3oAwPi4v+EM9RkNnnjG5M3vjF5j5OTbhEYwzAMwzCOjJWUNQzDMIw4Ykgr9mOVvD3ZEZGxIvKmiGwRkc0i8s1oe46IvCoiH0Wfswe7r/2JiCSIyPsi8mL0fdzKKyJZIvK0iGyNXuc5cS7vv0R/y5tE5E8ikhxv8orIwyJSIyKbYtqOKKOI3BW9h20TkcsGp9cnzhHk/Xn0N71RRJ4TkayYbXEnb8y2/yEiTkRyY9qOW94hq9j7WPL2ZCcEfMs5Nxk4B7g9KuN3gdedcxOB16Pv44lvAlti3sezvL8GXnHOnQrMQOWOS3lFZDTwDeBM59w0NCn3WuJP3keAy3u09Spj9P98LTA1+pn7ove2k4lHOFzeV4FpzrnpwHbgLohreRGRscClwJ6YthOSd8gqdvpW8vakxjm3zzm3Pvq6Bb3pj0blfDS626PAZwanh/2PiIwBrgQejGmOS3lFJAO4AHgIwDkXcM41EqfyRvECKSLiBVLRuhdxJa9zbgXQ0KP5SDJeBTzunOt0zu1EZxjN/lg62k/0Jq9zbplzLhR9uxKtcQJxKm+U/wD+J4cWaTsheYeyYh9S5WxFpAiYCawCCrrqBUSf8wevZ/3Or9A/RySmLV7lLQFqgd9HQw8PikgacSqvc64KuAcd0exD614sI07l7cGRZBwK97FbgL9GX8elvCKyEKhyzn3QY9MJyTuUFXufytnGAyKSDjwD3Omcax7s/gwUIrIAqHHOrRvsvnxMeIEzgN8652YCbZz8bugjEo0rXwUUA6OANBG5YXB7NejE9X1MRL6PhhSXdjX1sttJLa+IpALfB37U2+Ze2o4p71BW7H0qZ3uyIyKJqFJf6px7Ntpc3bWKXvS5ZrD618/MBRaKyC40tHKxiDxG/MpbCVQ651ZF3z+NKvp4lfcSYKdzrtY5FwSeBc4lfuWN5Ugyxu19TERuAhYA17vuednxKO941Fj9IHrvGgOsF5ERnKC8Q1mx96Xk7UmNiAgaf93inPtlzKYXgJuir28Cnv+4+zYQOOfucs6Ncc4VodfzDefcDcSvvPuBChGZFG2aB5QSp/KiLvhzRCQ1+tueh+aNxKu8sRxJxheAa0XEJyLFwERg9SD0r18RkcuB7wALnXPtMZviTl7n3IfOuXznXFH03lUJnBH9f5+YvM65IftAy9luB3YA3x/s/gyAfOehbpuNwIbo4wpgOJpZ+1H0OWew+zoAsn8KeDH6Om7lBU4H1kav8Z+B7DiX925gK7AJ+C/AF2/yAn9CcwiC0Zv8rUeTEXXj7gC2AfMHu//9JG8ZGlvuum8tiWd5e2zfBeT+PfJa5TnDMAzDiCOGsiveMAzDMOIOU+yGYRiGEUeYYjcMwzCMOMIUu2EYhmHEEabYDcMwDCOOMMVuGEa/ISKf6lpVzzCMwcEUu2EYhmHEEabYDWMIIiI3iMhqEdkgIvdH17BvFZFfiMh6EXldRPKi+54uIitj1sbOjrZPEJHXROSD6GfGRw+fLt1rxC+NVokzDONjwhS7YQwxRGQycA0w1zl3OhAGrgfSgPXOuTOAt4AfRz/yB+A7TtfG/jCmfSmw2Dk3A63Zvi/aPhO4E5iCrkA3d8CFMgzjIN7B7oBhGB8784BZwJroYDoFXVQkAjwR3ecx4FkRyQSynHNvRdsfBZ4SkWHAaOfccwDOOT9A9HirnXOV0fcbgCLg7YEXyzAMMMVuGEMRAR51zt11SKPID3vsd7R600dzr3fGvA5j9xnD+FgxV7xhDD1eBz4vIvkAIpIjIoXo/eDz0X2uA952zjUBB0Tk/Gj7F4G3nHPNQKWIfCZ6DF90XWnDMAYZs6QNY4jhnCsVkR8Ay0TEg64ydTvQBkwVkXVAExqHB10mdElUcZcDN0fbvwjcLyL/Fj3G1R+jGIZhHAFb3c0wDABEpNU5lz7Y/TAM4+/DXPGGYRiGEUfYiN0wDMMw4ggbsRuGYRhGHGGK3TAMwzDiCFPshmEYhhFHmGI3DMMwjDjCFLthGIZhxBGm2A3DMAwjjvj/G8FJ3Zh8z54AAAAASUVORK5CYII="}}],"execution_count":0},{"cell_type":"code","source":["# !tar -cvf /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0325/Model/Best_Model.tar /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0325/Model/Best_Model"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"05fb8785-f608-41fd-941d-68fbf41626d1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.8.3","nbconvert_exporter":"python","file_extension":".py"},"application/vnd.databricks.v1+notebook":{"notebookName":"MobileNet V3 Small","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2679691984810977}},"nbformat":4,"nbformat_minor":0}
