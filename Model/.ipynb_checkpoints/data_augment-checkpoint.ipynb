{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from PIL import Image\n",
    "import os\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "# import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T08:52:45.999183Z",
     "start_time": "2021-05-27T08:52:40.899Z"
    },
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c9656def-8fa9-4254-ae11-5c925b7b14ab",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "BASE_PATH = '/'\n",
    "DATA_PATH = 's'\n",
    "\n",
    "batch_size = 128\n",
    "img_height = 120\n",
    "img_width = 160\n",
    "\n",
    "resized_height = 120\n",
    "resized_width = 160\n",
    "\n",
    "num_classes = 2\n",
    "NUM_EPOCHS = 120\n",
    "seed = 12\n",
    "log_dir = BASE_PATH + \"/logs\"\n",
    "\n",
    "STEPS_PER_EPOCH = 1508 //batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T08:52:46.001178Z",
     "start_time": "2021-05-27T08:52:40.903Z"
    },
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8ca43b61-ceac-4d55-87bd-0e8daef5e137",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "  layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "  layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T08:52:46.003174Z",
     "start_time": "2021-05-27T08:52:40.905Z"
    },
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "72f19628-2664-4635-a029-5afed0acc053",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def augmentation(img,num=0):\n",
    "  if num == 1:\n",
    "    if random.random() > 0.5:\n",
    "      augmented_image = tf.image.flip_left_right(img)\n",
    "    else:\n",
    "      augmented_image = img\n",
    "    augmented_image = tf.image.central_crop(augmented_image,random.uniform(0.6,0.8))\n",
    "  elif num == 0:\n",
    "    augmented_image = tf.image.adjust_saturation(img,random.uniform(1,1.5))\n",
    "    augmented_image = tf.image.adjust_brightness(augmented_image,random.uniform(0.1,0.3))\n",
    "    augmented_image = tf.image.adjust_contrast(augmented_image,random.uniform(1,2))\n",
    "  elif num == 2:\n",
    "    augmented_image = img\n",
    "  return augmented_image\n",
    "\n",
    "# i = tf.keras.layers.Input([img_height, img_width, 3], dtype = tf.uint8)\n",
    "# x = tf.cast(i, tf.float32)\n",
    "# x = tf.keras.applications.mobilenet.preprocess_input(x)\n",
    "# core = tf.keras.applications.MobileNet()\n",
    "# x = core(x)\n",
    "# model = tf.keras.Model(inputs=[i], outputs=[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T08:52:46.005168Z",
     "start_time": "2021-05-27T08:52:40.909Z"
    },
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e3d81e33-d0b7-43a5-9ed4-b792e6eeb2cb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ls /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/Data_Augmentation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T08:52:46.007162Z",
     "start_time": "2021-05-27T08:52:40.913Z"
    },
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f0528052-9999-4f87-ac61-b1aa001bc59e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "rm /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/Data_Augmentation_positiveimg_R2NO2326-202104_29--15_28_56--255_9_.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T08:52:46.009157Z",
     "start_time": "2021-05-27T08:52:40.916Z"
    },
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "1337f1db-3ddc-4335-8561-cd38d54d493b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "image_raw =  tf.io.gfile.GFile('/dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/Pictures/positive/img_R2NO2326-202104_29--15_28_56--255.jpg','rb').read()\n",
    "img = tf.image.decode_jpeg(image_raw)\n",
    "plt.imshow(img)\n",
    "for i in range(3): \n",
    "  a = augmentation(img,num = i)\n",
    "  plt.figure(i)\n",
    "  plt.imshow(a)\n",
    "  plt.show()\n",
    "  final_img = tf.image.encode_png(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T08:52:46.011152Z",
     "start_time": "2021-05-27T08:52:40.919Z"
    },
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "16e6a387-90d6-452e-93e9-dc23a31aceb7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "files_name = os.listdir(DATA_PATH)\n",
    "save_path = '/dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/Data_Augmentation/'\n",
    "number = 0\n",
    "x, y = [] , []\n",
    "for files in files_name:\n",
    "  sub_path = DATA_PATH + \"/\" + files\n",
    "  print(files)\n",
    "  sub_files_name = os.listdir(sub_path)\n",
    "  for image_path in sub_files_name:\n",
    "    image_path2 = image_path\n",
    "    number += 1\n",
    "    image_path = sub_path + \"/\" + image_path\n",
    "    image_raw =  tf.io.gfile.GFile(image_path,'rb').read()\n",
    "    image_raw = tf.image.decode_jpeg(image_raw)\n",
    "    for i in range(3):\n",
    "      img = augmentation(img,num = i)\n",
    "      if files == 'negative':\n",
    "        name = save_path + 'negative/' + image_path2.replace('.jpg','')\n",
    "        name += \"_\" + str(i) +'.jpg'\n",
    "        with tf.io.gfile.GFile(name, 'wb') as f:\n",
    "          f.write(final_img.numpy())\n",
    "        print(name)\n",
    "#     print(number)\n",
    "# x = np.array(x,dtype = 'float')\n",
    "# y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T08:52:46.013146Z",
     "start_time": "2021-05-27T08:52:40.922Z"
    },
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "3d34c0a7-0212-448e-ae15-3d904f35836b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T08:52:46.015141Z",
     "start_time": "2021-05-27T08:52:40.925Z"
    },
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "5dc62fe8-014f-49c8-81cd-336843afd5f1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "image_raw =  tf.io.gfile.GFile('/dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/Pictures/positive/img_R2NO2326-202104_29--15_28_56--255.jpg','rb').read()\n",
    "img = tf.image.decode_jpeg(image_raw)\n",
    "\n",
    "img = augmentation(img,num = 2)\n",
    "plt.figure(i)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T08:52:46.017135Z",
     "start_time": "2021-05-27T08:52:40.928Z"
    },
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "0fb1c5ad-afa4-4222-9903-064496f1f318",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "LB = LabelBinarizer()\n",
    "y_ont_hot = LB.fit_transform(y)\n",
    "y_ont_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T08:52:46.018137Z",
     "start_time": "2021-05-27T08:52:40.933Z"
    },
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "99ce880e-5476-4f8e-b471-653a76a034d4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "  layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "  layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "  layers.experimental.preprocessing.RandomZoom(0.2),\n",
    "  layers.experimental.preprocessing.RandomContrast(0.2),\n",
    "])\n",
    "\n",
    "resize = tf.keras.layers.experimental.preprocessing.Resizing(resized_height, resized_width)\n",
    "\n",
    "def preprocess_input(image):\n",
    "    return (image/127.5) - 1\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  DATA_PATH,\n",
    "  seed=seed,\n",
    "  shuffle=True,\n",
    "  validation_split=0.1,\n",
    "  subset='training',\n",
    "  image_size=(img_height, img_width)\n",
    ")\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "train_ds = train_ds.map(\n",
    "  lambda x, y: (data_augmentation(x, training=True), y))\n",
    "\n",
    "train_ds = train_ds.map(\n",
    "  lambda x, y: (preprocess_input(x), y))\n",
    "\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  DATA_PATH,\n",
    "  seed=seed,\n",
    "  shuffle=True,\n",
    "  validation_split=0.1,\n",
    "  subset='validation',\n",
    "  image_size=(img_height, img_width)\n",
    ")\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.map(\n",
    "  lambda x, y: (preprocess_input(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T08:52:46.020127Z",
     "start_time": "2021-05-27T08:52:40.935Z"
    },
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "fdecf590-69e1-4548-be8e-746ec23f9612",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class CustomLearningRateScheduler(tf.keras.callbacks.Callback):\n",
    "    \"\"\"Learning rate scheduler which sets the learning rate according to schedule.\n",
    "\n",
    "  Arguments:\n",
    "      schedule: a function that takes an epoch index\n",
    "          (integer, indexed from 0) and current learning rate\n",
    "          as inputs and returns a new learning rate as output (float).\n",
    "  \"\"\"\n",
    "\n",
    "    def __init__(self, schedule):\n",
    "        super(CustomLearningRateScheduler, self).__init__()\n",
    "        self.schedule = schedule\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        if not hasattr(self.model.optimizer, \"lr\"):\n",
    "            raise ValueError('Optimizer must have a \"lr\" attribute.')\n",
    "        # Get the current learning rate from model's optimizer.\n",
    "        lr = float(tf.keras.backend.get_value(self.model.optimizer.learning_rate))\n",
    "        # Call schedule function to get the scheduled learning rate.\n",
    "        scheduled_lr = self.schedule(epoch, lr)\n",
    "        # Set the value back to the optimizer before this epoch starts\n",
    "        tf.keras.backend.set_value(self.model.optimizer.lr, scheduled_lr)\n",
    "        print(\"\\nEpoch %05d: Learning rate is %6.4f.\" % (epoch, scheduled_lr))\n",
    "\n",
    "\n",
    "LR_SCHEDULE = [\n",
    "    # (epoch to start, learning rate) tuples\n",
    "    (10, 0.005),\n",
    "    (30, 0.001),\n",
    "    (50, 0.0005)\n",
    "]\n",
    "\n",
    "\n",
    "def lr_schedule(epoch, lr):\n",
    "    \"\"\"Helper function to retrieve the scheduled learning rate based on epoch.\"\"\"\n",
    "    if epoch < LR_SCHEDULE[0][0] or epoch > LR_SCHEDULE[-1][0]:\n",
    "        return lr\n",
    "    for i in range(len(LR_SCHEDULE)):\n",
    "        if epoch == LR_SCHEDULE[i][0]:\n",
    "            return LR_SCHEDULE[i][1]\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T08:52:46.022122Z",
     "start_time": "2021-05-27T08:52:40.938Z"
    },
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "efb76772-5ba0-4868-9d28-45bd917b4836",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_model(lr=0.001, alpha=0.35):\n",
    "    base_model = tf.keras.applications.MobileNetV2(\n",
    "        input_shape=(img_height, img_width, 3),\n",
    "        include_top=False, weights='imagenet', alpha=alpha)\n",
    "#     base_model.trainable = False\n",
    "    base_model.trainable = True\n",
    "    # Add a new classifier layer for transfer learning\n",
    "    global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "    dropout = tf.keras.layers.Dropout(0.2)\n",
    "    prediction_layer = tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "#     prediction_layer = tf.keras.layers.Dense(1, activation='softmax')\n",
    "  \n",
    "    model = tf.keras.Sequential([\n",
    "      base_model,\n",
    "      global_average_layer,\n",
    "      dropout,\n",
    "      prediction_layer\n",
    "    ])\n",
    "    return model\n",
    "  \n",
    "def get_compiled_model(alpha=0.35, lr=0.001):\n",
    "    model = get_model(lr, alpha)\n",
    "#     lr = learning_rate = CustomSchedule(2)\n",
    "    model.compile(\n",
    "                optimizer=tf.keras.optimizers.SGD(learning_rate=lr, momentum=0.9),\n",
    "#                 optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "    return model\n",
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T08:52:46.025115Z",
     "start_time": "2021-05-27T08:52:40.940Z"
    },
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "36b6f893-7f0c-41ec-b049-985d42543ba7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate(train_ds, val_ds=None, lr=0.001):\n",
    "    model = get_compiled_model()\n",
    "#     model = get_compiled_model_2()\n",
    "    checkpoint_path = BASE_PATH + \"/Model/Best_Model.ckpt\"\n",
    "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "    \n",
    "#     model.save_weights(checkpoint_path.format(epoch=0))\n",
    "\n",
    "    # 创建一个保存模型权重的回调\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                     save_weights_only= True,\n",
    "                                                     save_best_only = True,\n",
    "                                                     monitor='accuracy',\n",
    "                                                     mode='auto', \n",
    "                                                     save_freq='epoch',\n",
    "                                                     verbose=1)\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=10)\n",
    "    board_callback = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=log_dir,\n",
    "        histogram_freq=0,  # How often to log histogram visualizations\n",
    "        embeddings_freq=0,  # How often to log embedding visualizations\n",
    "        update_freq=\"epoch\",\n",
    "    )  # How often to write logs (default: once per epoch)\n",
    "    \n",
    "#     steps_per_epoch = len(train_ds) // batch_size\n",
    "    hist = model.fit(train_ds, \n",
    "#                      steps_per_epoch=steps_per_epoch,\n",
    "                     epochs=NUM_EPOCHS,\n",
    "                     validation_data=val_ds,\n",
    "#                      class_weight={0:0.3, 1:0.7},\n",
    "#                      validation_steps=validation_steps,\n",
    "                     verbose=2,\n",
    "                     callbacks=[\n",
    "                       cp_callback, \n",
    "#                        board_callback, \n",
    "                       early_stop,\n",
    "#                        CustomLearningRateScheduler(lr_schedule),\n",
    "                     ])\n",
    "#     model.save('saved_model/my_model')\n",
    "    return hist,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T08:52:46.027109Z",
     "start_time": "2021-05-27T08:52:40.943Z"
    },
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4e02e922-b7c8-4368-af37-78a199f4b31c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "  try:\n",
    "    for gpu in gpus:\n",
    "#       tf.config.experimental.set_memory_growth(gpu, True)\n",
    "      print('yes')\n",
    "#     tf.config.experimental.set_virtual_device_configuration(\n",
    "#         gpus[0],\n",
    "#         [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T08:52:46.029104Z",
     "start_time": "2021-05-27T08:52:40.946Z"
    },
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d82f6f97-cdd4-41dc-afec-12b0b69e0a34",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "with strategy.scope():\n",
    "  hist,model = train_and_evaluate(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T08:52:46.030101Z",
     "start_time": "2021-05-27T08:52:40.948Z"
    },
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2fc10fee-5b2a-4be1-a095-842b0547489a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = hist.history['accuracy']\n",
    "# val_acc = hist.history['val_accuracy']\n",
    "\n",
    "loss = hist.history['loss']\n",
    "# val_loss = hist.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "# plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "# plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T08:52:46.032096Z",
     "start_time": "2021-05-27T08:52:40.950Z"
    },
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "05fb8785-f608-41fd-941d-68fbf41626d1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# !tar -cvf /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0325/Model/Best_Model.tar /dbfs/FileStore/shared_uploads/wu.wenjun@otis.com/0325/Model/Best_Model"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "data_augment",
   "notebookOrigID": 2879777356897807,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
